.

多线程的学习笔记

Web服务器（如Apache Tomcat）常常在同一时间内会收到多个HTTP请求。为了避免一个请求的处理快慢影响到其他请求的处理，绝大多数服务器都会采用一些专门的线程（工作者线程）负责请求处理，这些线程各自处理分配给它的请求，从而使得一个请求处理的快慢不会对其他请求的处理产生影响（当然，这里的“不影响”是相对的）。这有点像快餐店在点餐顾客多的情况下多开几条点餐线。
某系统需要从指定的日志文件中统计出一些信息。而待统计的日志文件中的每个文件可包含上万条记录。若要统计几十个这样的日志文件就会涉及几十万甚至上百万条记录的读取和处理。而读取日志文件所涉及的I/O操作又是一个比较慢的操作。因此，这里我们可以使用一个专门的线程负责日志文件的读取。另外，再使用专门的一个线程去负责对读取到内存中的日志记录数据进行统计。这样，使用多线程编程可以使得该统计工具的统计效率尽可能高。

**每个线程都有其要执行的任务。线程的任务处理逻辑可以在Thread类的run实例方法中直接实现或者通过该方法进行调用，因此run方法相当于线程的任务处理逻辑的入口方法，它由Java虚拟机在运行相应线程时直接调用，而不是由应用代码进行调用(?)。 运行一个线程实际上就是让Java虚拟机执行该线程的run方法，从而使相应线程的任务处理逻辑代码得以执行。为此，我们首先要启动线程。Thread类的start方法的作用是启动相应的线程。启动一个线程的实质是请求Java虚拟机运行相应的线程，而这个线程具体何时能够运行是由线程调度器（Scheduler）决定的。因此，start方法调用结束并不意味着相应线程已经开始运行，这个线程可能稍后才被运行，甚至也可能永远不会被运行。 **

不管是采用哪种方式创建线程，一旦线程的run方法执行（由Java虚拟机调用）结束，相应的线程的运行也就结束了。当然，run方法执行结束包括正常结束（run方法返回）以及代码中抛出异常而导致的中止。运行结束的线程所占用的资源（如内存空间）会如同其他Java对象一样被Java虚拟机垃圾回收。 线程属于“一次性用品”，我们不能通过重新调用一个已经运行结束的线程的start方法来使其重新运行。事实上，start方法也只能够被调用一次，多次调用同一个Thread实例的start方法会导致其抛出IllegalThreadStateException异常。 在Java平台中，一个线程就是一个对象，对象的创建离不开内存空间的分配。创建一个线程与创建其他类型的Java对象所不同的是，Java虚拟机会为每个线程分配调用栈（Call Stack）所需的内存空间。调用栈用于跟踪Java代码（方法）间的调用关系以及Java代码对本地代码（Native Code，通常是C代码）的调用。另外，Java平台中的每个线程可能还有一个内核线程（具体与Java虚拟机的实现有关）与之对应。因此相对来说，创建线程对象比创建其他类型的对象的成本要高一些。

一个真实的Java系统运行时往往有上百个线程在运行，如果没有相应的工具能够对这些线程进行监视，那么这些线程对于我们来说就成了黑盒。而我们在开发过程中进行代码调试、定位问题甚至是定位线上环境（生产环境）中的问题时往往都需要将线程变为白盒，即我们要能够知道系统中特定时刻存在哪些线程、这些线程处于什么状态以及这些线程具体是在做什么事情这些信息。 对线程进行监视的主要途径是获取并查看程序的线程转储（Thread Dump）。一个程序的线程转储包含了获取这个线程转储的那一刻该程序的线程信息。这些信息包括程序中有哪些线程以及这些线程的具体信息。Java程序的线程转储（如图1-4所示）包含的线程具体信息包括线程的属性（ID、名称、优先级等）、生命周期状态、线程的调用栈（Call Stack）以及锁（第3章会介绍这个概念）的相关信息等。通过查看调用栈我们就能够了解线程的执行情况（具体在干些什么）。 

从面向对象编程的角度来看：第1种创建方式（创建Thread类的子类）是一种基于继承（Inheritance）的技术，第2种创建方式（以Runnable接口实例为构造器参数直接通过new创建Thread实例）是一种基于组合（Composition）的技术。由于组合相对继承来说，其类和类之间的耦合性（Coupling）更低，因此它也更加灵活。一般我们认为组合是优先选用的技术。 从对象共享的角度来看：第2种创建方式意味着多个线程实例可以共享同一个Runnable实例。在某些情况下这可能导致程序的运行结果出乎我们的意料。 

一个进程中的多个线程可以共享其所在进程所申请的资源（如内存空间），因此使用多个线程相比于使用多个进程进行编程来说，节约了对系统资源的使用。 





# 监视的工具



JDK自带的工具jvisualvm适合于在开发和测试环境下监视Java系统中的线程情况。jvisualvm不仅可以用来获取线程转储，它还支持直接选中一个线程来查看该线程的调用栈。



# Linux环境下如何查找哪个线程使用CPU最长

1、获取项目的pid，jps或者ps -ef | grep java，这个前面有讲过
2、top -H -p pid，顺序不能改变
这样就可以打印出当前的项目，每条线程占用CPU时间的百分比。注意这里打出的是LWP，也就是操作系统原生线程的线程号
使用"top -H -p pid"+"jps pid"可以很容易地找到某条占用CPU高的线程的线程堆栈，从而定位占用CPU高的原因，一般是因为不当的代码操作导致了死循环。
最后提一点，"top -H -p pid"打出来的LWP是十进制的，"jps pid"打出来的本地线程号是十六进制的，转换一下，就能定位到占用CPU高的线程的当前线程堆栈了。



# 阻塞队列

![image-20210829204748019](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210829204748019.png)

![image-20210829204833645](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210829204833645.png)

![image-20210829204909411](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210829204909411.png)

# java中的线程与操作系统的线程有什么区别

在多核操作系统中，[jvm](https://so.csdn.net/so/search?q=jvm&spm=1001.2101.3001.7020)也会允许在一个进程内同时并发执行多个线程。java中的线程和操作系统中的线程分别存在于虚拟机和操作系统中，他们虽然不同，但却是一一对应，息息相关的

线程在创建时，其实是先创建一个java线程，等到本地存储、程序计数器、缓冲区等都分配好以后，JVM会调用操作系统的方法，创建一个与java线程绑定的原生线程。
线程的调度是由操作系统负责的。
当操作系统为线程分配好时间片以后，就会调用java线程的run方法执行线程。
当线程结束后，会释放java线程和原生线程所占用的资源

调用**Thread.start()\**方法，进入Thread类的源码查看会发现，它内部其实是调用了一个叫做\**start0**的方法

而对应在源码中：

![image-20220413232721863](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220413232721863.png)

# 父子线程

**严格的说，Java中不存在实质上的父子关系**

没有方法可以获取一个线程的父线程，也没有方法可以获取一个线程所有的子线程

子线程的消亡与父线程的消亡并没有任何关系，不会因为父线程的结束而导致子线程退出（操作系统中如此） 父线程的说法应该是来自于Thread的构造对象时的初始化方法，在init方法中，将创建这个线程的当前线程定义为“父”

​    **Thread parent = currentThread();**

在初始化之后，线程组（如果没设置）、是否为守护线程、优先级、上下文类加载器、父线程ThreadLocal（稍后讲解）都是从当前线程获取的

除了一些初始值的设置来自于所谓“父线程”之外，并没有强关系

**所以说，对Java中的线程，父线程的概念，只是一种逻辑称呼，创建线程的当前线程就是新线程的父线程，新线程的一些资源来自于这个父线程**

**在init方法中，对于所谓父线程的处理逻辑，换一个说法就是借助于当前正在运行的线程，对新创建线程进行一些必要的赋值与初始化**

**父线程的准确称呼应该被叫做当前线程的创建线程**

**当听到父线程的说法时，应该立即联想到的是创建线程，创建新线程时一些资源的供给者**



# Java实现阻塞队列

阻塞队列的实现原理
1、生产者向队尾添加元素
2、消费者向队头消费元素
3、添加和消费过程是线程安全的

实现1



```java

public class MyBlockingContainer<T> {
    private Queue<T> queue=new LinkedList<>();
    private final int MAX;
public MyBlockingContainer(int limit){
    this.MAX=limit;
}

public void put(T t) throws InterruptedException {
    synchronized (this){
        while(queue.size()==MAX){
            this.wait();//释放锁并且阻塞自己，要想唤醒必须先获取锁
        }
        queue.offer(t);
        this.notifyAll();//唤醒消费者线程，此时还没有释放锁
    }
}

public T get() throws InterruptedException {
    T t;
    synchronized (this){
        while(queue.size()==0){
            this.wait();
        }
        t=queue.poll();
        this.notifyAll();
    }
    return t;
}}
```
原理是synchronized+wait+notify实现，但是notify的时候是会唤醒生产者线程和消费者线程的，想象一下，当前生产者线程已经生产了MAX个元素，当他唤醒其他线程的时候，也会唤醒生产者线程，在这里显然是没有必要的。

实现二

```java
public class MyBlockingQueueForLock<T> {
    private Queue<T> queue=new LinkedList<>();
    private final int MAX;
    private ReentrantLock lock=new ReentrantLock();
    private Condition producer=lock.newCondition();
    private Condition consumer=lock.newCondition();

    public MyBlockingQueueForLock(int limit){
        this.MAX=limit;
    }

    public void put(T t) throws InterruptedException {
        final ReentrantLock lock=this.lock;
        lock.lockInterruptibly();
        try {
            while(queue.size()==MAX){
                producer.await();//响应中断
            }
            queue.offer(t);
            consumer.signalAll();
        }finally {
            lock.unlock();
        }
    }

    public T get() throws InterruptedException {
        final ReentrantLock lock=this.lock;
        lock.lockInterruptibly();
        T t;
        try {
            while (queue.size()==0){
                consumer.await();//响应中断
            }
            t=queue.poll();
            producer.signalAll();
        }finally {
            lock.unlock();
        }
        return t;
    }
}

```

lockInterruptibly():除非当前线程被中断，否则获取锁。
如果其他线程没有持有锁，则获取该锁并立即返回，将锁持有计数设置为 1。
如果当前线程已经持有这个锁，那么持有计数加一并且该方法立即返回。
**如果锁被另一个线程持有，那么当前线程将被禁用以进行线程调度并处于休眠状态，直到发生以下两种情况之一**：
锁被当前线程获取； 或者一些其他线程中断当前线程。
如果当前线程获取了锁，则锁保持计数设置为 1。
如果当前线程：
在进入此方法时设置其中断状态； 或者在获取锁时被中断，然后抛出InterruptedException并清除当前线程的中断状态。
在此实现中，由于此方法是显式中断点，因此优先响应中断而不是正常或可重入获取锁。



实现二**用AQS的条件队列实现了唤醒线程的灵活性**，可以说比实现一更进了一步

总结：JDK自带的阻塞队列其实原理和上面差不多，但是实现得更加灵活，支持高并发。比如LinkedBlockingQueue是用了两把不同的锁来实现









# 一些概念

如果这下面的题目都会，可以在简历上写”精通java并发“

![image-20210722195904894](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210722195904894.png)





## 线程的生命周期

![image-20211209122857077](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211209122857077.png)

僵死进程是指子进程退出时，父进程并未对其发出的SIGCHLD信号进行适当处理，导致子进程停留在僵死状态等待其父进程为其收尸，这个状态下的子进程就是僵死进程。



## 如何开启一个线程？

1.继承Thread类

2.实现Runnable接口

3.实现Callable接口，实现call方法，通过FutureTask创建一个线程，获取到线程执行的返回值

4.通过线程池来开启线程

通过继承Thread类或者实现Runnable接口、Callable接口都可以实现多线程，不过实现Runnable  接口与实现Callable接口的方式基本相同，只是Callable接口里定义的方法返回值，可以声明抛出异 常而已。**因此将实现Runnable接口和实现Callable接口归为一种方式**。这种方式与继承Thread方式 之间的主要差别如下。
采用实现Runnable、Callable接口的方式创建线程的优缺点
优点：线程类只是实现了Runnable或者Callable接口，还可以继承其他类。这种方式下，多个线程 可以共享一个target对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好的体现了面向对象的思想。



## 什么是Callable和Future?

Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，并且无法抛
出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被
Future拿到，**也就是说，Future可以拿到异步执行任务的返回值。可以认为是带有回调的**
**Runnable**。
Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，
Future用于获取结果。





保证线程安全的关键：加锁（两种方式。1.jvm提供的锁：即synchronized关键字 ，2 jdk提供的各种锁lock

volatile不能保证线程安全，它只保证线程可见性，不保证原子性

volatile可以防止指令重排。在DCL中，防止高并发情况下，指令重排造成的线程安全问题。

多线程编程步骤：

第一步，创建资源类

第二部

1.锁池
**所有需要竞争同步锁的线程都会放在锁池当中**，比如当前对象的锁已经被其中一个线程得到，则其他线程需要在这个锁池进行等待，当前面的线程释放同步锁后锁池中的线程去竞争同步锁，当某个线程得到后会进入就绪队列进行等待cpu资源分配。
2.等待池
当我们调用wait（）方法后，线程会放到等待池当中，等待池的线程是不会去竞争同步锁。只有调用了notify（）或notifyAll()后等待池的线程才会开始去竞争锁，notify（）是随机从等待池选出一个线程放到锁池，而notifyAll()是将等待池的所有线程放到锁池当中



1、sleep 是 Thread 类的静态本地方法，wait 则是 Object 类的本地方法。
2、sleep方法不会释放lock，但是wait会释放，而且会加入到等待队列中。

3、sleep方法不依赖于同步器synchronized，但是wait需要依赖synchronized关键字。
4、sleep不需要被唤醒（休眠之后推出阻塞），但是wait需要（不指定时间需要被别人中断）。
5、sleep 一般用于当前线程休眠，或者轮循暂停操作，wait 则多用于多线程之间的通信。
6、sleep 会让出 CPU 执行时间且强制上下文切换，而 wait 则不一定，wait 后可能还是有机会重新竞争到锁继续执行的。

yield（）执行后线程直接进入就绪状态，马上释放了cpu的执行权，但是依然保留了cpu的执行资格，所以有可能cpu下次进行线程调度还会让这个线程获取到执行权继续执行join（）执行后线程进入阻塞状态，例如在线程B中调用线程A的join（），那线程B会进入到阻塞队列，直到线程A结束或中断线程





# 同步方法和同步代码块的区别是什么？

在Java语言中，每一个对象有一把锁。线程可以使用synchronized关键字来获取对象上的锁。
synchronized关键字可应用在方法级别(粗粒度锁)或者是代码块级别(细粒度锁)。、



## 什么是竞争条件

多个线程或者进程在读写一个共享数据时结果依赖于它们执行的相对时间，这种情形叫做竞争。

竞争条件发生在当多个进程或者线程在读写数据时，其最终的的结果依赖于多个进程的指令执行顺序。

例如：考虑下面的例子

假设两个进程P1和P2共享了 变量a。在某一执行时刻，P1更新a为1，在另一时刻，P2更新a为2。

因此两个任务竞争地写变量a。在这个例子中，竞争的“ 失败者”(最后更新的进程）决定了变量a的最终值。

多个进程并发访问和操作同一数据且执行结果与访问的特定顺序有关，称为竞争条件 



# 多线程有什么用

![image-20220130013832644](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220130013832644.png)

（1）发挥多核CPU的优势
随着工业的进步，现在的笔记本、台式机乃至商用的应用服务器至少也都是双核的，4核、8核甚至
16核的也都不少见，如果是单线程的程序，那么在双核CPU上就浪费了50%，在4核CPU上就浪费
了75%。单核CPU上所谓的"多线程"那是假的多线程，同一时间处理器只会处理一段逻辑，只不过
线程之间切换得比较快，看着像多个线程"同时"运行罢了。多核CPU上的多线程才是真正的多线
程，它能让你的多段逻辑同时工作，多线程，可以真正发挥出多核CPU的优势来，达到充分利用
CPU的目的。

（2）防止阻塞
从程序运行效率的角度来看，单核CPU不但不会发挥出多线程的优势，反而会因为在单核CPU上运
行多线程导致线程上下文的切换，而降低程序整体的效率。但是单核CPU我们还是要应用多线程，
就是为了防止阻塞。试想，如果单核CPU使用单线程，那么只要这个线程阻塞了，<font color="red">**比方说远程读取某个数据吧，对端迟迟未返回又没有设置超时时间，那么你的整个程序在数据返回回来之前就停止运行了。多线程可以防止这个问题**</font>，多条线程同时运行，哪怕一条线程的代码执行读取数据阻塞，也不会影响其它任务的执行。
（3）便于建模
这是另外一个没有这么明显的优点了。假设有一个大的任务A，单线程编程，那么就要考虑很多，
建立整个程序模型比较麻烦。但是如果把这个大的任务A分解成几个小任务，任务B、任务C、任务
D，分别建立程序模型，并通过多线程分别运行这几个任务，那就简单很多了。





# CopyOnWrite容器

：Copy-On-Write 简称 COW，其基本思路是，从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容 Copy 出去形成一个新的内容然后再改，这是一种延时懒惰策略

`CopyOnWrite` 容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy`，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器

缺点：占内存(写时复制new两个对象)、不能保证数据实时一致性

# **Collections.synchronizedList和CopyOnWriteArrayList**

    CopyOnWrite容器即写时复制的容器。通俗的理解是当往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。

优点： CopyOnWriteArrayList经常被⽤于“读多写少”的并发场景，是因为CopyOnWriteArrayList⽆需任何同步措施，⼤⼤增强了读的性能。在Java中遍历线程⾮安全的List(如：ArrayList和 LinkedList)的时候，若中途有别的线程对List容器进⾏修改，那么会抛出ConcurrentModificationException异常。
CopyOnWriteArrayList由于其"读写分离"，遍历和修改操作分别作⽤在不同的List容器，所以在使⽤迭代器遍历的时候，则不会抛出异常。
缺点： 第⼀个缺点是CopyOnWriteArrayList每次执⾏写操作都会将原容器进⾏拷⻉了⼀份，数据量⼤的时候，内存会存在较⼤的压⼒，可能会引起频繁FullGC（ZGC因为没有使⽤Full GC）。⽐如这些对象占⽤的内存⽐较⼤200M左右，
那么再写⼊100M数据进去，内存就会多占⽤300M。
第⼆个缺点是CopyOnWriteArrayList由于实现的原因，写和读分别作⽤在不同新⽼容器上，在写操作执⾏过程中，读不会阻塞，但读取到的却是⽼容器的数据。

```java

public boolean add(T e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        Object[] elements = getArray();
       int len = elements.length;
        // 复制出新数组 
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        // 把新元素添加到新数组里
        newElements[len] = e;
        // 把原数组引用指向新数组 
        setArray(newElements);
 
        return true;
 
    } finally {
 
        lock.unlock();
    }
}
 
final void setArray(Object[] a) {
    array = a;

```

我们再来看⼀下remove操作的源码，remove的逻辑是将要remove元素之外的其他元素拷⻉到新的副本中，然后切换引⽤，再将原容器的引⽤指向新的副本中，因为remove操作也是“写操作”所以也是要加锁的。

```java
public E remove(int index) {
// 加锁
final ReentrantLock lock = this.lock;
lock.lock();
try {
Object[] elements = getArray();
int len = elements.length;
E oldValue = get(elements, index);
int numMoved = len - index - 1;
if (numMoved == 0)
// 如果要删除的是列表末端数据，拷⻉前len-1个数据到新副本上，再切换引⽤
setArray(Arrays.copyOf(elements, len - 1));
else {
// 否则，将除要删除元素之外的其他元素拷⻉到新副本中，并切换引⽤
Object[] newElements = new Object[len - 1];
System.arraycopy(elements, 0, newElements, 0, index);
System.arraycopy(elements, index + 1, newElements, index,
numMoved);
setArray(newElements);
}
return oldValue;
} finally {
// 解锁
lock.unlock();
}

```

如果读的时候有多个线程正在向ArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的ArrayList。

CopyOnWriteArrayList在线程对其进行变更操作的时候，会拷贝一个新的数组以存放新的字段，因此写操作性能很差；而Collections.synchronizedList读操作采用了synchronized，因此读性能较差。以下为测试程序：

```java
public class App {
    private static List<String> arrayList = Collections.synchronizedList(new ArrayList<String>());
    private static List<String> copyOnWriteArrayList = new CopyOnWriteArrayList<String>();
    private static CountDownLatch cdl1 = new CountDownLatch(2);
    private static CountDownLatch cdl2 = new CountDownLatch(2);
    private static CountDownLatch cdl3 = new CountDownLatch(2);
    private static CountDownLatch cdl4 = new CountDownLatch(2);

    static class Thread1 extends Thread {
        @Override
        public void run() {
            for (int i = 0; i < 10000; i++)
                arrayList.add(String.valueOf(i));
            cdl1.countDown();
        }
    }

    static class Thread2 extends Thread {
        @Override
        public void run() {
            for (int i = 0; i < 10000; i++)
                copyOnWriteArrayList.add(String.valueOf(i));
            cdl2.countDown();
        }
    }

    static class Thread3 extends Thread1 {
        @Override
        public void run() {
            int size = arrayList.size();
            for (int i = 0; i < size; i++)
                arrayList.get(i);
            cdl3.countDown();
        }
    }

    static class Thread4 extends Thread1 {
        @Override
        public void run() {
            int size = copyOnWriteArrayList.size();
            for (int i = 0; i < size; i++)
                copyOnWriteArrayList.get(i);
            cdl4.countDown();
        }
    }

    public static void main(String[] args) throws InterruptedException {
        long start1 = System.currentTimeMillis();
        new Thread1().start();
        new Thread1().start();
        cdl1.await();
        System.out.println("arrayList add: " + (System.currentTimeMillis() - start1));

        long start2 = System.currentTimeMillis();
        new Thread2().start();
        new Thread2().start();
        cdl2.await();
        System.out.println("copyOnWriteArrayList add: " + (System.currentTimeMillis() - start2));

        long start3 = System.currentTimeMillis();
        new Thread3().start();
        new Thread3().start();
        cdl3.await();
        System.out.println("arrayList get: " + (System.currentTimeMillis() - start3));

        long start4 = System.currentTimeMillis();
        new Thread4().start();
        new Thread4().start();
        cdl4.await();
        System.out.println("copyOnWriteArrayList get: " + (System.currentTimeMillis() - start4));
    }
}
```

输出

arrayList add: 8
copyOnWriteArrayList add: 223
arrayList get: 4
copyOnWriteArrayList get: 4

CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。


# call的使用

```java
public static void main(String[] args) {
        //使用main方法模拟Callable的call()方法的调用
        CallableTest callableTest = new CallableTest("我是阿T");
        ExecutorService executorService = Executors.newCachedThreadPool();
        System.out.println("开始执行call()方法!");
        Future<String> future = executorService.submit(callableTest);
        try {
            System.out.println("这里是为了测试一下程序的执行。");
            System.out.println("调用call()方法返回的结果："+future.get());
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }
    }

```



不使用线程池：

```java
 CallableTest callableTest1 = new CallableTest();
        CallableTest callableTest2 = new CallableTest();
        FutureTask<String> futureTask1 = new FutureTask<String>(callableTest1);
        FutureTask<String> futureTask2 = new FutureTask<String>(callableTest2);
        new Thread(futureTask1,"Thread-1: ").start();
        new Thread(futureTask2,"Thread-2: ").start();


```





# 对象同步



还需要提示一下，只要对象不变，既使对象的属性被改变，运行的结果还是同步。此结论的实验代码在setNewProperties LockOne项目里进行演示，创建类Userinfo.java，

```java
package service;
import entity.Userinfo;
public class Service {
  public void serviceMethodA(Userinfo userinfo) {
    synchronized (userinfo) {
      try {
        System.out.println(Thread.currentThread().getName());
        userinfo.setUsername("abcabcabc");
        Thread.sleep(3000);
        System.out.println("end! time=" + System.currentTimeMillis());
      } catch (InterruptedException e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
      }
    }
  }
} 两个线程类代码如图2-68所示。 运行类Run.java代码如下：package test.run;
import service.Service;
import entity.Userinfo;
import extthread.ThreadA;
import extthread.ThreadB;
public class Run {
  public static void main(String[] args) {
    try {
      Service service = new Service();
      Userinfo userinfo = new Userinfo();
      ThreadA a = new ThreadA(service, userinfo);
      a.setName("a");
      a.start();
      Thread.sleep(50);
      ThreadB b = new ThreadB(service, userinfo);
      b.setName("b");
      b.start();
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
  }
}
```

![image-20211005124238595](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211005124238595.png)





# Spring框架对TaskExecutor的抽象

Spring框架本身内置了很多类型的TaskExecutor实现。 ·SimpleAsyncTaskExecutor 这种TaskExecutor接口的实现不会复用线程，对应每个请求会新创建一个对应的线程来执行。它支持的并发限制将阻止任何超出限制的调用，这个可以通过调用setConcurrencyLimit方法来限制并发数，默认是不限制并发数的。 

·SyncTaskExecutor 这种TaskExecutor接口的实现不会异步地执行提交的任务，而是会同步使用调用线程来执行，这种实现主要用于没有必要多线程进行处理的情况，比如在进行简单的单元测试时。

·ConcurrentTaskExecutor 这种TaskExecutor接口的实现是对JDK5中的java.util.concurrent.Executor的一个包装，通过setConcurrentExecutor(Executor concurrentExecutor)接口可以设置一个JUC中的线程池到其内部来做适配。还有一个替代方案ThreadPoolTaskExecutor，它通过bean属性的方式配置Executor线程池的属性。一般很少会用到Concurrent TaskExecutor，但如果ThreadPoolTaskExecutor不够健壮满足不了你的需求，那么ConcurrentTaskExecutor也是一种选择。 

·SimpleThreadPoolTaskExecutor 这个实现实际上是Quartz的SimpleThreadPool的子类，它监听Spring的生命周期回调。当你有一个可能需要Quartz和非Quartz组件共享的线程池时，通常会使用该实现。

·ThreadPoolTaskExecutor 该实现只能在Java 5环境中使用，其也是该环境中最常用的实现。它公开了bean属性，用于配置java.util.concurrent.ThreadPoolExecutor并将其包装在TaskExecutor中。如果你需要一些高级的接口，例如ScheduledThreadPoolExecutor，建议使用Concurrent TaskExecutor。 

·TimerTaskExecutor 该实现使用单个java.util.Timer对象作为其内部异步线程来执行任务。它与SyncTaskExecutor的不同之处在于，该实现对所有提交的任务都在Timer内的单独线程中执行，尽管提交的多个任务的执行是顺序同步的。 如上，Spring框架本身提供了很多TaskExecutor的实现，但是如果不符合你的需要，你可以通过实现TaskExecutor接口来定制自己的执行器。 

# ExecutorService类



ExecutorService有一个子接口ScheduledExecutorService和一个抽象实现类AbstractExecutorService。  ScheduledExecutorService定义了四个方法，已经在上面给出基本的解释。ScheduledExecutorService有 两个实现类，分别是DelegatedScheduledExecutorService和ScheduledThreadPoolExecutor，还需要解释的是ScheduledFuture。

   ScheduledFuture继承自Future和Delayed接口，自身没有添加方法。Delayed接口定义了一个获取剩余延迟的方法。 



# 如何在Spring中使用异步执行 

  4.2.1　使用TaskExecutor实现异步执行 



在Spring中TaskExecutor的实现类是以JavaBeans的方式提供服务的，比如下面这个例子，我们通过xml方式向Spring容器中注入了TaskExecutor的实现者ThreadPoolTaskExecutor的实例。     

```xml
<bean id="taskExecutor" class="org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor">        <!--1. 核心线程个数-->        
    <property name="corePoolSize" value="5" />        <!--2.最大线程个数 -->        
    <property name="maxPoolSize" value="10" /><!--3.超过核心线程个数的线程空闲多久被回收 -->        
    <property name="keepAliveSeconds" value="60" />                <!--4.缓存队列大小 -->        
    <property name="queueCapacity" value="20" />        <!--5.拒绝策略 -->        
    <property name="rejectedExecutionHandler">            
        <bean class="java.util.concurrent.ThreadPoolExecutor$CallerRunsPolicy" />        
    </property>    
</bean>
```



  ·如上代码我们向Spring容器中注入了一个ThreadPoolTaskExecutor处理器实例，其配置属性与Java并发包中的线程池ThreadPoolExecutor类似。 ·其中代码1、2将处理器中核心线程个数设置为5，最大线程个数设置为10。 ·代码3设置了线程池中非核心线程空闲60s后会被自动回收。 

·代码5设置了线程池的拒绝策略，这里设置为CallerRunsPolicy，意为当线程池中的队列满了，并且所有线程都在忙碌的时候，如果此时向处理器提交了新的任务，则新的任务不再是异步执行，而是使用调用线程来执行。 

当我们向Spring容器中注入了TaskExecutor的实例后，我们就可以在Spring容器中使用它。

```xml
 <bean id="asyncExecutorExample"
  class="com.jiaduo.async.AsyncProgram.AsyncExecutorExample">
  <property name="taskExecutor" ref="taskExecutor" />
</bean> 
```





如上代码通过xml方式向Spring容器注入了AsyncExecutorExample的实例，并且其属性taskExecutor注入了上面创建的名称为taskExecutor的执行器，下面我们看看AsyncExecutorExample的代码。 

```java


public class AsyncExecutorExample {
  private class MessagePrinterTask implements Runnable {

    private String message;

    public MessagePrinterTask(String message) {
      this.message = message;
    }

    public void run() {
      try {
        Thread.sleep(1000);
        System.out.println(Thread.currentThread().getName() + " " + message);
      } catch (Exception e) {
        e.printStackTrace();
      }
    }
  }

  public TaskExecutor getTaskExecutor() {
    return taskExecutor;
  }

  public void setTaskExecutor(TaskExecutor taskExecutor) {
    this.taskExecutor = taskExecutor;
  }

```



## 使用注解@Async实现异步执行 

在Spring中可以在方法上添加@Async注释，以便异步执行该方法。换句话说，调用线程将在调用含有@Async注释的方法时立即返回，并且该方法的实际执行将发生在Spring的TaskExecutor异步处理器线程中。需要注意的是，该注解@Async默认是不会解析的，你可以使用如下两种方式开启该注

解的解析。 

·基于xml配置Bean时需要加入如下配置，才可以开启异步处理：   <task:annotation-driven /> ·

在基于注解的情况下可以添加如下注解来启动异步处理：   @EnableAsync

⇥⇢⇢下面我们看看如何使用第一种方式开启并使用异步执行，首先我们需要在beans-annotation.xml中配置如下代码。

```xml
<?xml version="1.0" encoding="UTF-8" ?>
<beans xmlns="http://www.springframework.org/schema/beans"
  xmlns:context="http://www.springframework.org/schema/context"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns:task="http://www.springframework.org/schema/task"
  xsi:schemaLocation="http://www.springframework.org/schema/beans
    http://www.springframework.org/schema/beans/spring-beans-2.0.xsd
    http://www.springframework.org/schema/context
    http://www.springframework.org/schema/context/spring-context-2.5.xsd
    http://www.springframework.org/schema/task
    http://www.springframework.org/schema/task/spring-task.xsd">
  <!--1.开启Async注解的解析 -->
  <task:annotation-driven />

  <!--2.注入业务Bean -->
  <bean id="asyncCommentExample"
class="com.jiaduo.async.AsyncProgram.AsyncAnnotationExample">
  </bean>
</beans>
```



  如上代码1通过配置开启了对注解Async的解析，代码2注入了我们的业务Bean，其代码如下所示。 

```java


public class AsyncAnnotationExample {
  @Async
  public void printMessages() {
    for (int i = 0; i < 6; i++) {
      try {
        Thread.sleep(1000);
        System.out.println(Thread.currentThread().getName() + " 、
Message" + i);
      } catch (Exception e) {
        e.printStackTrace();
      }
    }
  }
```


} 如上代码的printMessages方法添加了@Async注解，方法内循环6次，循环中先让执行线程休眠1s，然后打印输出。 下面我们组合上面的代码片段形成一个可执行程序进行测试，测试代码如下所示。 

```java
public static void main(String arg[]) throws InterruptedException {
  // 1.创建容器上下文
  ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(
      new String[] { "beans-annotation.xml" });

  // 2. 获取AsyncAnnotationExample实例并调用打印方法
  System.out.println(Thread.currentThread().getName() + " begin ");
  AsyncAnnotationExample asyncCommentExample = applicationContext.getBean(AsyncAnnotationExample.class);
  asyncCommentExample.printMessages();
  System.out.println(Thread.currentThread().getName() + " end ");
```




} 如上代码1使用beans-annotation.xml作为容器Bean的元数据创建了Spring上下文，代码2从中获取了AsyncAnnotationExample的实例，然后调用其printMessages，main线程调用该方法后，该方法会马上返回，**printMessages内的任务是使用Spring框架内的默认执行器SimpleAsyncTaskExecutor中的线程来执行的。** 

另外需要注意的是**@Async注解本身也是有参数的，比如我们可以在某一个需要异步处理的方法上加@Async，注解时指定使用哪一个线程池处理器来进行异步处理**。 @Async("bizExecutor")
void doSomething(String s) {
....
}



上面我们讲解的异步任务都是没有返回结果的，**其实基于@Async注解的异步处理也是支持返回值的，但是返回值类型必须是Future或者其子类类型的**，比如返回的Future类型可以是普通的java.util.concurrent.Future类型，也可以是Spring框架的org.springframework.util.concurrent.ListenableFuture类型，或者JDK8中的java.util.concurrent.CompletableFuture类型，又或者Spring中的AsyncResult类型等。这提供了异步执行的好处，以便调用者可以在调用Future上的get()之前处理其他任务。 如下代码展示了在AsyncAnnotationExample中，方法doSomething是如何在具有返回值的方法上使用注解@Async的。 

```java
 @Async
  public CompletableFuture<String> doSomething() {
    // 1.创建future
    CompletableFuture<String> result = new CompletableFuture<String>();
    // 2.模拟任务执行
    try {
      Thread.sleep(5000);
      System.out.println(Thread.currentThread().getName() + "doSomething");
    } catch (Exception e) {
      e.printStackTrace();
    }
    result.complete("done");
    // 3.返回结果
    return result;
  }
```



 



# 15.在监视器(Monitor)内部，是如何做线程同步的？程序应该做哪种级别的同步？

监视器和锁在Java虚拟机中是一块使用的。监视器监视一块同步代码块，确保一次只有一个线程执行同步代码块。每一个监视器都和一个对象引用相关联。线程在获取锁之前不允许执行同步代码。

# 16.什么是死锁(deadlock)？

两个进程都在等待对方执行完毕才能继续往下执行的时候就发生了死锁。结果就是两个进程都陷入了无限的等待中。

死锁后会陷入循环等待中。
如何避免死锁？
1）避免一个线程同时获取多个锁
2）避免一个线程在锁内占用多个资源，尽量保证每个锁只占用一个资源
3）尝试使用定时锁tryLock 替代阻塞式的锁（treentranlock)
4）对于数据库锁，加锁和解锁必须在一个数据库连接中，否则会解锁失败

指定获取锁的顺序，举例如下：
1. 比如某个线程只有获得A锁和B锁才能对某资源进行操作，在多线程条件下，如何避免死锁？
2. 获得锁的顺序是一定的，比如规定，只有获得A锁的线程才有资格获取B锁，按顺序获取锁就可
以避免死锁！！！



另一个解答：

规避死锁的常见方法：

 粗锁法（Coarsen-grained Lock）——使用一个粗粒度的锁代替多个锁。 锁排序法（Lock Ordering）——**相关线程使用全局统一的顺序申请锁**。 

使用ReentrantLock.tryLock（long，TimeUnit）来申请锁。

 使用开放调用（Open Call）——在调用外部方法时不加锁。 

使用锁的替代品



在Java中使用多线程，就会有可能导致死锁问题。死锁会让程序一直卡住，不再程序往下执行。我们只能通过中止并重启的方式来让程序重新执行。这是我们非常不愿意看到的一种现象，我们要尽可能避免死锁的情况发生！

# 死锁的四个必要条件
1、互斥条件：指进程对所分配到的资源进行排它性使用，**即在一段时间内某资源只由一个进程占用。**如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用完释放。
2、请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。
3、不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。
4、环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{A，B，C，···，Z} 中的A正在等待一个B占用的资源；B正在等待C占用的资源，……，Z正在等待已被A占用的资源。（或者叫循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系）



```java
/**
* 死锁类示例
*/
public class DeadLock implements Runnable {
public int flag = 1;
//静态对象是类的所有对象共享的
private static Object o1 = new Object(), o2 = new Object();
@Override
public void run() {
System.out.println("flag:{}"+flag);
if (flag == 1) { //先锁o1，再对o2加锁，环路等待条件
synchronized (o1) {
try {
Thread.sleep(500);
} catch (Exception e) {
e.printStackTrace();
}
synchronized (o2) {
System.out.println("1");
}
}
}
if (flag == 0) {//先锁o2，在锁01
synchronized (o2) {
try {
Thread.sleep(500);
} catch (Exception e) {
e.printStackTrace();
}
synchronized (o1) {
System.out.println("0");
}
}
}
}
    public static void main(String[] args) {
DeadLock td1 = new DeadLock();
DeadLock td2 = new DeadLock();
td1.flag = 1;
td2.flag = 0;
//td1,td2都处于可执行状态，但JVM线程调度先执行哪个线程是不确定的。
//td2的run()可能在td1的run()之前运行
new Thread(td1).start();
new Thread(td2).start();
}
}
```

1、当DeadLock 类的对象flag=1时（td1），先锁定o1,睡眠500毫秒
2、而td1在睡眠的时候另一个flag==0的对象（td2）线程启动，先锁定o2,睡眠500毫秒
3、td1睡眠结束后需要锁定o2才能继续执行，而此时o2已被td2锁定；
4、td2睡眠结束后需要锁定o1才能继续执行，而此时o1已被td1锁定；
5、td1、td2相互等待，都需要得到对方锁定的资源才能继续执行，从而死锁。



# 解决死锁：

如何避免死锁和检测

只要死锁的四个条件有一个不满足就能避免死锁

**预防死锁**
破坏互斥条件：使资源同时访问而非互斥使用，就没有进程会阻塞在资源上，从而不发生死锁
破坏请求和保持条件：**采用静态分配的方式**，静态分配的方式是指进程必须在执行之前就申请需要的全部资源，且直至所要的资源全部得到满足后才开始执行，只要有一个资源得不到分配，也不给这个进程分配其他的资源。
破坏不剥夺条件：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源，但是只适用于内存和处理器资源。
破坏循环等待条件：给系统的所有资源编号，规定进程请求所需资源的顺序必须按照资源的编号依次进行。

**设置加锁顺序**

![image-20210923111558961](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210923111558961.png)

![image-20210923111640325](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210923111640325.png)

例子：

```java
public class DeadLockExample3 {
// 加时赛锁，在极少数情况下，如果两个hash值相等，使用这个锁进行加锁
private static final Object tieLock = new Object();
public void transferMoney(final Account fromAcct,
final Account toAcct,
final DollarAmount amount)
throws InsufficientFundsException {
class Helper {
public void transfer() throws InsufficientFundsException {
if (fromAcct.getBalance().compareTo(amount) < 0)
throw new InsufficientFundsException();
else {
fromAcct.debit(amount);
toAcct.credit(amount);
}
}
}
// 得到两个锁的hash值
int fromHash = System.identityHashCode(fromAcct);
int toHash = System.identityHashCode(toAcct);
// 根据hash值判断锁顺序，决定锁的顺序
if (fromHash < toHash) {
synchronized (fromAcct) {
synchronized (toAcct) {
new Helper().transfer();
}
}
} else if (fromHash > toHash) {
synchronized (toAcct) {
synchronized (fromAcct) {
new Helper().transfer();
}
}
    } else {// 如果两个对象的hash相等，通过tieLock来决定加锁的顺序，否则又会重新引入死锁——加时锁
synchronized (tieLock) {
synchronized (fromAcct) {
    synchronized (toAcct) {
new Helper().transfer();
}
}
}
}}}
```

在极少数情况下，两个对象可能拥有两个相同的散列值，此时必须通过某种任意的方法来决定锁的顺序，否则可能又会重新引入死锁。
为了避免这种情况，可以使用 “加时(Tie-Breaking)）”锁,从而消除了死锁发生的可能性







# 17.如何确保N个线程可以访问N个资源同时又不导致死锁？

使用多线程的时候，一种非常简单的避免死锁的方式就是：**指定获取锁的顺序，并强制线程按照指定的顺序获取锁**。因此，如果所有的线程都是以同样的顺序加锁和释放锁，就不会出现死锁了。



# CopyOnWriteArrayList详细描述

在 CopyOnWriteArrayList 出现之前，我们已经有了 ArrayList 和 LinkedList 作为 List 的数组和链表的实现，而且也有了线程安全的 Vector 和 Collections.synchronizedList() 可以使用。所以首先就让我们来看下线程安全的 Vector 的 size 和 get 方法的代码：

```java
￼
public synchronized int size() {
  return elementCount;
}
public synchronized E get(int index) {
  if (index >= elementCount)
    throw new ArrayIndexOutOfBoundsException(index);
  return elementData(index);
}


```



先把我们目的说下，首先我们自己做一个写时复制的线程安全List会怎么做，我们需要考虑以下几个问题：

何时初始化list,初始化list元素个数为多少，list是有大小限制的吗？
如何保证线程安全
如何保证使用迭代器遍历list时的数据一致性？
在java并发包JUC中的List只有CopyOnWriteArrayList，它是一个线程安全的ArrayList，对其进行的修改操作都是在底层的一个复制数组(快照)上进行的，也就是写时复制策略，下面是大致的类图结构:
￼

CopyOnWriteArrayList对象里面有一个array数组对象用来存放数据，ReentrantLock独占锁对象用来保证只有一个线程可以对array进行修改。

第一个问题，什么时候初始化，初始放多少元素，list的大小有限制吗？ 我把源码贴过来：

```java
public CopyOnWriteArrayList() {
  //初始时只放了一个元素
  this.setArray(new Object[0]);
}

public CopyOnWriteArrayList(Collection<? extends E> var1) {
  Object[] var2;
  if (var1.getClass() == CopyOnWriteArrayList.class) {
    var2 = ((CopyOnWriteArrayList)var1).getArray();
  } else {
    var2 = var1.toArray();
    if (var2.getClass() != Object[].class) {
      var2 = Arrays.copyOf(var2, var2.length, Object[].class);
    }
  }

  this.setArray(var2);
}

public CopyOnWriteArrayList(E[] var1) {
  //创建一个list,其内部元素是入参var1的副本
  this.setArray(Arrays.copyOf(var1, var1.length, Object[].class));
}



public boolean add(E var1) {
  //在写操作时进行了加锁，保证了线程写操作的安全问题
  ReentrantLock var2 = this.lock;
  var2.lock();

  boolean var6;
  try {
    Object[] var3 = this.getArray();
    int var4 = var3.length;
    
    //加一个元素是在当前数组长度加1，然后赋值一个数组
    //因为动态对数组加1，所以是无界的
    Object[] var5 = Arrays.copyOf(var3, var4 + 1);
    var5[var4] = var1;
    this.setArray(var5);
    var6 = true;
  } finally {
    var2.unlock();
  }

  return var6;
}
```

通过观看源码我们已经知道初始化大小，和大小限制问题,安全问题，下面还有个很重要的数据一致性问题，还是把源码贴出来

```java
public ListIterator<E> listIterator(int var1) {
    Object[] var2 = this.getArray();
    int var3 = var2.length;
    if (var1 >= 0 && var1 <= var3) {
       //注意返回的是一个COWIterator对象
        return new CopyOnWriteArrayList.COWIterator(var2, var1);
    } else {
        throw new IndexOutOfBoundsException("Index: " + var1);
    }
} 
```

可以看出，Vector 内部是使用 synchronized 来保证线程安全的，并且锁的粒度比较大，都是方法级别的锁，在并发量高的时候，很容易发生竞争，并发效率相对比较低。在这一点上，Vector 和 Hashtable 很类似。

并且，前面这几种 List 在迭代期间不允许编辑，如果在迭代期间进行添加或删除元素等操作，则会抛出 ConcurrentModificationException 异常，这样的特点也在很多情况下给使用者带来了麻烦。

 

所以从 JDK1.5 开始，Java 并发包里提供了使用 CopyOnWrite 机制实现的并发容器 CopyOnWriteArrayList 作为主要的并发 List，CopyOnWrite 的并发集合还包括 CopyOnWriteArraySet，其底层正是利用 CopyOnWriteArrayList 实现的。

适用场景
读操作可以尽可能的快，而写即使慢一些也没关系
在很多应用场景中，读操作可能会远远多于写操作。比如，有些系统级别的信息，往往只需要加载或者修改很少的次数，但是会被系统内所有模块频繁的访问。对于这种场景，我们最希望看到的就是读操作可以尽可能的快，而写即使慢一些也没关系。

读多写少
黑名单是最典型的场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单中，黑名单并不需要实时更新，可能每天晚上更新一次就可以了。当用户搜索时，会检查当前关键字在不在黑名单中，如果在，则提示不能搜索。这种读多写少的场景也很适合使用 CopyOnWrite 集合。 





# 解决单例线程安全 DCL

示例：(一个单例)

```java
public class SingleDemo1{
    private static SingleDemo1 singleDemo1;
    private SingleDemo1(){}

    //希望实现需要使用singleDemo1时才对它进行加载，因此不在上面的static SingleDemo1 中初始化 即不写成private static SingleDemo1 singleDemo1 = new SingleDemo1();
    public static SingleDemo1 getInstance(){
        if(null == singleDemo1)
        {
            synchronized(SingleDemo1.class){
                if(null == singleDemo1)
                    singleDemo1 = new SingleDemo1();
            }
        }
        return singleDemo1;
    }
}
```



DCL存在的问题：

```java
public class DCLDemo3 {
    private static DCLTestBean instance;

    public static DCLTestBean getInstance(){
        if (instance==null){                  //第一次检
        	synchronized (DCLDemo3.class) {//同步锁
				if(instance==null) {   //第二次检查
					instance = new DCLTestBean();     
				}

			}
        }
        return instance;
    }
}
```

 

如上面代码所示，DCL本质上也就是减少了锁粒度，如果第一次检查instance不为null，那么就不需要执行下面的加锁和初始化操作。因此，可以大幅降低synchronized带来的性能开销。上面代码表面上看起来，似乎两全其美。多个线程试图在同一时间创建对象时，会通过加锁来保证只有一个线程能创建对象。在对象创建好之后，执行getInstance()方法将不需要获取锁，直接返回已创建好的对象。双重检查锁定看起来似乎很完美，但这是一个错误的优化！当线程进行第一次检查的时候，代码读取到instance不为null时，instance引用的对象有可能还没有完成初始化。

**DCL问题分析**
在上面代码中：

instance = new DCLTestBean();
这段代码可以分为如下三行伪代码：

```java

memory = allocate(); //1.分配对象内存空间
 
ctorInstance(memory); //2.在内存空间初始化对象
 
instance = memory; //3.设置instance指向刚分配的内存地址
```

上面3行伪代码中的2和3之间，可能会被重排序（在一些JIT编译器上，这种重排序是真实发生的）。

```java
memory = allocate(); //1.分配对象内存空间
instance = memory; //3.设置instance指向刚分配的内存地址

ctorInstance(memory); //2.在内存空间初始化对象
```

之前介绍过（https://blog.csdn.net/Dongguabai/article/details/82290776），指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。也就是说上面3行伪代码的2和3之间虽然被重排序了，但是是不影响串行语义的。但是在多线程并发执行的情况就可能出现：/

![image-20211222005016896](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211222005016896.png)

也就是说一个线程可能读到尚未初始化的DCLTestBean，而这个instance的确是!=null的。

![image-20211222005046834](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211222005046834.png)



可以用过一段代码来“模拟”下这种情况：

```java
package myTest;
import java.util.concurrent.TimeUnit;
 
/**
* <p>Title: DCLDemo</p>  
* <p>Description: </p>  
* @author xiayuxuanmin  
* @date 2019年7月8日
 */
public class DCLDemo {
 
    private static volatile DCLTestBean instance;
 
    public static DCLTestBean getInstance() throws InterruptedException {
        System.out.println(Thread.currentThread().getName()+"-----等待执行同步方法");
        if (instance == null) {
            synchronized (DCLDemo.class) {
            	System.out.println(Thread.currentThread().getName()+"进入同步方法");
                if (instance == null) {
                    instance = new DCLTestBean();
                    System.out.println(Thread.currentThread().getName()+"new 了");
                    //当前线程睡眠3秒
                    //该数值要大于main方法中的sleep,保证thread3在启动的时候,已经执行过new方法的线程正在睡眠状态
                    TimeUnit.SECONDS.sleep(3);
                    instance.setPassword(123);
                    instance.setUsername("zhangsan");
                }
            }
        }
        return instance;
    }
 
    public static void main(String[] args) throws InterruptedException {
        Runnable runnable = new Runnable() {
            @Override
            public void run() {
                try {
                    DCLTestBean instance = DCLDemo.getInstance();
                    System.out.println(Thread.currentThread().getName()+"^^^^^"+instance.getUsername().toString());
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        };
 
        Thread thread1 = new Thread(runnable);
        Thread thread2 = new Thread(runnable);
        Thread thread3 = new Thread(runnable);
        thread1.start();
        thread2.start();
        //该代码的作用是让thread3延迟启动2秒(保证thread3在进入getInstance() 方法之后,在判断instance == null的时候,thread1 或者thread2已经执行过new()方法,并且执行new()方法的线程正处于睡眠状态)
        Thread.sleep(2000);
        thread3.start();
    }
}
 
 
```

在知晓了问题发生的根源之后，我们可以想出两个办法来实现线程安全的延迟初始化。
1）不允许2和3重排序（在JDK 1.5后可以基于volatile来解决）；
2）允许2和3重排序，但不允许其他线程“看到”这个重排序（可以使用静态内部类解决）；

基于volatile的解决方案
很简单，只需要添加volatile关键字即可：

1.  private static volatile DCLTestBean instance;*//这里加上volatile*

这个解决方案需要JDK 5或更高版本（因为从JDK 5开始使用新的JSR-133内存模型规范，这个规范增强了volatile的语义）。
**当声明对象的引用为volatile后，下图中的3行伪代码中的2和3之间的重排序，在多线程环境中将会被禁止。当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取变量。**





## 并发并行

并发说的是在一个时间段内，多件事情在这个时间段内**交替执行。**
并行说的是多件事情在同一个时刻**同时发生。**
实际上，如果系统内只有一个CPU，而使用多进程或者多线程任务，那么真实环境中这些任务不可能是真实并行的，毕竟一个CPU一次只能执行一条指令，在这种情况下多进程或者多线程就是并发的，而不
是并行的（操作系统会不停地切换多任务）。真实的并行也只可能出现在拥有多个CPU的系统中（比如多核CPU）。

有关为什么要使用并行程序的问题前面已经进行了简单的探讨。总的来说，最重要的应该是处于两个目的。
第一，为了获得更好的性能；
第二，由于业务模型的需要，确实需要多个执行实体。
在这里，我将更加关注第一种情况，也就是有关性能的问题。将串行程序改造为并发程序，一般来说可以提高程序的整体性能，但是究竟能提高多少，甚至说究竟是否真的可以提高，还是一个需要研究的问
题。目前，主要有两个定律对这个问题进行解答，一个是Amdahl定律，另外一个是Gustafson定律。

注意：根据Amdahl定律，使用多核CPU对系统进行优化，优化的效果取决于CPU的数量，以及系统中串行化程序的比例。CPU数量越多，串行化比例越低，则优化效果越好。仅提高CPU数量而不降低程序的串行化比例，也无法提高系统的性能。

从阿姆达尔定律可以看出，程序的可并行化部分可以通过使用更多的硬件（更多的线程或CPU）运行更快。对于不可并行化的部分，只能通过优化代码来达到提速的目的。**因此，你可以通过优化不可并行化**
**部分来提高你的程序的运行速度和并行能力**。你可以对不可并行化在算法上做一点改动，如果有可能，你也可以把一些移到可并行化放的部分。

Amdahl强调：当串行换比例一定时，加速比是有上限的，不管你堆叠多少个CPU参与计算，都不能突破这个上限。 Gustafson定律关系的是：如果可被并行化的代码所占比例足够大，那么加速比就能随着CPU的数量线性增长。
总的来说，提升性能的方法：想办法提升系统并行的比例，同时增加CPU数量。



## 进程 线程 协程

![image-20220126132503702](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220126132503702.png)

进程
进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，**是系统进行资源分配和调度的基本单位**，是操作系统结构的基础。程序是指令、数据及其组织形式的描述，进程是程序的实体。

进程具有的特征：
动态性：进程是程序的一次执行过程，是临时的，有生命期的，是动态产生，动态消亡的
并发性：任何进程都可以同其他进行一起并发执行
独立性：进程是系统进行资源分配和调度的一个独立单位
结构性：进程由程序，数据和进程控制块三部分组成

进程是资源分配的最小单位,线程是程序执行的最小单位(资源调度的最小单位)

**线程是轻量级的进程，是程序执行的最小单元**，使用多线程而不是多进程去进行并发程序的设计，是因为线程间的切换和调度的成本远远小于进程。

线程的所有状态在java.lang.Thread中的State枚举中有定义，如：

```java
public enum State {
NEW,
RUNNABLE,
BLOCKED,
WAITING,
TIMED_WAITING,
TERMINATED;
}
```

操作系统的设计，因此可以归结为三点： 

（1）以多进程形式，允许多个任务同时运行； 

（2）以多线程形式，允许单个任务分成不同的部分运行； 

（3）提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源

每一个 Thread 的类都有一个 start 方法。 当调用start 启动线程时Java 虚拟机会调用该类的 run方法。 那么该类的 run() 方法中就是调用了 Runnable 对象的 run() 方法。 我们可以继承重写Thread 类，在其 start 方法中添加不断循环调用传递过来的 Runnable 对象。 这就是线程池的实现原理。循环方法中不断获取 Runnable 是用 Queue 实现的，在获取下一个 Runnable 之前可以是阻塞的。

线程池的组成
❗一般的线程池主要分为以下4 个组成部分：

1. 线程池管理器：用于创建并管理线程池

2. 工作线程：线程池中的线程

3. 任务接口：每个任务必须实现的接口，用于工作线程调度其运行

4. 任务队列：用于存放待处理的任务，提供一种缓冲机制

   

多进程是指操作系统能同时运行多个任务（程序）。

多线程是指在同一程序中有多个顺序流在执行。

 

    （1）一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。
    （2）资源分配给进程，同一进程的所有线程共享该进程的所有资源。
    
    （3）处理机分给线程，即真正在处理机上运行的是线程。
    
    （4）线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。线程是指进程内的一个执行单元,也是进程内的可调度实体.
“协程,英文Coroutines,是一种比线程更加轻量级的存在。正如一个进程可以拥有多个线程一样,一个线程也可以拥有多个协程 。

操作系统怎么进行线程的切换，CPU要切换另一个线程，线程栈里面的内容保存好，把另外一个线程拿进来，所以他是通过栈来做的。协程也是通过栈来完成。
线程和协程的本质区别**是一个通过内核空间一个不同过内核空间**
linux操作系统它分为两个不同的级别，一个是用户级一个是系统级，JVM是跑在用户空间里的，他要进行系统调用时候他要通过内核空间来进行调用的，这其中就包括了启动一个个线程，当启动一个线程时候需要内核调用，这个过程比较复杂，消耗资源比较多，正是因为如此这种线程级的并发就比较重量级。所以人们就探索，那干脆把线程挪到用户空间去，一个个线程不就是栈来回切换的记录吗，所以每一个协程和每一个协程对应的也是一个协程栈，我自己执行时候对应第一个栈数据，其他协程对应是另外的协程数据，我整个运行时候运行到这里了可以让他暂停，运行到下一个了可以让他暂停，他们本质上看上去不也是CPU执行，他**们之间的切换时通过用户空间的，不通过系统空间的**，所以他们之间切换资源消耗比较低，切换就比较快。

到目前JDK13都没见官方支持协程的影子，java要像支持协程，需要用开源第三方的协程库。

 **最重要的是,协程不是被操作系统内核所管理,而完全是由程序所控制(也就是用户执行)**

![image-20220126132528534](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220126132528534.png)

这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。

协程的开销远远小于线程的开销。

虽然协程这个概念很早就被提出，但真正作为原生特效被广泛应用，确是在本世纪。

协程的应用

**Lua语言**

Lua从5.0版本开始使用协程，通过扩展库coroutine来实现。

**Python语言**

python可以通过yield/send的方式实现协程。在python3.5以后，async/await成了更好的替代方案。

**Go语言**

Go语言对协程的实现非常强大而简洁，可以轻松创建成百上千个协程并发执行。

**Java语言**

Java语言并没有对协程的原生支持，但是某些开源框架模拟出了协程的功能。



## 线程安全活跃态问题：死锁 饥饿 活锁

同步锁
当多个线程同时访问同一个数据时，很容易出现问题。为了避免这种情况出现，我们要保证线程同步互斥，就是指并发执行的多个线程，在同一时间内只允许一个线程访问共享数据。 Java 中可以使用synchronized 关键字来取得一个对象的同步锁。


线程池原理
线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，<font color="red">如果线程数量超过了最大数量,超出数量的线程排队等候</font>，等其它线程执行完毕，再从队列中取出任务来执行。他的主要特点为：<font color="red">线程复用；控制最大并发数；管理线程。</font>

资源就是一个变量、一个对象或一个文件等；而锁就是要实现线程对资源的访问控制，保证同一时间只能有一个线程去访问某一个资源。打个比方，线程就是一个个游客，资源就是一个待参观的房子。这个房子同一时间只允许一个游客进去参观，当一个人出来后下一个人才能进去。而锁，就是这个房子门口的守卫。如果同一时间允许多个游客参观，锁就变成信号量，这点后面会专门讨论。 

死锁：是指两个或两个以上的进程（ 或线程） 在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用， 它们都将无法推进下去。

==产生死锁的必要条件：==
1、互斥条件：所谓互斥就是进程在某一时间内独占资源。
2、请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3、不剥夺条件:进程已获得资源， 在末使用完之前， 不能强行剥夺。
4、循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

发生死锁的根本原因是：**在申请锁时发生了交叉闭环申请**。

1、是多个线程涉及到多个锁，这些锁存在着交叉，所以可能会导致了一个锁依赖的闭环。
例如：线程在获得了锁A 并且没有释放的情况下去申请锁B，这时， 另一个线程已经获得了锁B，在释放锁B 之前又要先获得锁A，因此闭环发生，陷入死锁循环。
2、默认的锁申请操作是阻塞的。

所以要避免死锁，就要在一遇到多个对象锁交叉的情况，就要仔细审查这几个对象的类中的所有方法，是否存在着导致锁依赖的环路的可能性。总之是尽量避免在一个同步方法中调用其它对象的延时方法和同步方法。

**饥饿**是指某一个或者多个线程因为种种原因无法获得所要的资源，导致一直无法执行。比如它的优先级可能太低，而高优先级的线程不断抢占它需要的资源，导致低优先级线程无法工作。在自然界中，母鸡给雏鸟喂食很容易出现这种情况：由于雏鸟很多，食物有限，雏鸟之间的事务竞争可能非常厉害，经常抢不到事务的雏鸟有可能被饿死。线程的饥饿非常类似这种情况。此外，某一个线程一直占着关键资源不放，导致其他需要这个资源的线程无法正常执行，这种情况也是饥饿的一种。于死锁想必，饥饿还是有可能在未来一段时间内解决的（比如，高优先级的线程已经完成任务，不再疯狂执行）。

。如果线程智力不够。且都秉承着“谦让”的原则，主动将资源释放给他人使用，那么久会导致资源不断地在两个线程间跳动，而没有一个线程可以同时拿到所有资源正常执行。这种情况就是活锁。

活锁：有线程虽然没有发生阻塞，但仍然存在执行不下去的情况，活锁不会阻塞线程，线程会一直执行某个相同的操作并且一直失败重试

比如：开发中使用的异步消息队列就有可能造成活锁的问题，在消息队列的 消费端如果没有正确的ack消息并且执行过程中报错了，就会再次放回消息头，然后再拿出来执行，一直循环往复的失败，这个问题除了正确ack之外，往往是通过将失败的消息放入延时队列中，等到一定的延时再进行重试来解决

### 一个死锁的代码

```java
package com.Thread1;



class Lipstick{
    //口红类
}
class Mirror{

}
class Makeup extends Thread{
    int flag;
    String girl;
    static Lipstick lipstick = new Lipstick();
    static Mirror mirror = new Mirror();//静态成员
    public void run(){
doMakeUp();
    }
    public void doMakeUp(){
        if(flag == 0)
        {
            synchronized (mirror)
            {
                System.out.println(girl+"拿到了镜子");
                try{
                    Thread.sleep(2000);

                }catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
                synchronized (lipstick)
                {
                    System.out.println(girl+"拿着口红");
                }//注意这个synchronized是放在外面synchronized里面的
            }

        }
        else
        {
            synchronized (lipstick)
            {
                System.out.println(girl+"拿着口红");
            try {
                Thread.sleep(2000);

            }catch (InterruptedException e)
            {
                e.printStackTrace();
            }
            synchronized (mirror)
            {
                System.out.println(girl+"拿着镜子");
            }
            }
        }
    }
}
public class DeadLock {
    public static void main(String[] args) {
        Makeup a1 = new Makeup();
        a1.girl = "小红";
        Makeup a2 = new Makeup();
        a2.girl = "小黄";
        a1.flag = 0;
        a2.flag = 1;
        a1.start();
        a2.start();
    }
}

```

结果：

![image-20210715003558895](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210715003558895.png)

解决死锁的一个方案：同一个代码块不要同时持有两个对象锁

改为

```java
   if(flag == 0)
        {
            synchronized (mirror)
            {
                System.out.println(girl+"拿到了镜子");
                try{
                    Thread.sleep(2000);

                }catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
            
            }
            synchronized (lipstick)
            {
                System.out.println(girl+"拿着口红");
            }//   注意这个synchronized是放在上面synchronized外面的
        }
```

![image-20210715003809181](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210715003809181.png)

其中前两句输出以后隔两秒才会输出后面两句。





## sychronized关键字



（拓展：Linux中提供一把**互斥锁mutex**（**也称之为互斥量**）。

每个线程在对资源操作前都尝试先加锁，成功加锁才能操作，操作结束解锁。

但通过“锁”就将资源的访问变成互斥操作，而后与时间有关的错误也不会再产生了。）



synchronized关键字提供了一种锁的机制，能够确保共享变量的互斥访问，从而防止数据不一致问题的出现。 synchronized关键字包括monitor enter和monitor exit两个JVM指令，它能够保证在任何时候任何线程执行到**monitor enter成功之前都必须从主内存中获取数据，而不是从缓存中，在monitor exit运行成功之后，共享变量被更新后的值必须刷入主内存（**在本书的第三部分会重点介绍）。moniterenter指向同步代码块开始的位置，exit指向结束的位置，当执行monitorenter指令时线程视图获取锁也就是获取monitor(monitor存在每个java对象的对象头中，sychonized锁便是通过这种方式获取锁的，这也是为什么java中任意对象都能获得锁)

为什么sychonized修饰的变量保证原子性：线程1在执行中间指令时，其他线程不可以进入monitorenter，需要等线程1执行完monitorexist，其他进程才能继续monitorenter，进行自增操作。

synchonized修饰的方法并没有monitorenter标志，取而代之的是acc_synchonized标识，该标识指明了该方法是一个同步方法，jvm通过该acc_synchonized标识来辨别一个方法是否声明为同步方法从而执行相应的同步调用

 synchronized的指令严格遵守java happens-before规则，一个monitor exit指令之前必定要有一个monitor enter（在本书的第三部分会详细介绍）。synchronized关键字提供了一种互斥机制，也就是说在同一时刻，只能有一个线程访问同步资源，很多资料、书籍将synchronized（mutex）称为锁，其实这种说法是不严谨的，准确地讲应该是某线程获取了与mutex关联的monitor锁（当然写程序的时候知道它想要表达的语义即可），下面我们来看一个简单的例子对其进行说明：

```java
 package com.wangwenjun.concurrent.chapter04;

import java.util.concurrent.TimeUnit;

public class Mutex
{
  private final static Object MUTEX = new Object();
public void accessResource()
  {
    synchronized (MUTEX)
    {
      try
      {
        TimeUnit.MINUTES.sleep(10);
      } catch (InterruptedException e)
      {
        e.printStackTrace();
      }
    }
  }
  public static void main(String[] args)
  {
    final Mutex mutex = new Mutex();
    for (int i = 0; i < 5; i++)
    {
      new Thread(mutex::accessResource).start();
    }
  }
}
```




 上面的代码中定义了一个方法accessResource，并且使用同步代码块的方式对accessResource进行了同步，同时定义了5个线程调用accessResource方法，由于同步代码块的互斥性，只能有一个线程获取了mutex monitor的锁，其他线程只能进入阻塞 随便选中程序中创建的某个线程，会发现只有一个线程在TIMED_WAITING（sleeping）状态，其他线程都进入了BLOCKED状态 





说一说自己对于 synchronized 关键字的了解
synchronized关键字解决的是【多个线程之间访问资源的同步性】，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，**因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex** Lock 来实现的，**Java的线程是映射到操作系统的原生线程之上的**。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

所谓锁的升级、降级，就是 JVM 优化 synchronized 运行的机制，当 JVM 检测到不同的竞争状况时，会自动切换到适合的锁实现，这种切换就是锁的升级、降级。
当没有竞争出现时，默认会使用偏斜锁。JVM 会利用 CAS 操作（compare and swap），在对象头上的 Mark Word 部分设置线程 ID，以表示这个对象偏向于当前线程，所以并不涉及真正的互斥锁。这样做的假设是基于在很多应用场景中，大部分对象生命周期中最多会被一个线程锁定，使用偏斜锁可以降低无竞争开销。
如果有另外的线程试图锁定某个已经被偏斜过的对象，JVM 就需要撤销（revoke）偏斜锁，并切换到轻量级锁实现。轻量级锁依赖 CAS 操作 Mark Word 来试图获取锁，如果重试成功，就使用普通的轻量级锁；否则，进一步升级为重量级锁。
我注意到有的观点认为 Java 不会进行锁降级。实际上据我所知，锁降级确实是会发生的，当 JVM 进入安全点（SafePoint）的时候，会检查是否有闲置的 Monitor，然后试图进行降级。

一共有四种状态,级别从低到高依次为:
无锁状态，偏向锁状态，轻量级锁(自旋锁)状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。

1）一个锁对象刚刚开始创建的时候，没有任何线程来访问它，此时线程状态为无锁状态。Mark word（锁标志位-01 是否偏向-0）
2）当线程A来访问这个对象锁时，它会偏向这个线程A。线程A检查Mark word（锁标志位-01 是否偏向-0）为无锁状态。此时，有线程访问锁了，无锁升级为偏向锁，Mark word（锁标志位-01，是否偏向-1，线程ID-线程A的ID）
3）当线程A执行完同步块时，不会主动释放偏向锁。持有偏向锁的线程执行完同步代码后不会主动释放偏向锁，而是等待其他线程来竞争才会释放锁。Mark word不变（锁标志位-01，是否偏向-1，线程ID-线程A的ID）
4）当线程A再次获取这个对象锁时，检查Mark word（锁标志位-01，是否偏向-1，线程ID-线程A的ID），偏向锁且偏向线程A，可以直接执行同步代码。这样偏向锁保证了总是同一个线程多次获取锁的情况下，每次只需要检查标志位就行，效率很高。
5）当线程A执行完同步块之后，线程B获取这个对象锁 检查Mark word（锁标志位-01，是否偏向-1，线程ID-线程A的ID），偏向锁且偏向线程A。有不同的线程获取锁对象，偏向锁升级为轻量级锁，并由线程B获取该锁。
6）当线程A正在执行同步块时，也就是正持有偏向锁时，线程B获取来这个对象锁。
检查Mark word（锁标志位-01，是否偏向-1，线程ID-线程A的ID），偏向锁且偏向线程A。

【说说自己是怎么使用 synchronized 关键字，在项目中用到了吗】
synchronized关键字最主要的三种使用方式：
☛修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁
☛修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。
☛修饰代码块: 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 总结：
synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。
synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！



Synchronized修饰一个方法很简单，就是在方法的前面加synchronized，synchronized修饰方法和修饰一个代码块类似，只是作用范围不一样，修饰代码块是大括号括起来的范围，而修饰方法范围是整个函数。

在使用同步synchronized（this）代码块时需要注意的是**，当一个线程访问object的一个synchronized（this）同步代码块时，其他线程对同一个object中所有其他synchronized（this）同步代码块的访问将被阻塞**，这说明synchronized使用的“对象监视器”是一个。

例子：

```java
public class ObjectService {
    public void serviceMethodA() {
        try {
            synchronized (this) {
                System.out.println("A begin time=" + System.currentTimeMillis());
                Thread.sleep(2000);
                System.out.println("A end    end=" + System.currentTimeMillis());
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
    public void serviceMethodB() {
        synchronized (this) {
            System.out.println("B begin time=" + System.currentTimeMillis());
            System.out.println("B end end=" + System.currentTimeMillis());
        }
    }
}

public class ThreadA extends Thread{
    private ObjectService objectService;
    public ThreadA(ObjectService objectService){
        this.objectService = objectService;
    }
    @Override
    public void run(){
        super.run();
        objectService.serviceMethodA();
    }
}
class ThreadB extends Thread{
    private ObjectService objectService;
    public ThreadB(ObjectService objectService){
        this.objectService = objectService;
    }
    @Override
    public void run(){
        super.run();
        objectService.serviceMethodB();
    }
}


/**
 * @Author
 * @Description 运行类
 * @Date 8.21
 **/
public class Run {
    public static void main(String[] args) {
        ObjectService objectService = new ObjectService();
        ThreadA threadA = new ThreadA(objectService);
        ThreadB threadB = new ThreadB(objectService);
        threadA.setName("a");
        threadB.setName("b");
        threadA.start();
        threadB.start();
    }
}

```

A begin time=1629769384466
A end    end=1629769386478
B begin time=1629769386478
B end    end=1629769386478

个人理解这里super.run()就是执行目标线程

------------------------

在前面的学习中，使用synchronized（this）格式来同步代码块，**其实Java还支持对“任意对象”作为“对象监视器”来实现同步的功能**。这个“任意对象”大多数是实例变量及方法的参数，使用格式为synchronized（非this对象）。 根据前面对synchronized（this）同步代码块的作用总结可知，synchronized（非this对象）格式的作用只有1种：synchronized（非this对象x）同步代码块。

 1）在多个线程持有“对象监视器”为同一个对象的前提下，同一时间只有一个线程可以执行synchronized（非this对象x）同步代码块中的代码。 

2）当持有“对象监视器”为同一个对象的前提下，同一时间只有一个线程可以执行synchronized（非this对象x）同步代码块中的代码。 

例子：

```java
public class ObjectService {
    private String usernameParam;
    private String passwordParam;
    private String anyString = new String();

    public void setUsernamePassword(String username, String password) {
        try {
            synchronized (anyString) {
                System.out.println("线程名称为：" + Thread.currentThread().getName()
                        + "在" + System.currentTimeMillis() + "进入同步块");
                usernameParam = username;
                Thread.sleep(3000);
                passwordParam = password;
                System.out.println("线程名称为：" + Thread.currentThread().getName()
                        + "在" + System.currentTimeMillis() + "离开同步块");
            }
        } catch (InterruptedException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }
    }
}

public class ThreadA extends Thread{
    private ObjectService objectService;
    public ThreadA(ObjectService objectService){
        this.objectService = objectService;
    }
    @Override
    public void run(){
     objectService.setUsernamePassword("线程a","aa");
    }

}
class ThreadB extends Thread{
    private ObjectService objectService;
    public ThreadB(ObjectService objectService){
        this.objectService = objectService;
    }
    @Override
    public void run(){
        super.run();
        objectService.setUsernamePassword("线程b","bb");
    }
}

public class Run {
    public static void main(String[] args) {
        ObjectService objectService = new ObjectService();
        ThreadA threadA = new ThreadA(objectService);
        ThreadB threadB = new ThreadB(objectService);
        threadA.setName("a");
        threadB.setName("b");
        threadA.start();
        System.out.println(Thread.currentThread().getName());
        threadB.start();
        System.out.println(Thread.currentThread().getName());
    }
}
```

线程名称为：a在1629770746768进入同步块
线程名称为：a在1629770749783离开同步块
线程名称为：b在1629770749783进入同步块
线程名称为：b在1629770752789离开同步块

锁非this对象具有一定的优点：如果在一个类中有很多个synchronized方法，这时虽然能实现同步，但会受到阻塞，所以影响运行效率；但如果使用同步代码块锁非this对象，则synchronized（非this）代码块中的程序与同步方法是异步的，不与其他锁this同步方法争抢this锁，则可大大提高运行效率。

修改上面的例子，把String anyString = new String();放在try后面，synchronized前面，则会出现不同结果：

 ![image-20210824102003073](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210824102003073.png)

由于对象监视器对象不同，所以运行结果就是异步的。



-----------------



**Synchronized 是非公平锁**。 Synchronized 在线程进入ContentionList 时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck 线程的锁资源。

synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线程加锁消耗的时间比有用操作消耗的时间更多。

每个对象都有个monitor 对象，加锁就是在竞争monitor 对象，**代码块加锁是在前后分别加上monitorenter 和monitorexit 指令来实现的，方法加锁是通过一个标记位来判断的**

同步代码块：

```java
public class SynchronizedDemo {
public void method() {
synchronized (this) {
System.out.println("synchronized 代码块");
}
}
}
```



![image-20210923115112702](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210923115112702.png)

synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(<font color="red">monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因 </font>) 的持有权.当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

同步方法：

```java
public class SynchronizedDemo2 {
public synchronized void method() {
System.out.println("synchronized 方法");
}
}
```

![image-20210923115416228](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210923115416228.png)

用ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

例如：

方法一

```java
public synchronized void method()
{
   // todo
}
```

方法二

```java
public void method()
{
   synchronized(this) {
      // todo
   }
}
```

写法一修饰的是一个方法，写法二修饰的是一个代码块，但写法一与写法二是等价的，都是锁定了整个方法时的内容。

 synchronized 的常见问题：一个静态成员函数和一个非静态成员函数，都加了synchronized关键字，分别被两个线程调用，它们是否互斥？很显然，因为是两把不同的锁，所以不会互斥。 

**synchronized关键字不能继承。** 
虽然可以使用synchronized来定义方法，但synchronized并不属于方法定义的一部分，因此，synchronized关键字不能被继承。如果在父类中的某个方法使用了synchronized关键字，而在子类中覆盖了这个方法，在子类中的这个方法默认情况下并不是同步的，而必须显式地在子类的这个方法中加上synchronized关键字才可以。当然，还可以在子类方法中调用父类中相应的方法，这样虽然子类中的方法不是同步的，但子类调用了父类的同步方法，因此，子类的方法也就相当于同步了。这两种方式的例子代码如下： 

在子类方法中加上synchronized关键字

```java
class Parent {
   public synchronized void method() { }
}
class Child extends Parent {
   public synchronized void method() { }
}
```

在子类方法中调用父类的同步方法

```java
class Parent {
   public synchronized void method() {   }
}
class Child extends Parent {
   public void method() { super.method();   }
} 
```

1. 在定义接口方法时不能使用synchronized关键字。
2. 构造方法不能使用synchronized关键字，但可以使用synchronized代码块来进行同步。 

修饰代码块

）一个线程访问一个对象中的synchronized(this)同步代码块时，其他试图访问该对象的线程将被阻塞

class SyncThread implements Runnable {
       private static int count;

```java
  
public class sisuoDemo4 implements Runnable{
    private int count;
    public sisuoDemo4() {
        count = 0;
    }

    public  void run() {
        synchronized(this) {
            for (int i = 0; i < 5; i++) {
                try {
                    System.out.println(Thread.currentThread().getName() + ":" + (count++));
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    public int getCount() {
        return count;
    }

    public static void main(String[] args) {
        sisuoDemo4 sisuoDemo = new sisuoDemo4();
        Thread t1 = new Thread(sisuoDemo);
        Thread t2 = new Thread(sisuoDemo);
        t1.start();
        t2.start();
    }
}

```
输出

Thread-0:0
Thread-0:1
Thread-0:2
Thread-0:3
Thread-0:4
Thread-1:5
Thread-1:6
Thread-1:7
Thread-1:8
Thread-1:9



）

另一个例子：

```java
public class Demo5 implements Runnable {
static Demo5 instance = new Demo5();
static int i = 0;
@Override
public void run() {
//省略其他耗时操作....
//使用同步代码块对变量i进行同步操作,锁对象为instance
synchronized (instance) {
for (int j = 0; j < 10000; j++) {
i++;
}
}
}
public static void main(String[] args) throws InterruptedException {
Thread t1 = new Thread(instance);
Thread t2 = new Thread(instance);
t1.start();
t2.start();
t1.join();
t2.join();
System.out.println(i);
}
}
```

从代码看出，将synchronized作用于一个给定的实例对象instance，即当前实例对象就是锁对象，每次当线程进入synchronized包裹的代码块时就会要求当前线程持有instance实例对象锁，如果当前有其他线程正持有该对象锁，那么新到的线程就必须等待，这样也就保证了每次只有一个线程执行i++;操作。
当然除了instance作为对象外，我们还可以使用this对象(代表当前实例)或者当前类的class对象作为锁

```java
//this,当前实例对象锁
synchronized(this){
for(int j=0;j<1000000;j++){
i++;
}
}
//class对象锁
synchronized(Demo5.class){
for(int j=0;j<1000000;j++){
i++;
}
}
```





指定要给某个对象加锁

```java
/**
 * 银行账户类
 */
class Account {
   String name;
   float amount;
 
   public Account(String name, float amount) {
      this.name = name;
      this.amount = amount;
   }
   //存钱
   public  void deposit(float amt) {
      amount += amt;
      try {
         Thread.sleep(100);
      } catch (InterruptedException e) {
         e.printStackTrace();
      }
   }
   //取钱
   public  void withdraw(float amt) {
      amount -= amt;
      try {
         Thread.sleep(100);
      } catch (InterruptedException e) {
         e.printStackTrace();
      }
   }
 
   public float getBalance() {
      return amount;
   }
}
 
/**
 * 账户操作类
 */
class AccountOperator implements Runnable{
   private Account account;
   public AccountOperator(Account account) {
      this.account = account;
   }
 
   public void run() {
      synchronized (account) {
         account.deposit(500);
         account.withdraw(500);
         System.out.println(Thread.currentThread().getName() + ":" + account.getBalance());
      }
   }
}
 
public class Demo00{
    
    //public static final Object signal = new Object(); // 线程间通信变量
    //将account改为Demo00.signal也能实现线程同步
    public static void main(String args[]){
        Account account = new Account("zhang san", 10000.0f);
        AccountOperator accountOperator = new AccountOperator(account);
 
        final int THREAD_NUM = 5;
        Thread threads[] = new Thread[THREAD_NUM];
        for (int i = 0; i < THREAD_NUM; i ++) {
           threads[i] = new Thread(accountOperator, "Thread" + i);
           threads[i].start();
        }
    }
}
```

在AccountOperator 类中的run方法里，我们用synchronized 给account对象加了锁。这时，当一个线程访问account对象时，其他试图访问account对象的线程将会阻塞，直到该线程访问account对象结束。也就是说谁拿到那个锁谁就可以运行它所控制的那段代码。 
当有一个明确的对象作为锁时，就可以用类似下面这样的方式写程序。

```java
public void method3(SomeObject obj)
{
   //obj 锁定的对象
   synchronized(obj)
   {
      // todo
   }
}
```

当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。



当没有明确的对象作为锁，只是想让一段代码同步时，可以创建一个特殊的对象来充当锁：

```java
class Test implements Runnable
{
   private byte[] lock = new byte[0];  // 特殊的instance变量
   public void method()
   {
      synchronized(lock) {
         // todo 同步代码块
      }
   }
 
   public void run() {
 
   }
}
```

当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。

尤其关键的是，当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对object中所有其它synchronized(this)同步代码块的访问将被阻塞。

第三个例子同样适用其它同步代码块。也就是说，当一个线程访问object的一个synchronized(this)同步代码块时，它就获得了这个object的对象锁。结果，其它线程对该object对象所有同步代码部分的访问都被暂时阻塞。

以上规则对其它对象锁同样适用.

**修饰静态方法其实是类锁，区别于对象锁。**静态方法是属于类的而不属于对象的。同样的，synchronized修饰的静态方法锁定的是这个类的所有对象。

```java
public ClassA {
    public synchronized static void staticMethod() {
    // todo
}

public synchronized void method() {
    // todo
}

public void method2() {
synchronized(ClassA.class) {
            // todo
        }
    }
}

ClassA obj = new ClassA();

```

也就是说ClassA.staticMethod() 和 obj.method() 并不会存在互斥关系，但是会和obj.method2()存在互斥关系。

**四  修饰一个类**

Synchronized还可作用于一个类，用法如下：

```java
class ClassName {
   public void method() {
      synchronized(ClassName.class) {
         // todo
      }
   }
}
```

## 对象锁的“锁”到底是什么

锁的本质其实是monitorenter和monitorexit字节码指令的一个引用类型的参数，即要锁定和解锁的对象。锁住的具体内容要根据sychronized修饰的具体对象来确认：

1. 如果 Synchronized 明确指定了锁对象，比如 Synchronized（变量名）、Synchronized(this) 等，说明加解锁对象为该对象。 
2. 如果没有明确指定： 若 Synchronized 修饰的方法为非静态方法，表示此方法对应的对象为锁对象； 若 Synchronized 修饰的方法为静态方法，则表示此方法对应的类对象为锁对象。注意，当一个对象被锁住时，对象里面所有用 Synchronized 修饰的方法都将产生堵塞，而对象里非 Synchronized 修饰的方法可正常被调用，不受锁影响。





## 锁升级 递归锁 独占锁 偏向锁 轻量级锁



偏向锁、轻量级锁（自旋锁）都是用户空间完成，重量级锁都需要向内核申请

[大彻大悟synchronized原理，锁如何升级 - 哔哩哔哩 (bilibili.com)](https://www.bilibili.com/read/cv8462012)



![image-20211219130721097](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211219130721097.png)



•锁的升降级规则

Java SE 1.6为了提高锁的性能。弓|入了"偏向锁”和轻量级锁"。

Java SE 1.6中锁有4种状态。级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁 状态。

锁只能升级不能降级。

![image-20211218113739441](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211218113739441.png)

![image-20211218113945829](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211218113945829.png)



 1.初期锁对象刚创建时，还没有任何线程来竞争，对象的Mark Word是下图的第一种情形，这偏向锁标识位是0，锁状态01，说明该对象处于无锁状态（无线程竞争它）。

​    2.当有一个线程来竞争锁时，先用偏向锁，表示锁对象偏爱这个线程，这个线程要执行这个锁关联的任何代码，不需要再做任何检查和切换，这种竞争不激烈的情况下，效率非常高。这时Mark Word会记录自己偏爱的线程的ID，把该线程当做自己的熟人。如下图第二种情形。

​    3.当有两个线程开始竞争这个锁对象，情况发生变化了，不再是偏向（独占）锁了，锁会升级为轻量级锁，两个线程公平竞争，哪个线程先占有锁对象并执行代码，锁对象的Mark Word就执行哪个线程的栈帧中的锁记录。如下图第三种情形。

​    4.如果竞争的这个锁对象的线程更多，导致了更多的切换和等待，JVM会把该锁对象的锁升级为重量级锁，这个就叫做同步锁，这个锁对象Mark Word再次发生变化，**会指向一个监视器对象，这个监视器对象用集合的形式，来登记和管理排队的线程**。如下图第四种情形。

![img](https://img-blog.csdnimg.cn/20190111091608949.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdWR1bl9jb29s,size_16,color_FFFFFF,t_70)

<font color="red">可重入锁（递归锁）</font>
本文里面讲的是广义上的可重入锁，而不是单指JAVA 下的ReentrantLock。可重入锁，也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。在JAVA 环境下 ReentrantLock 和synchronized 都是 可重入锁。

<font color="red">独占锁</font>
独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。
独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。
共享锁
共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。

1. AQS 的内部类Node 定义了两个常量SHARED 和EXCLUSIVE，他们分别标识 AQS 队列中等待线程的锁获取模式。
2. java 的并发包中提供了ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问，或者被一个 写操作访问，但两者不能同时进行。

<font color="red">偏向锁</font>

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。

偏向锁会偏向于第⼀个访问锁的线程，如果在接下来的运⾏过程中，该锁没有被其他的线程访问，则持有偏向锁的线程将永远不需要触发同步。也就是说，偏向锁在资源⽆竞争情况下消除了同步语句，连CAS操作都不做了，提⾼了程序的运⾏性能。
⼤⽩话就是对锁置个变量，如果发现为true，代表资源⽆竞争，则⽆需再⾛各种加锁/解锁流程。如果为false，代表存在其他线程竞争资源，那么就会⾛后⾯的流程。

获取偏向锁时线程会将自己的id赋值给markword，即将原来的hashcode值改为线程id，是否是偏向锁改为1，表示线程拥有对象锁，可以执行下面的业务逻辑。`如果synchronized执行完，对象还是偏向锁状态；如果线程结束之后，会撤销偏向锁，将该对象还原成无锁状态`



在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。
当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径**，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。**



偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。==偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行）==，它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。所以，如果应该程序中的锁通常处于竞争状态，偏向锁就会是一种累赘，我们可以一开始就把偏向锁这个默认功能关闭。

![image-20220217015251673](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220217015251673.png)偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。

具体来说，在线程进行加锁时，如果该锁对象支持偏向锁，那么 Java 虚拟机会通过 CAS操作，将当前线程的地址记录在锁对象的标记字段之中，并且将标记字段的最后三位设置为：1 01；
在接下来的运行过程中，每当有线程请求这把锁，Java 虚拟机只需判断锁对象标记字段中：最后三位是否为： 1 01，是否包含当前线程的地址，以及 epoch 值是否和锁对象的类的epoch 值相同。如果都满足，那么当前线程持有该偏向锁，可以直接返回；

Hotspot 的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。**偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销**，看起来让这个线程得到了偏护。引入偏向锁是为了在**无多线程竞争的情况下尽量减少不必要的轻量级锁执**。上面说过，轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。



大多数情况，锁不仅不存在多线程竞争，而且总由同一线程多次获得。当一个线程访问同步块并获取锁 时，会在对象头和栈帧中记录存储锁偏向的线程ID,**以后该线程在进入和退出同步块时不需要进行cas操作来加锁和解锁，只需测试一下对象头Mark Word里是否存储着指向当前线程的偏向锁**。如果测试成 功，表示线程已经获得了锁，如果失败，则需要测试下Mark Word中偏向锁的标示是否已经设置成 1 （表示当前时偏向锁），如果没有设置，则使用cas竞争锁，如果设置了，则尝试使用cas将对象头的偏向 锁指向当前线程。（适合一个线程访问同步块的情况）

关闭偏向锁延迟

java6和7中默认启用，但是会在程序启动几秒后才激活，如果需要关闭延迟,

-XX:BiasedLockingStartupDelay=O。

如何关闭偏向锁

JVM参数关闭偏向锁:-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。

Tips:如果你可以确定程序的所有锁通常情况处于竞态，则可以选择关闭。

![image-20211219133224545](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211219133224545.png)

锁消除：删除不必要的锁操作，如果判断一段代码中堆上的数据不会逃逸 出当前线程，则认为此代码是线程安全的，无需加锁

如：public void function()

{

StringBuilder sb = new ...;//这里sb是局部变量，不会有线程安全问题，无需加锁

}

<font color="red">轻量级锁</font>
锁的状态总共有四种：无锁状态、偏向锁、轻量级锁和重量级锁。
锁升级
随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级）。

 轻量级锁

**JVM会为每个线程在当前线程的栈帧中创建⽤于存储锁记录的空间，我们称为Displaced Mark Word**。如果⼀个线程获得锁的时候发现是轻量级锁，会把锁的Mark Word复制到⾃⼰的Displaced Mark Word⾥⾯。
然后线程尝试⽤CAS将锁的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示Mark Word已经被替换成了其他线程的锁记录，说明在与其它线程竞争锁，当前线程就尝试使⽤⾃旋来获取锁。

轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在多个线程同一时间访问同一锁（同一资源）的场合，就会导致轻量级锁膨胀为重量级锁。

 轻量锁的解锁

⾃旋是需要消耗CPU的，如果⼀直获取不到锁的话，那该线程就⼀直处在⾃旋状态，⽩⽩浪费CPU资源。解决这个问题最简单的办法就是指定⾃旋的次数，例如让其循环10次，如果还没获取到锁就进⼊阻塞状态。
但是JDK采⽤了更聪明的⽅式——适应性⾃旋，简单来说就是线程如果⾃旋成功了，则下次⾃旋的次数会更多，如果⾃旋失败了，则⾃旋的次数就会减少。⾃旋也不是⼀直进⾏下去的，如果⾃旋到⼀定程度（和JVM、操作系统相关），依然没有获取到锁，称为⾃旋失败，那么这个线程会阻塞。同时这个锁就会升级成重量级锁。

轻量级锁的释放：
在释放锁时，当前线程会使⽤CAS操作将Displaced Mark Word的内容复制回锁的Mark Word⾥⾯。如果没有发⽣竞争，那么这个复制的操作会成功。如果有其他线程因为⾃旋多次导致轻量级锁升级成了重量级锁，那么CAS操作会失败，此时会释放锁并唤醒被阻塞的线程。

“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是，首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用产生的性能消耗。在解释轻量级锁的执行过程之前，先明白一点，轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。

==自旋锁==
轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或
100循环，在经过若干次循环后，**如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起**，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。

<font color="red">重量级锁</font>

重量级锁的指针指向monitor 对象（监视器锁）所以每一个对象都与一个monitor 关联，当一个monitor 被某个线程持有后，它便处于锁定状态。谈及monitor 来看一下monitord的实现，monitor 是由ObjectMonitor
实现的，其主要数据结构如下



![image-20220324203037273](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220324203037273.png)

重量级锁依赖操作系统的互斥量实现的，而操作系统中线程状态的转化需要一定的时间，因此重量级锁效率很低，但是被阻塞的线程不会消耗cpu.

前⾯说到，每⼀个对象都可以当做⼀个锁，当多个线程同时请求某个对象锁时，对象锁会设置⼏种状态⽤来区分请求的线程：
Contention List：所有请求锁的线程将被⾸先放置到该竞争队列
Entry List：Contention List中那些有资格成为候选⼈的线程被移到Entry List
Wait Set：那些调⽤wait⽅法被阻塞的线程被放置到Wait Set
OnDeck：任何时刻最多只能有⼀个线程正在竞争锁，该线程称为OnDeck
Owner：获得锁的线程称为Owner
!Owner：释放锁的线程
当⼀个线程尝试获得锁时，如果该锁已经被占⽤，则会将该线程封装成⼀
个 ObjectWaiter 对象插⼊到Contention List的队列的队⾸，然后调⽤ park 函数挂起当前线程。
当线程释放锁时，会从Contention List或EntryList中挑选⼀个线程唤醒，被选中的线程叫做 Heir presumptive 即假定继承⼈，假定继承⼈被唤醒后会尝试获得锁，但 synchronized 是⾮公平的，所以假定继承⼈不⼀定能获得锁。**这是因为对于重量级锁，线程先⾃旋尝试获得锁，这样做的⽬的是为了减少执⾏操作系统同步操作带来的开销。如果⾃旋不成功再进⼊等待队列**。这对那些已经在等待队列中的线程来说，稍微显得不公平，还有⼀个不公平的地⽅是⾃旋线程可能会抢占了Ready线程的锁。线程获得锁后调⽤ Object.wait ⽅法，则会将线程加⼊到WaitSet中，当被 Object.notify 唤醒后，会将线程从WaitSet移动到Contention List或EntryList中去。需要注意的是，当调⽤⼀个锁对象的 wait 或 notify ⽅法时，如当前锁的状态是偏向锁或轻量级锁则会先膨胀成重量级锁。

![image-20220324204144775](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220324204144775.png)

总结：

![image-20220217035916353](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220217035916353.png)

<font color="red">锁消除</font>

消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，**去除不可能存在共享资源竞争的锁**，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。锁消除的依据是逃逸分析的数据支持。

:-XX:+DoEscapeAnalysis 开启逃逸分析
-XX:+EliminateLocks 表示开启锁消除。

**jdk15取消偏向锁：**

JDK15默认关闭偏向锁优化，如果要开启可以使用XX:+UseBiasedLocking，但使用偏向锁相关的参数都会触发deprecate警告

原因
1 偏向锁导致synchronization子系统的代码复杂度过高，并且影响到了其他子系统，导致难以维护、升级

2 在现在的jdk中，偏向锁带来的加锁时性能提升从整体上看并没有带来过多收益(撤销锁的成本过高 需要等待全局安全点，再暂停线程做锁撤销)

3 官方说明中有这么一段话: since the introduction of biased locking into HotSpot also change the amount of uncontended operations needed for that relation to remain true.，我个人理解是说原子指令成本变化(我理解是降低)，导致自旋锁需要的原子指令次数变少(或者cas操作变少 个人理解)，所以自旋锁成本下降，故偏向锁的带来的优势就更小了。

## 偏向锁获得和释放详解

![image-20220205182739678](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220205182739678.png)

当JVM启用了偏向锁模式（JDK6以上默认开启），**新创建对象的Mark Word中的Thread Id为0，说明此时处于可偏向但未偏向任何线程，也叫做匿名偏向状态(anonymously biased)。**

偏向锁逻辑
1.线程A第一次访问同步块时，先检测对象头Mark Word中的标志位是否为01，依此判断此时对象锁是否处于无锁状态或者偏向锁状态（匿名偏向锁）；

2.然后判断偏向锁标志位是否为1，如果不是，则进入轻量级锁逻辑（使用CAS竞争锁），如果是，则进入下一步流程；

3.判断是偏向锁时，检查对象头Mark Word中记录的Thread Id是否是当前线程ID，如果是，则表明当前线程已经获得对象锁，以后该线程进入同步块时，不需要CAS进行加锁，只会往当前线程的栈中添加一条Displaced Mark Word为空的Lock Record中，用来统计重入的次数（如图为当对象所处于偏向锁时，当前线程重入3次，线程栈帧中Lock Record记录）。

偏向锁重入

退出同步块释放偏向锁时，则依次删除对应Lock Record，但是不会修改对象头中的Thread Id；

注：**偏向锁撤销是指在获取偏向锁的过程中因不满足条件导致要将锁对象改为非偏向锁状态，而偏向锁释放是指退出同步块时的过程。**

4.如果对象头Mark Word中Thread Id不是当前线程ID，则进行CAS操作，企图将当前线程ID替换进Mark Word。如果当前对象锁状态处于匿名偏向锁状态（可偏向未锁定），则会替换成功（将Mark Word中的Thread id由匿名0改成当前线程ID，在当前线程栈中找到内存地址最高的可用Lock Record，将线程ID存入），获取到锁，执行同步代码块；

5.如果对象锁已经被其他线程占用，则会替换失败，开始进行偏向锁撤销，这也是偏向锁的特点，一旦出现线程竞争，就会撤销偏向锁；

6.偏向锁的撤销需要等待全局安全点（safe point，代表了一个状态，在该状态下所有线程都是暂停的）,暂停持有偏向锁的线程，检查持有偏向锁的线程状态（遍历当前JVM的所有线程，如果能找到，则说明偏向的线程还存活），如果线程还存活，则检查线程是否在执行同步代码块中的代码，如果是，则升级为轻量级锁，进行CAS竞争锁；

注：每次进入同步块（即执行monitorenter）的时候都会以从高往低的顺序在栈中找到第一个可用的Lock Record，并设置偏向线程ID；每次解锁（即执行monitorexit）的时候都会从最低的一个Lock Record移除。所以如果能找到对应的Lock Record说明偏向的线程还在执行同步代码块中的代码。

7.如果持有偏向锁的线程未存活，或者持有偏向锁的线程未在执行同步代码块中的代码，则进行校验是否允许重偏向，如果不允许重偏向，则撤销偏向锁，将Mark Word设置为无锁状态（未锁定不可偏向状态），然后升级为轻量级锁，进行CAS竞争锁；

8.如果允许重偏向，设置为匿名偏向锁状态,CAS将偏向锁重新指向线程A（在对象头和线程栈帧的锁记录中存储当前线程ID）；

9.唤醒暂停的线程，从安全点继续执行代码。

以上便是偏向锁的整个逻辑了。



## monitor

在HotSpot虚拟机中，monitor是由C++中ObjectMonitor实现。
synchronized 的运行机制，就是当 JVM 监测到对象在不同的竞争状况时，会自动切换到适合的锁实现，这种切换就是锁的升级、降级。
那么三种不同的 Monitor 实现，也就是常说的三种不同的锁：偏斜锁（Biased Locking）、轻量级锁和重量级锁。当一个 Monitor 被某个线程持有后，它便处于锁定状态

Monitor 主要数据结构如下：


```java
// initialize the monitor, exception the semaphore, all other fields

 // are simple integers or pointers 
ObjectMonitor() { 

_header = NULL; 

_count = 0; // 记录个数 

_waiters = 0, 

_recursions = 0; // 线程重入次数 

_object = NULL; // 存储 Monitor 对象 

_owner = NULL; // 持有当前线程的owner

owner _WaitSet = NULL; // 处于wait状态的线程，会被加入到 _WaitSet _WaitSetLock = 0 ; 

_Responsible = NULL ; 

_succ = NULL ; 

_cxq = NULL ; // 单向列表 

FreeNext = NULL ;
    _EntryList = NULL ; // 处于等待锁block状态的线程，会被加入到该列表
    _SpinFreq = 0 ; 
    _SpinClock = 0 ; 
    OwnerIsThread = 0 ; 
    _previous_owner_tid = 0; }
```



每个 Java 对象头中都包括 Monitor 对象(存储的指针的指向)，synchronized 也就是通过这一种方式获取锁，也就解释了为什么 synchronized() 括号里放任何对象都能获得锁

## Java对象头长度信息



| 长  度   | 内  容                 | 说  明                                                       |
| -------- | ---------------------- | ------------------------------------------------------------ |
| 32/64bit | Mark Word              | 存储对象的hashCode或锁信息等                                 |
| 32/64bit | Class Metadata Addiess | 存储到对象类型数据的指针（对象是由类创建的，该字段说明哪个类创建了它） |
| 32/32bit | Array length           | 数组的长度(如果当前对象是数组)                               |



## volatile和synchronized

一篇参考文章:

[volatile与内存屏障_zhifeng687的博客-CSDN博客](https://blog.csdn.net/qq_26222859/article/details/52240256)

instance = new Singleton();         

// instance是volatile变量
 转变成汇编代码，如下

 0x01a3de1d: movb $0×0,0×1104800(%esi);

0x01a3de24: **lock addl** $0×0,(%esp);
 有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架构软件开发者手册可知，**Lock前缀的指令在多核处理器下会引发了两件事情。**

 1）将当前处理器缓存行的数据写回到系统内存。 

2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 

volatile保证可见性底层是经过了缓存一致性协议，在多处理器下为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存中。

1. volatile主要应用在多个线程对实例变量更改的场合，刷新主内存共享变量的值从而使得各个线程可以获得最新的值，线程读取变量的值需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。另外，synchronized还会创建一个内存屏障，内存屏障指令保证了所有CPU操作结果都会直接刷到主存中（即释放锁前），从而保证了操作的内存可见性，同时也使得先获得这个锁的线程的所有操作>

   

2. volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的。volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞，比如多个线程争抢synchronized锁对象时，会出现阻塞。



3) volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性，因为线程获得锁才能进入临界区，从而保证临界区中的所有语句全部得到执行。
4) volatile标记的变量不会被编译器优化，可以禁止进行指令重排；synchronized标记的变量可以被编译器优化。

我们这⾥介绍⼀下“临界区”的概念。所谓“临界区”，指的是某⼀块代码区域，它同⼀时刻只能由⼀个线程执⾏。在上⾯的例⼦中，如果 synchronized 关键字在⽅法上，那临界区就是整个⽅法内部。⽽如果是使⽤synchronized代码块，那临界区就指的是代码块内部的区



**volataile关键字的作用**

Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java内存模型的抽象示意图如下：

![image-20210725131743399](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210725131743399.png)

本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。 从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。

<font color="blue">在访问volatile 变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile 变量是一种比sychronized 关键字更轻量级的同步机制。volatile 适合这种场景：一个变量被多个线程共享，线程直接给这个变量赋值。</font>

volatile 变量：当把变量声明为volatile 类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序。**volatile 变量不会被缓存在寄存器或其他对处理器不可见的地方，因此在读取volatile 类型的变量时总会返回最新写入的值。volatile 的语义不足以确保递增操作的原子性，除非你能确保只有一个线程对变量执行写操作**。原子变量提供了“读-改-写”的原子操作，并且常常用做一种更好的volatile 变量。

一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：
☻☻☻保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
☻☻☻禁止进行指令重排序。

**volatile**采用memory barrier实现，保证可见性，禁止指令重排序，不保证原子操作。

每个volatile写操作的前后插入一个StoreStore屏障
每个volatile读操作的前后面插入一个LoadLoad屏障

![image-20220407165131552](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220407165131552.png)

例子：

![image-20230213165119950](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20230213165119950.png) 

☞☛volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的。
☞☛**volatile仅能实现变量的修改可见性，并不能保证原子性**；synchronized则可以保证变量的修改可见性和原子性。
☞☛volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。
volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。
☞☛从实践角度而言，volatile的一个重要作用就是和CAS结合，保证了原子性，详细的可以参见java.util.concurrent.atomic 包下的类，比如AtomicInteger 。



当对非 volatile 变量进行读写的时候，每个线程先从内存拷贝变量到CPU 缓存中。如果计算机有多个CPU，每个线程可能在不同的CPU 上被处理，这意味着每个线程可以拷贝到不同的 CPUcache 中。<font color="blue">而声明变量是 volatile 的，JVM 保证了每次读变量都从内存中读，跳过 CPU cache这一步。</font>

![image-20210805101759522](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210805101759522.png)

加锁机制既可以确保可见性，又可以确保原子性，而volatile 变量只能确保可见性。

volatile：会保证数据在读操作之前，上一次写操作必须生效，即写回。
1）修改volatile 变量时会强制将修改后的值刷新到主内存中。
2）**修改volatile 变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值**。
相较于synchronized 是一种较为轻量级的同步策略，但是volatile 不具备互斥性；不能保证修改变量时的原子性。

被volatile修改的变量有以下特点：

1. 线程中读取的时候，每次读取都会去主内存中读取共享变量最新的值，然后将其复制到工作内存
2. 线程中修改了工作内存中变量的副本，修改之后会立即刷新到主内存

volatile的三重功效：64位写入的原子性、内存可见性和禁止重排序。



## 为什么volatile不能保证原子性而Atomic可以

在Java中long赋值不是原子操作，因为先写32位，再写后32位，分两步操作，而AtomicLong赋值是原子操作，为什么？为什么volatile能替代简单的锁，却不能保证原子性？

意思就是说，如果一个变量加了volatile关键字，就会告诉编译器和JVM的内存模型：这个变量是对所有线程共享的、可见的，每次jvm都会读取最新写入的值并使其最新值在所有CPU可见。**volatile似乎是有时候可以代替简单的锁，似乎加了volatile关键字就省掉了锁。但又说volatile不能保证原子性（java程序员很熟悉这句话：volatile仅仅用来保证该变量对所有线程的可见性，但不保证原子性）**。这不是互相矛盾吗？

不要将volatile用在getAndOperate场合，仅仅set或者get的场景是适合volatile的

**不要将volatile用在getAndOperate场合（这种场合不原子，需要再加锁），仅仅set或者get的场景是适合volatile的**。

volatile没有原子性举例：AtomicInteger自增

例如你让一个volatile的integer自增（i++），其实要分成3步：1）读取volatile变量值到local； 2）增加变量的值；3）把local的值写回，让其它的线程可见。这3步的jvm指令为：

```
mov  ``0xc``(%r10),%r8d ; Load
inc  %r8d      ; Increment
mov  %r8d,``0xc``(%r10) ; Store
lock addl $``0x0``,(%rsp) ; StoreLoad Barrier
```

插入一个内存屏障，相当于告诉CPU和编译器先于这个命令的必须先执行，后于这个命令的必须后执行。内存屏障另一个作用是强制更新一次不同CPU的缓存。例如，一个写屏障会把这个屏障前写入的数据刷新到缓存，这样任何试图读取该数据的线程将得到最新值，而不用考虑到底是被哪个cpu核心或者哪颗CPU执行的。

内存屏障（[memory barrier](http://en.wikipedia.org/wiki/Memory_barrier)）和volatile什么关系？上面的虚拟机指令里面有提到，如果你的字段是volatile，Java内存模型将在写操作后插入一个写屏障指令，在读操作前插入一个读屏障指令。这意味着如果你对一个volatile字段进行写操作，你必须知道：

1、一旦你完成写入，任何访问这个字段的线程将会得到最新的值。

2、在你写入前，会保证所有之前发生的事已经发生，并且任何更新过的数据值也是可见的，**因为内存屏障会把之前的写入值都刷新到缓存。**

volatile为什么没有原子性?

明白了内存屏障（[memory barrier](http://en.wikipedia.org/wiki/Memory_barrier)）这个CPU指令，回到前面的JVM指令：从Load到store到内存屏障，一共4步，其中最后一步jvm让这个最新的变量的值在所有线程可见，也就是最后一步让所有的CPU内核都获得了最新的值，但**中间的几步（从Load到Store）**是不安全的，中间如果其他的CPU修改了值将会丢失。

为什么AtomicXXX具有原子性和可见性？

就拿AtomicLong来说，它既解决了上述的volatile的原子性没有保证的问题，又具有可见性。它是如何做到的？当然就是上文《[非阻塞同步算法与CAS(Compare and Swap)无锁算法](http://www.cnblogs.com/Mainz/p/3546347.html)》提到的CAS（比较并交换）指令。 其实AtomicLong的源码里也用到了volatile，但只是用来读取或写入，见源码：

```java
public` `class` `AtomicLong ``extends` `Number ``implements` `java.io.Serializable {
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;
    private volatile long value;

    public AtomicLong(long initialValue) {
        value = initialValue;
    }

    ``/**
   ``* Creates a new AtomicLong with initial value {@code 0}.
   ``*/
 public  AtomicLong() {
}
```

 cas部分：

```java
public final boolean compareAndSet(long expect, long update) {
    return unsafe.compareAndSwapLong(this, valueOffset, expect, update);
}
```

因为CAS是基于乐观锁的，也就是说当写入的时候，如果寄存器旧值已经不等于现值，说明有其他CPU在修改，那就继续尝试。所以这就保证了操作的原子性。

## 内存屏障

如下是 happens-before 的8条原则，摘自 《深入理解Java虚拟机》。

- 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
- 锁定规则：一个 unLock 操作先行发生于后面对同一个锁的 lock 操作；
- volatile 变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；
- 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
- 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；
- 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
- 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
- 对象终结规则：一个对象的初始化完成先行发生于他的 finalize() 方法的开始；

为了禁止编译器重排序和 CPU 重排序，在编译器和 CPU 层面都有对应的指令，也就是内存屏障（Memory Barrier）。这也正是JMM和happen-before规则的底层实现原理。 编译器的内存屏障，只是为了告诉编译器不要对指令进行重排序。当编译完成之后，这种内存屏障就消失了，CPU并不会感知到编译器中内存屏障的存在。 而CPU的内存屏障是CPU提供的指令，可以由开发者显示调用。

什么是内存屏障？硬件层⾯，内存屏障分两种：读屏障（Load Barrier）和写屏障（Store Barrier）。内存屏障有两个作⽤：

1. 阻⽌屏障两侧的指令重排序；
2. 强制把写缓冲区/⾼速缓存中的脏数据等写回主内存，或者让缓存中相应的数据失效。注意这⾥的缓存主要指的是CPU缓存，如L1，L2等

volatile原理
volatile变量进行写操作时，JVM 会向处理器发送一条 Lock 前缀的指令，将这个变量所在缓存行的数据写会到系统内存。
**Lock 前缀指令实际上相当于一个内存屏障**（也成内存栅栏），它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成。

![image-20211209161543494](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211209161543494.png)

在每个volatile写操作前插⼊⼀个StoreStore屏障；
在每个volatile写操作后插⼊⼀个StoreLoad屏障；
在每个volatile读操作后插⼊⼀个LoadLoad屏障；
在每个volatile读操作后再插⼊⼀个LoadStore屏障。

![image-20220216164212144](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220216164212144.png)

禁止了普通变量和volatile变量重排序

在保证内存可⻅性这⼀点上，volatile有着与锁相同的内存语义，所以可以作为⼀个“轻量级”的锁来使⽤。但由于volatile仅仅保证对单个volatile变量的读/写具有原⼦性，⽽锁可以保证整个临界区代码的执⾏具有原⼦性。所以在功能上，锁⽐volatile更强⼤；在性能上，volatile更有优势。

如果这⾥的变量声明不使⽤volatile关键字，是可能会发⽣错误的。它可能会被重排序：
instance = new Singleton(); // 第10⾏
// 可以分解为以下三个步骤
1 memory=allocate();// 分配内存 相当于c的malloc
2 ctorInstanc(memory) //初始化对象
3 s=memory //设置s指向刚分配的地址
// 上述三个步骤可能会被重排序为 1-3-2，也就是：
1 memory=allocate();// 分配内存 相当于c的malloc
3 s=memory //设置s指向刚分配的地址
2 ctorInstanc(memory) //初始化对象
⽽⼀旦假设发⽣了这样的重排序，⽐如线程A在第10⾏执⾏了步骤1和步骤3，但是步骤2还没有执⾏完。这个时候线程A执⾏到了第7⾏，它会判定instance不为空，然后直接返回了⼀个未初始化完成的instance！

## Synchronized与Reentrantlock的区别

ReentrantLock 类实现了Lock ，它拥有与synchronized 相同的并发性和内存语义，但是添加了类似锁投票、定时锁等候和可中断锁等候的一些特性。此外，它还提供了在激烈争用情况下更佳的性能。（换句话说，当许多线程都想访问共享资源时，JVM可以花更少的时候来调度线程，把更多时间用在执行线程上。）

**synchronized是和if、else、for、while一样的关键字，ReentrantLock是类**，这是二者的本质区别。既然ReentrantLock是类，那么它就提供了比synchronized更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量，ReentrantLock比synchronized的扩展性体现在几点上：
1、ReentrantLock可以对获取锁的等待时间进行设置，这样就避免了死锁
2、ReentrantLock可以获取各种锁的信息
3、ReentrantLock可以灵活地实现多路通知

**如果临界区是只读操作，其实可以多线程⼀起执⾏，但使⽤synchronized的话，同⼀时间只能有⼀个线程执⾏。**
**synchronized⽆法知道线程有没有成功获取到锁**
**使⽤synchronized，如果临界区因为IO或者sleep⽅法等原因阻塞了，⽽当前线程⼜没有释放锁，就会导致所有线程等待。**

以上问题都可以用lock解决

ReentrantReadWriteLock类作为读写锁的默认实现，内部维护了两个锁：⼀个读锁，⼀个写锁。通过分离读锁和写锁，使得在“读多写少”的环境下，⼤⼤地提⾼了性能。
注意，即使⽤读写锁，在写线程访问时，所有的读线程和其它写线程均被阻塞。

⽽ReadWriteLock⾥⾯只有两个⽅法，分别返回“读锁”和“写锁”：
public interface ReadWriteLock {
Lock readLock();
Lock writeLock();
}



在非常复杂的同步应用中，请考虑使用ReentrantLock，特别是遇到下面2 种需求的时候:
1.某个线程在等待一个锁的控制权的这段时间需要中断
2.需要分开处理一些wait-notify，ReentrantLock 里面的Condition 应用，能够控制notify 哪个线程
3.具有公平锁功能，每个到来的线程都将排队等候



Reentrant 锁意味着什么呢？
简单来说，它有一个与锁相关的获取计数器，如果拥有锁的某个线程再次得到锁，那么获取计数器就加1，然后锁需要被释放两次才能获得真正释放。这模仿了synchronized 的语义；如果线程进入由线程已经拥有的监控器保护的synchronized 块，就允许线程继续进行，当线程退出第二个（或者后续）synchronized块的时候，不释放锁，只有线程退出它进入的监控器保护的第一个synchronized 块时，才释放锁。



1. ReentrantLock 通过方法lock()与unlock()来进行加锁与解锁操作，与synchronized 会被JVM 自动解锁机制不同，ReentrantLock 加锁后需要手动进行解锁。为了避免程序出现异常而无法正常解锁的情况，使用ReentrantLock 必须在finally 控制块中进行解锁操作。
2. ReentrantLock 相比synchronized 的优势是可中断、公平锁、多个锁。这种情况下需要使用ReentrantLock。

```java
public class MyService {
private Lock lock = new ReentrantLock();
//Lock lock=new ReentrantLock(true);//公平锁
//Lock lock=new ReentrantLock(false);//非公平锁
private Condition condition=lock.newCondition();//创建Condition
public void testMethod() {
try {
lock.lock();//lock 加锁
//1：wait 方法等待：
//System.out.println("开始wait");
condition.await();//相当于wait
//通过创建Condition 对象来使线程wait，必须先执行lock.lock 方法获得锁
//:2：signal 方法唤醒 相当于notify()
condition.signal();//condition 对象的signal 方法可以唤醒wait 线程
for (int i = 0; i < 5; i++) {
System.out.println("ThreadName=" + Thread.currentThread().getName()+ (" " + (i + 1)));
}
} catch (InterruptedException e) {
e.printStackTrace();
}
finally
{
lock.unlock();
}
}
}
```

1. Condition 类的awiat 方法和Object 类的wait 方法等效
2. Condition 类的signal 方法和Object 类的notify 方法等效
3. Condition 类的signalAll 方法和Object 类的notifyAll 方法等效
4. ReentrantLock 类可以唤醒指定条件的线程，而object 的唤醒是随机的

两者的共同点：
1. 都是用来协调多线程对共享对象、变量的访问
2. 都是可重入锁，同一线程可以多次获得同一个锁
3. 都保证了可见性和互斥性

两者的不同点：
1. ReentrantLock 显示的获得、释放锁，synchronized 隐式获得释放锁
2. ReentrantLock 可响应中断、可轮回，synchronized 是不可以响应中断的，为处理锁的不可用性提供了更高的灵活性，例如：线程A和B都要获取对象O的锁定，假设A获取了对象O锁，B将等待A释放对O的锁定
   - 如果使用 synchronized ，如果A不释放，B将一直等下去，不能被中断
   - 如果 使用ReentrantLock，如果A不释放，可以使B在等待了足够长的时间以后，中断等待，而干别的事情
3. ReentrantLock 是API 级别的，synchronized 是JVM级别的
4. ReentrantLock 可以实现公平锁
5. ReentrantLock 通过Condition 可以绑定多个条件
6. 底层实现不一样， synchronized 是同步阻塞，使用的是悲观并发策略，lock 是同步非阻塞，采用的是乐观并发策略
7. Lock 是一个接口，而synchronized 是Java 中的关键字，synchronized 是内置的语言实现。
8. **synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生**；而Lock 在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock 时需要在finally 块中释放锁。
9. Lock 可以让等待锁的线程响应中断，而synchronized 却不行，使用synchronized 时，等待的线程会一直等待下去，不能够响应中断。
10. 通过Lock 可以知道有没有成功获取锁，而synchronized 却无法办到。
11. Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等。



![image-20211219150708544](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211219150708544.png)

 *Lock* 锁是*可中断*锁,而 synchronized 则为不*可中断*锁。**中断锁指的是锁在执行时可被中断，也就是在执行时可以接收 interrupt 的通知，从而中断锁执行**

PS：默认情况下 Lock 也是不可中断锁，但是可以通过特殊的“手段”，可以让其变为可中断锁，接下来我们一起来看。

为什么需要可中断锁？

不可中断锁的问题是，当出现“异常”时，只能一直阻塞等待，别无其他办法，比如下面这个程序。下面的这个程序中有两个线程，其中线程 1 先获取到锁资源执行相应代码，而线程 2 在 0.5s 之后开始尝试获取锁资源，但线程 1 执行时忘记释放锁了，这就造成线程 2 一直阻塞等待的情况，实现代码如下：

```java
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class InterruptiblyExample {
    public static void main(String[] args) {
        Lock lock = new ReentrantLock();

        // 创建线程 1
        Thread t1 = new Thread(new Runnable() {
            @Override
            public void run() {
                lock.lock();
                System.out.println("线程 1：获取到锁.");
                // 线程 1 未释放锁
            }
        });
        t1.start();

        // 创建线程 2
        Thread t2 = new Thread(new Runnable() {
            @Override
            public void run() {
                // 先休眠 0.5s，让线程 1 先执行
                try {
                    Thread.sleep(500);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                // 获取锁
                System.out.println("线程 2:等待获取锁.");
                lock.lock();
                try {
                    System.out.println("线程 2：获取锁成功.");
                } finally {
                    lock.unlock();
                }
            }
        });
        t2.start();
    }
}
```

然而，中断锁的出现，就可以打破这一僵局，它可以在等待一定时间之后，主动的中断线程 2，以解决线程阻塞等待的问题。 

中断锁的核心实现代码是 lock.lockInterruptibly() 方法，它和 lock.lock() 方法作用类似，只不过使用 lockInterruptibly 方法可以优先接收中断的请求，中断锁的具体实现如下：

```java
 // 获取锁
                try {
               System.out.println("线程 2:尝试获取锁.");
              lock.lockInterruptibly(); // 可中断锁
         System.out.println("线程 2:获取锁成功.");
     } catch (InterruptedException e) {
                    System.out.println("线程 2:执行已被中断.");
                }
```



 还有lock可以设置公平与非公平

重入锁 ReentrantLock

支持重进入的锁，它表示该锁能够支持一个线程对资源的重复加锁。除此之外，该锁的还支持获取锁时 的公平和非公平性选择。

 重进入是什么意思？

**重进入是指任意线程在获取到锁之后能够再次获锁而不被锁不塞。**

该特性主要解决以下两个问题：

一、 锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是则再次成功获取。

二、 所得最终释放。线程重复n次是获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。



![image-20210813091626819](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813091626819.png)

![image-20210813092116043](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813092116043.png)

![image-20210813092152159](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813092152159.png)

![image-20210813092211849](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813092211849.png)



lock()：获取锁，如果锁被暂用则一直等待
unlock():释放锁
tryLock(): 注意返回类型是boolean，如果获取锁的时候锁被占用就返回false，否则返回true
tryLock(long time, TimeUnit unit)：比起tryLock()就是给了一个时间期限，保证等待参数时间
lock 与 lockInterruptibly比较区别在于：
lock 优先考虑获取锁，待获取锁成功后，才响应[中断](https://so.csdn.net/so/search?q=中断&spm=1001.2101.3001.7020)。
lockInterruptibly 优先考虑响应中断，而不是响应锁的普通获取或重入获取。

ReentrantLock.lockInterruptibly允许在等待时由其它线程调用等待线程的Thread.interrupt方法来中断等待线程的等待而直接返回，这时不用获取锁，而会抛出一个InterruptedException。 ReentrantLock.lock方法不允许Thread.interrupt中断,即使检测到Thread.isInterrupted,一样会继续尝试获取锁，失败则继续休眠。只是在最后获取锁成功后再把当前线程置为interrupted状态,然后再中断线程。

==sychronized与lock==



![image-20220105112722731](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105112722731.png)

**ReentrantLock**
ReentrantLock是一种基于AQS框架的应用实现，是JDK中的一种线程并发访问的同步手段，它的功能类似于synchronized是一种互斥锁，可以保证线程安全。而且它具有比synchronized更多的特性，比如它支持手动加锁与解锁，支持加锁的公平性。
1 使用ReentrantLock进行同步
2 ReentrantLock lock = new ReentrantLock(false);//false为非公平锁，true为公平锁
3 lock.lock() //加锁
4 lock.unlock() //解锁
==ReentrantLock如何实现synchronized不具备的公平与非公平性呢？==
在ReentrantLock内部定义了一个Sync的内部类，该类继承AbstractQueuedSynchronized，对
该抽象类的部分方法做了实现；并且还定义了两个子类：
1、FairSync 公平锁的实现
2、NonfairSync 非公平锁的实现
这两个类都继承自Sync，也就是间接继承了AbstractQueuedSynchronized，所以这一个
ReentrantLock同时具备公平与非公平特性。
上面主要涉及的设计模式：模板模式-子类根据需要做具体业务实现

```java
static final class NonfairSync extends Sync {
    private static final long serialVersionUID = 7316153563782823691L;

    /**
     * Performs lock.  Try immediate barge, backing up to normal
     * acquire on failure.
     */
    final void lock() {
        if (compareAndSetState(0, 1))
            setExclusiveOwnerThread(Thread.currentThread());
        else
            acquire(1);
    }

    protected final boolean tryAcquire(int acquires) {
        return nonfairTryAcquire(acquires);
    }
}

/**
 * Sync object for fair locks
 */
static final class FairSync extends Sync {
    private static final long serialVersionUID = -3000897897090466540L;

    final void lock() {
        acquire(1);
    }

    /**
     * Fair version of tryAcquire.  Don't grant access unless
     * recursive call or no waiters or is first.
     */
    protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (!hasQueuedPredecessors() &&
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
//     public final boolean hasQueuedPredecessors()
//查询是否有任何线程等待获取的时间比当前线程长。
//调用此方法等效于（但可能比）：
  
 getFirstQueuedThread() != Thread.currentThread() &&
 hasQueuedThreads()
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc < 0)
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
}
```



![image-20220105112838312](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105112838312.png)

代码：

![image-20220105113855526](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105113855526.png)

![image-20220105113829101](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105113829101.png)

![image-20220105115644926](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105115644926.png)



## Synchronized为什么是可重入锁?

可重入是锁的一个基本要求，是为了解决自己锁死自己的情况。

实际上， synchronized 内部锁是可重入锁。**可重入锁的原理是在锁内部维护一个线程标示，用来标示该锁目前被哪个线程占用，然后关联一个计数器。**一开始计数器值为0，说明该锁没有被任何线程占用。当一个线程获取了该锁时，计数器的值会变成1，这时其他线程再来获取该锁时会发现锁的所有者不是自己而被阻塞挂起。 但是当获取了该锁的线程再次获取锁时发现锁拥有者是自己，就会把计数器值加+1，当释放锁后计数器值-1。当计数器值为0时，锁里面的线程标示被重置为 null，这时候被阻塞的线程会被唤醒来竞争获取该锁。

如果synchronized 不是重入锁 ，一个类中同步方法调用另一个同步方法，进入method方法获得锁，在methor方法内部调用method2又需要尝试获得锁，如果这时候不支持重入的话就会把自己阻塞，导致自己锁死自己。

由于Java中的线程是与操作系统中的线程一一对应的，所以当一个线程在获取锁（比如独占锁）失败后，会被切换到内核状态而被挂起。当该线程获取到锁时又需要将其切换到内核状态而唤醒该线程。而从用户状态切换到内核状态的开销是比较大的，在一定程度上会影响并发性能。自旋锁则是，当前线程在获取锁时，如果发现锁已经被其他线程占有，它不马上阻塞自己，在不放弃CPU使用权的情况下，多次尝试获取（默认次数是10，可以使用-XX:PreBlockSpinsh参数设置该值），很有可能在后面几次尝试中其他线程已经释放了锁。如果尝试指定的次数后仍没有获取到锁则当前线程才会被阻塞挂起。由此看来自旋锁是使用CPU时间换取线程阻塞与调度的开销，但是很有可能这些CPU时间白白浪费了。 

## 项目中哪里用到了synchronized

（在qiwen网盘项目的上传文件部分用到了：）

```java
@Tag(name = "filetransfer", description = "该接口为文件传输接口，主要用来做文件的上传和下载")
@RestController
@RequestMapping("/filetransfer")
public class FiletransferController {

    @Resource
    IFiletransferService filetransferService;

    @Resource
    IFileService fileService;
    @Resource
    IUserService userService;
    @Resource
    IUserFileService userFileService;
    @Resource
    FileDealComp fileDealComp;
    @Resource
    StorageService storageService;
    public static final String CURRENT_MODULE = "文件传输接口";
@RequestMapping(value = "/uploadfile", method = RequestMethod.GET)
@MyLog(operation = "极速上传", module = CURRENT_MODULE)
@ResponseBody
public RestResult<UploadFileVo> uploadFileSpeed(UploadFileDTO uploadFileDto, @RequestHeader("token") String token) {

    UserBean sessionUserBean = userService.getUserBeanByToken(token);

    boolean isCheckSuccess = storageService.checkStorage(sessionUserBean.getUserId(), uploadFileDto.getTotalSize());
    if (!isCheckSuccess) {
        return RestResult.fail().message("存储空间不足");
    }

    UploadFileVo uploadFileVo = new UploadFileVo();
    Map<String, Object> param = new HashMap<String, Object>();
    param.put("identifier", uploadFileDto.getIdentifier());
    synchronized (FiletransferController.class) {//在这个文件上传这里进行了加锁
        List<FileBean> list = fileService.listByMap(param);
        if (list != null && !list.isEmpty()) {
            FileBean file = list.get(0);

            UserFile userFile = new UserFile();
            userFile.setFileId(file.getFileId());
            userFile.setUserId(sessionUserBean.getUserId());
            userFile.setFilePath(uploadFileDto.getFilePath());
            String fileName = uploadFileDto.getFilename();
            userFile.setFileName(fileName.substring(0, fileName.lastIndexOf(".")));
            userFile.setExtendName(FileUtil.getFileExtendName(fileName));
            userFile.setDeleteFlag(0);
            userFile.setIsDir(0);
            userFile.setUploadTime(DateUtil.getCurrentTime());
            userFileService.save(userFile);
            fileService.increaseFilePointCount(file.getFileId());
            uploadFileVo.setSkipUpload(true);
            fileDealComp.uploadESByUserFileId(userFile.getUserFileId());
        } else {
            uploadFileVo.setSkipUpload(false);

        }
    }
    return RestResult.success().data(uploadFileVo);

}
```

阿里云上传文件实现类：

```java
@Slf4j
@Component
public class AliyunOSSUploader extends Uploader {

    // partETags是PartETag的集合。PartETag由分片的ETag和分片号组成。
    public static Map<String, List<PartETag>> partETagsMap = new HashMap<String, List<PartETag>>();
    public static Map<String, UploadFileInfo> uploadPartRequestMap = new HashMap<>();

    public static Map<String, OSS> ossMap = new HashMap<>();

    @Override
    public List<UploadFile> upload(HttpServletRequest httpServletRequest, UploadFile uploadFile) {
        log.info("开始上传upload");

        List<UploadFile> saveUploadFileList = new ArrayList<>();
        StandardMultipartHttpServletRequest request = (StandardMultipartHttpServletRequest) httpServletRequest;

        boolean isMultipart = ServletFileUpload.isMultipartContent(request);
        if (!isMultipart) {
            throw new UploadException("未包含文件上传域");
        }

        Iterator<String> iter = request.getFileNames();
        while (iter.hasNext()) {

            saveUploadFileList = doUpload(request, iter, uploadFile);
        }


        log.info("结束上传");
        return saveUploadFileList;
    }

    private List<UploadFile> doUpload(StandardMultipartHttpServletRequest standardMultipartHttpServletRequest, Iterator<String> iter, UploadFile uploadFile) {
        String savePath = getLocalFileSavePath();
        OSS ossClient = getClient(uploadFile);

        List<UploadFile> saveUploadFileList = new ArrayList<>();

        try {
            MultipartFile multipartfile = standardMultipartHttpServletRequest.getFile(iter.next());

            String timeStampName = getTimeStampName();
            String originalName = multipartfile.getOriginalFilename();
            String fileName = getFileName(originalName);
            String fileType = FileUtil.getFileExtendName(originalName);
            uploadFile.setFileName(fileName);
            uploadFile.setFileType(fileType);
            uploadFile.setTimeStampName(timeStampName);

            String ossFilePath = savePath + FILE_SEPARATOR + timeStampName + FILE_SEPARATOR + fileName + "." + fileType;
            String confFilePath = savePath + FILE_SEPARATOR + uploadFile.getIdentifier() + "." + "conf";
            File confFile = new File(PathUtil.getStaticPath() + FILE_SEPARATOR + confFilePath);

            synchronized (AliyunOSSUploader.class) {
                if (uploadPartRequestMap.get(uploadFile.getIdentifier()) == null) {
                    InitiateMultipartUploadRequest request = new InitiateMultipartUploadRequest(UFOAutoConfiguration.aliyunConfig.getOss().getBucketName(), ossFilePath.substring(1));
                    InitiateMultipartUploadResult upresult = ossClient.initiateMultipartUpload(request);
                    String uploadId = upresult.getUploadId();

                    UploadFileInfo uploadPartRequest = new UploadFileInfo();
                    uploadPartRequest.setBucketName(UFOAutoConfiguration.aliyunConfig.getOss().getBucketName());
                    uploadPartRequest.setKey(ossFilePath.substring(1));
                    uploadPartRequest.setUploadId(uploadId);
                    uploadPartRequestMap.put(uploadFile.getIdentifier(), uploadPartRequest);
                }

            }

            UploadFileInfo uploadFileInfo = uploadPartRequestMap.get(uploadFile.getIdentifier());
            UploadPartRequest uploadPartRequest = new UploadPartRequest();
            uploadPartRequest.setBucketName(uploadFileInfo.getBucketName());
            uploadPartRequest.setKey(uploadFileInfo.getKey());
            uploadPartRequest.setUploadId(uploadFileInfo.getUploadId());
            uploadPartRequest.setInputStream(multipartfile.getInputStream());
            uploadPartRequest.setPartSize(uploadFile.getCurrentChunkSize());
            uploadPartRequest.setPartNumber(uploadFile.getChunkNumber());
            log.info(JSON.toJSONString(uploadPartRequest));

            UploadPartResult uploadPartResult = ossClient.uploadPart(uploadPartRequest);
            synchronized (AliyunOSSUploader.class) {
                log.info("上传结果：" + JSON.toJSONString(uploadPartResult));
                if (partETagsMap.get(uploadFile.getIdentifier()) == null) {
                    List<PartETag> partETags = new ArrayList<PartETag>();
                    partETags.add(uploadPartResult.getPartETag());
                    partETagsMap.put(uploadFile.getIdentifier(), partETags);
                } else {
                    partETagsMap.get(uploadFile.getIdentifier()).add(uploadPartResult.getPartETag());
                }
            }

            boolean isComplete = checkUploadStatus(uploadFile, confFile);
            if (isComplete) {
                log.info("分片上传完成");
                completeMultipartUpload(uploadFile);

                uploadFile.setUrl("/" + uploadPartRequestMap.get(uploadFile.getIdentifier()).getKey());
                uploadFile.setSuccess(1);
                uploadFile.setMessage("上传成功");
                partETagsMap.remove(uploadFile.getIdentifier());
                uploadPartRequestMap.remove(uploadFile.getIdentifier());
                ossMap.remove(uploadFile.getIdentifier());
            } else {
                uploadFile.setSuccess(0);
                uploadFile.setMessage("未完成");
            }

        } catch (Exception e) {
            log.error("上传出错：" + e);
            throw new UploadException(e);
        }

        uploadFile.setStorageType(1);

        uploadFile.setFileSize(uploadFile.getTotalSize());
        saveUploadFileList.add(uploadFile);
        return saveUploadFileList;
    }

    /**
     * 将文件分块进行升序排序并执行文件上传。
     */
    protected void completeMultipartUpload(UploadFile uploadFile) {

        List<PartETag> partETags = partETagsMap.get(uploadFile.getIdentifier());
        Collections.sort(partETags, Comparator.comparingInt(PartETag::getPartNumber));
        UploadFileInfo uploadFileInfo = uploadPartRequestMap.get(uploadFile.getIdentifier());
        CompleteMultipartUploadRequest completeMultipartUploadRequest =
                new CompleteMultipartUploadRequest(UFOAutoConfiguration.aliyunConfig.getOss().getBucketName(),
                        uploadFileInfo.getKey(),
                        uploadFileInfo.getUploadId(),
                        partETags);
        log.info("----:" + JSON.toJSONString(partETags));
        // 完成上传。
        CompleteMultipartUploadResult completeMultipartUploadResult = getClient(uploadFile).completeMultipartUpload(completeMultipartUploadRequest);
        log.info("----:" + JSON.toJSONString(completeMultipartUploadRequest));
        getClient(uploadFile).shutdown();

//
    }

    private void listFile(UploadFile uploadFile) {
        // 列举已上传的分片，其中uploadId来自于InitiateMultipartUpload返回的结果。
        ListPartsRequest listPartsRequest = new ListPartsRequest(UFOAutoConfiguration.aliyunConfig.getOss().getBucketName(), uploadPartRequestMap.get(uploadFile.getIdentifier()).getKey(), uploadPartRequestMap.get(uploadFile.getIdentifier()).getUploadId());
        // 设置uploadId。
        //listPartsRequest.setUploadId(uploadId);
        // 设置分页时每一页中分片数量为100个。默认列举1000个分片。
        listPartsRequest.setMaxParts(100);
        // 指定List的起始位置。只有分片号大于此参数值的分片会被列举。
//            listPartsRequest.setPartNumberMarker(1);
        PartListing partListing = getClient(uploadFile).listParts(listPartsRequest);

        for (PartSummary part : partListing.getParts()) {
            log.info("分片号："+part.getPartNumber() + ", 分片数据大小: "+
                    part.getSize() + "，分片的ETag:"+part.getETag()
                    + "， 分片最后修改时间："+ part.getLastModified());
            // 获取分片号。
            part.getPartNumber();
            // 获取分片数据大小。
            part.getSize();
            // 获取分片的ETag。
            part.getETag();
            // 获取分片的最后修改时间。
            part.getLastModified();
        }

    }

    /**
     * 取消上传
     */
    @Override
    public void cancelUpload(UploadFile uploadFile) {
        AbortMultipartUploadRequest abortMultipartUploadRequest =
                new AbortMultipartUploadRequest(UFOAutoConfiguration.aliyunConfig.getOss().getBucketName(), uploadPartRequestMap.get(uploadFile.getIdentifier()).getKey(), uploadPartRequestMap.get(uploadFile.getIdentifier()).getUploadId());
        getClient(uploadFile).abortMultipartUpload(abortMultipartUploadRequest);
    }

    private synchronized OSS getClient(UploadFile uploadFile) {
        OSS ossClient = null;
        if (ossMap.get(uploadFile.getIdentifier()) == null) {
            ossClient = new OSSClientBuilder().build(UFOAutoConfiguration.aliyunConfig.getOss().getEndpoint(), UFOAutoConfiguration.aliyunConfig.getOss().getAccessKeyId(), UFOAutoConfiguration.aliyunConfig.getOss().getAccessKeySecret());
            ossMap.put(uploadFile.getIdentifier(), ossClient);
        } else {
            ossClient = ossMap.get(uploadFile.getIdentifier());
        }
        return ossClient;
    }

    @Data
    public class UploadFileInfo {
        private String bucketName;
        private String key;
        private String uploadId;
    }

}
```

## synchronized 特性

synchronized是基于JVM内置锁实现，通过内部对象Monitor(监视器锁)实现，基于进入与退出Monitor对象实现方法与代码块同步，监视器锁的实现依赖底层操作系统的Mutex lock（互斥锁）实现，它是一个重量级锁性能较低。当然，JVM内置锁在1.5之后版本做了重大的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等技术来减少锁操作的开销，，内置锁的并发性能已经基本与
Lock持平。

Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。


 29.synchronized包括哪两个jvm的指令？
monitor enter 􀀻 monitor exit

synchronized用的锁是存在Java对象头里的。对象如果是数组类型，虚拟机用3个字宽(Word)存储对象 头，如果对象是非数组类型，用2字宽存储对象头。

2.1 原子性
原子性是指一个操作是不可中断的，要么全部执行成功要么全部执行失败。

> int a = 10;  //1
> a++;  //2
> int b=a; //3
> a = a+1; //4

上面这四个语句中只**有第1个语句是原子操作**，将10赋值给线程工作内存的变量a,而语句2（a++），实际上包含了三个操作：1. 读取变量a的值；2：对a进行加一的操作；3.将计算后的值再赋值给变量a，而这三个操作无法构成原子操作。对语句3,4的分析同理可得这两条语句不具备原子性。当然，**[java内存模型](https://www.jianshu.com/p/d52fea0d6ba5)中定义了8种操作都是原子的，不可再分的。**

1. lock(锁定)：作用于主内存中的变量，它把一个变量标识为一个线程独占的状态；
2. unlock(解锁):作用于主内存中的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定
3. read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便后面的load动作使用；
4. load（载入）：作用于工作内存中的变量，它把read操作从主内存中得到的变量值放入工作内存中的变量副本
5. use（使用）：作用于工作内存中的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作；
6. assign（赋值）：作用于工作内存中的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作；
7. store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送给主内存中以便随后的write操作使用；
8. write（操作）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。



上面的这些指令操作是相当底层的，可以作为扩展知识面掌握下。那么如何理解这些指令了?比如，把一个变量从主内存中复制到工作内存中就需要执行read,load操作，将工作内存同步到主内存中就需要执行store,write操作。注意的是：**java内存模型只是要求上述两个操作是顺序执行的并不是连续执行的**。也就是说read和load之间可以插入其他指令，store和writer可以插入其他指令。比如对主内存中的a,b进行访问就可以出现这样的操作顺序：**read a,read b, load b,load a**。

由原子性变量操作read,load,use,assign,store,write，可以**大致认为基本数据类型的访问读写具备原子性**（例外就是long和double的非原子性协定）

synchronized经过编译之后，**对应的是class文件中的monitorenter和monitorexit这两个字节码指令。这两个字节码对应的内存模型的操作是lock（上锁）和unlock（解锁）**。因为这两个操作之间运行的都是原子的（这个操作保证了变量为一个线程独占的，也就是说只有获得锁的线程才能够操作被锁定的内存区域），所以synchronized也具有原子性。



案例代码

```java
private static volatile int counter = 0; 
public static void main(String[] args) throws InterruptedException { 
    for (int i = 0; i < 10; i++) 
    { 
        Thread thread = new Thread(() -> 
        { 
            for (int i1 = 0; i1 < 10000; i1++)
            { 
                add(); 
            } 
        }
); 
        thread.start(); 
    } // 等10个线程运行完毕 Thread.sleep(1000); 
    System.out.println(counter); 
} 
public static void add()
{ counter++;
}
```

这段代码开启了 10 个线程来累加 counter，按照预期结果应该是 100000。但实际运行会发现，counter 值每次运行都小于 10000，这是因为 volatile 并不能保证原子性，所以最后的结果不会是10000。
修改方法 add()，添加 synchronized：

```java
public static void add() {

 synchronized (AtomicityTest.class) {

 counter++; 

}

}
```

反编译查看指令码
javap -v -p AtomicityTest

同步方法ACC_SYNCHRONIZED 这是一个同步标识，对应的16进制值是 0x0020
这10个线程进入这个方法时，都会判断是否有此标识，然后开始竞争 Monitor 对象。

monitorenter ，在判断拥有同步标识 ACC_SYNCHRONIZED 抢先进入此方法的线程会优先拥有 Monitor 的 owner ，此时计数器 +1 。

monitorexit ，当执行完退出后，计数器 1 ，归 0 后被其他进入的线程获得。

2.2 可见性

例子

```java
public static boolean sign = false; 
public static void main(String[] args) { 
    Thread Thread01 = new Thread(
        () -> { 
            int i = 0; 
            while (!sign) { 
                i++; add(i); 
            } 
        }); 
    Thread Thread02 = new Thread(() -> { 
        try { Thread.sleep(3000); } 
        catch (InterruptedException ignore) 
        {
        } 
        sign = true; 
        logger.info("vt.sign = true while (!sign)") }); Thread01.start(); 
    Thread02.start(); } 
public static int add(int i) 
{
    return i + 1; 
}
```

这是两个线程操作一个变量的例子，因为线程间对变量 sign 的不可见性，线程 Thread01 中的 while (!sign) 会一直执行，不会随着线程 Thread02 修改 sign = true 而退出循环。
现在我们给方法 add 添加 synchronized 关键字修饰，如下：
public static synchronized int add(int i) { return i + 1; }

可以看到当线程 Thread02 改变变量 sign = true 后，线程 Thread01 立即退出了循环。

==**为什么添加 synchronized 也能保证变量的可见性呢？**==
因为：

1. 线程解锁前，必须把共享变量的最新值刷新到主内存中。
2. 线程加锁前，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存
   中重新读取最新的值。
3. volatile 的可见性都是通过内存屏障（ Memnory Barrier ）来实现的。
4. synchronized 靠操作系统内核互斥锁实现，相当于 JMM 中的 lock 、 unlock 。退出代码块时刷新变量到主内存。





2.3有序性

as-if-serial，保证不管编译器和处理器为了性能优化会如何进行指令重排序，都需要保证单线程下的运行结果的正确性。也就是常说的：如果在本线程内观察，所有的操作都是有序的；如果在一个线程观察另一个线程，所有的操作都是无序的。

为什么synchronized无法禁止指令重排，却能保证有序性？？因为在一个线程内部，他不管怎么指令重排，他都是as if serial的，也就是说单线程即使重排序之后的运行结果和串行运行的结果是一样的，是类似串行的语义。而当线程运行到同步块时，会加锁，其他线程无法获得锁**，也就是说此时同步块内的方法是单线程的**，根据as if serial，可以认为他是有序的。


这里有一段双重检验锁（Double-checked Locking）的经典案例：

```j
public class Singleton { 
private Singleton() 
{ 
} 
private volatile static Singleton instance; 
public Singleton getInstance() 
{ 
if (instance == null) { 
synchronized (Singleton.class) 
{ 
if (instance == null) 
{
instance = new Singleton(); 
}
}
} return instance; }
```

synchronized语义表示锁在同一时刻只能由一个线程进行获取，当锁被占用后，其他线程只能等待。因此，==synchronized语义就要求==线程在访问读写共享变量时只能“串行”执行，因此**synchronized具有有序性**

为什么synchronized 也有可见性的特点，还需要 volatile 关键字？

**因为synchronized 的有序性，不是 volatile 的防止指令重排序。**
那如果不加 volatile 关键字可能导致的结果，就是第一个线程在初始化初始化对象，设置 instance 指向内存地址时。第二个线程进入时，有指令重排。在判断 if (instance == null) 时就会有出错的可能，因为这会可能 instance 可能还没有初始化成功。

在java内存模型中说过，为了性能优化，编译器和处理器会进行指令重排序；也就是说java程序天然的有序性可以总结为：**如果在本线程内观察，所有的操作都是有序的；如果在一个线程观察另一个线程，所有的操作都是无序的**。在单例模式的实现上有一种双重检验锁定的方式（Double-checked 在java内存模型中说过，为了性能优化，编译器和处理器会进行指令重排序；也就是说java程序天然的有序性可以总结为：**如果在本线程内观察，所有的操作都是有序的；如果在一个线程观察另一个线程，所有的操作都是无序的**。在单例模式的实现上有一种双重检验锁定的方式（Double-checked Locking）。代码如下：

```java
public class Singleton {
    private Singleton() { }
    private volatile static Singleton instance;
    public Singleton getInstance(){
        if(instance==null){
            synchronized (Singleton.class){
                if(instance==null){
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

这里为什么要加volatile了？我们先来分析一下不加volatile的情况，有问题的语句是这条：

> instance = new Singleton();

这条语句实际上包含了三个操作：1.分配对象的内存空间；2.初始化对象；3.设置instance指向刚分配的内存地址。但由于存在重排序的问题，可能有以下的执行顺序：

![image-20220126153221899](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220126153221899.png)

如果2和3进行了重排序的话，线程B进行判断if(instance==null)时就会为true，而实际上这个instance并没有初始化成功，显而易见对线程B来说之后的操作就会是错得。而**用volatile修饰**的话就可以禁止2和3操作重排序，从而避免这种情况。**volatile包含禁止指令重排序的语义，其具有有序性**。

# 



2.4可重入性
synchronized 是可重入锁，也就是说，允许一个线程二次请求自己持有对象锁的临界资源，这种情况称为可重入锁🔒。
那么我们就写一个例子，来证明这样的情况。

```java
class A { 
    public synchronized void doA() { 
        System.out.println("父类方法：A.doA() ThreadId：" + Thread.currentThread().getId()); 
    } 
}
public class ReentryTest extends A{ 

public static void main(String[] args) 

{ 

ReentryTest reentry = new ReentryTest(); 

reentry.doA(); 

}

public synchronized void doA() { 

System.out.println("子类方法：ReentryTest.doA() ThreadId：" + Thread.currentThread().getId()); 

doB(); } 

private synchronized void doB() {

 super.doA(); 

System.out.println("子类方法：ReentryTest.doB() ThreadId：" + Thread.currentThread().getId());
}
```

测试结果
子类方法：ReentryTest.doA() ThreadId：1 父类方法：A.doA() ThreadId：1 子类方法：ReentryTest.doB() ThreadId：1 Process finished with exit code 0
这段单例代码是递归调用含有 synchronized 锁的方法，从运行正常的测试结果看，并没有发生死锁。所有可以证明 synchronized 是可重入锁。

synchronized锁对象的时候有个计数器，他会记录下线程获取锁的次数，在执行完对应的代码块之后，计数器就会-1，直到计数器清零，就释放锁了。
之所以，是可以重入。是因为 synchronized 锁对象有个计数器，会随着线程获取锁后 +1 计数，当线程执行完毕后 -1，直到清零释放锁。

## 非公平锁的优缺点？

非公平主要表现在获取锁的行为上，并非是按照申请锁的时间前后给等待线程分配锁的，每当锁被释放后，任何一个线程都有机会竞争到锁，**这样做的目的是为了提高执行性能，缺点是可能会产生线程饥饿现象**。

# ReentrantLock



ReentrantLock主要利用CAS+AQS队列来实现。它支持公平锁和非公平锁，两者的实现类似。

其实，锁的实现原理基本是为了达到一个目的： 让所有的线程都能看到某种标记。 Synchronized 通过在对象头中设置标记实现了这一目的，是一种 JVM 原生的锁实现方式，而 ReentrantLock 以及所有的基于 Lock 接口的实现类，都是通过用一个 volitile 修饰的 int 型变量，并保证每个线程都能拥有对该 int 的可见性和原子修改，其本质是基于所谓的 AQS 框架和cas乐观锁。

CAS：Compare and [Swap](https://so.csdn.net/so/search?q=Swap&spm=1001.2101.3001.7020)，比较并交换。CAS有3个操作数：内存值V、预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。该操作是一个原子操作，被广泛的应用在Java的底层实现中。在Java中，CAS主要是由sun.misc.Unsafe这个类通过JNI调用CPU底层指令实现

事实上concurrent包内许多类都是基于AQS构建，例如ReentrantLock，Semaphore，CountDownLatch，ReentrantReadWriteLock，FutureTask等。AQS解决了在实现同步容器时设计的大量细节问题

AbstractQueuedSynchronizer简称AQS

![image-20211010151918506](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211010151918506.png)

ReentrantLock的基本实现可以概括为：先通过CAS尝试获取锁。如果此时已经有线程占据了锁，那就加入AQS队列并且被挂起。当锁被释放之后，排在CLH队列队首的线程会被唤醒，然后CAS再次尝试获取锁。在这个时候，如果是：

非公平锁：如果同时还有另一个线程进来尝试获取，那么有可能会让这个线程抢先获取；

公平锁：如果同时还有另一个线程进来尝试获取，当它发现自己不是在队首的话，就会排到队尾，由队首的线程获取到锁

ReentrantLock是Lock的默认实现，在聊ReentranLock之前，我们需要先弄清楚一些概念：

1. 可重入锁：可重入锁是指同一个线程可以多次获得同一把锁；ReentrantLock和关键字Synchronized都是可重入锁
2. 可中断锁：可中断锁时子线程在获取锁的过程中，是否可以相应线程中断操作。<font color="red">synchronized是不可中断的，ReentrantLock是可中断的</font>

 中断响应：

对于synchronized来说，一个线程要么获取到锁开始执行，要么继续等待。但是对于重入锁来说，提供了更灵活的一种机制，那就是在等待锁的过程中，可以取消对锁的请求，这样可以有效避免死锁的可能。

3. 公平锁和非公平锁：公平锁是指多个线程尝试获取同一把锁的时候，获取锁的顺序按照线程到达的后顺序获取，而不是随机插队的方式获取。synchronized是非公平锁，而ReentrantLock是两种都可以实现，不过默认是非公平锁

  公平锁的一大特点是：它不会产生饥饿现象，只要你排队，最终还是可以等到资源的；**synchronized关键字默认是由jvm内部实现控制的，是非公平锁**。而ReentrantLock运行开发者自己设置锁的公平性。

  公平锁看起来很不错，不过要实现公平锁，系统内部肯定需要维护一个有序队列，因此公平锁的实现成本比较高，性能相对于非公平锁来说相对低一些。因此，在默认情况下，锁是非公平的，如果没有特别要求，则不建议使用公平锁。

ReentrantLock的使用过程：

1. 创建锁：ReentrantLock lock = new ReentrantLock();
2. 获取锁：lock.lock()
3. 释放锁：lock.unlock();

上面代码需要注意lock.unlock()一定要放在finally中，否则，若程序出现了异常，锁没有释放，那么其他线程就再也没有机会获取这个锁了。

来验证一下ReentrantLock是可重入锁，实例代码：

```java
public class Demo4 {
private static int num = 0;
private static ReentrantLock lock = new ReentrantLock();
private static void add() {
lock.lock();
lock.lock();
try {
num++;
} finally {
lock.unlock();
lock.unlock();
}
}
public static class T extends Thread {
@Override
public void run() {
for (int i = 0; i < 10000; i++) {
Demo4.add();
}
}
}
    
    public static void main(String[] args) throws InterruptedException {
T t1 = new T();
T t2 = new T();
T t3 = new T();
t1.start();
t2.start();
t3.start();
t1.join();
t2.join();
t3.join();
System.out.println(Demo4.num);
}
```

上面代码中add()方法中，当一个线程进入的时候，会执行2次获取锁的操作，运行程序可以正常结束，并输出和期望值一样的30000，假如ReentrantLock是不可重入的锁，那么同一个线程第2次获取锁的时候由于前面的锁还未释放而导致死锁，程序是无法正常结束的。Reentrant Lock，和其名字一样，可重入锁。



关于获取锁的过程中被中断，注意几点:

1. ReentrankLock中必须使用实例方法lockInterruptibly() 获取锁时，在线程调用interrupt()方法之后，才会引发InterruptedException 异常
2. 线程调用interrupt()之后，线程的中断标志会被置为true
3. 触发InterruptedException异常之后，线程的中断标志会被清空，即置为false
4. 所以当线程调用interrupt()引发InterruptedException异常，中断标志的变化是:false->true->->false

5. 实例方法tryLock()会尝试获取锁，会立即返回，返回值表示是否获取成功
6. 实例方法tryLock(long timeout, TimeUnit unit)会在指定的时间内尝试获取锁，指定的时间内是否能够获取锁，都会返回，返回值表示是否获取锁成功，该方法会响应线程的中断

与synchronized 会被JVM 自动解锁机制不同，ReentrantLock 加锁后需要手动进行解锁。为了避免程序出现异常而无法正常解锁的情况，使用ReentrantLock 必须在finally 控制块中进行解锁操作。

ReentrantLock 相比synchronized 的优势是可中断、公平锁、多个锁。这种情况下需要使用ReentrantLock。



自定义拓展一个 ReentrantLock：

```java
public class PauseControl extends ReentrantLock {
  private static final long serialVersionUID = 176912639934052187L;
  // 线程暂挂标志
  private volatile boolean suspended = false;
  private final Condition condSuspended = newCondition();

  /**
   * 暂停线程
   */
  public void requestPause() {
    suspended = true;
  }

  /**
   * 恢复线程
   */
  public void proceed() {
    lock();
    try {
      suspended = false;
      condSuspended.signalAll();
    } finally {
      unlock();
    }
  }

  /**
   * 当前线程仅在线程暂挂标记不为true的情况下才执行指定的目标动作。
   *
   * @targetAction 目标动作
   * @throws InterruptedException
   */
  public void pauseIfNeccessary(Runnable targetAction) throws InterruptedException {
    lock();
    try {
      while (suspended) {//如果线程挂起则进入等待状态
        condSuspended.await();
      }
      targetAction.run();
    } finally {
      unlock();
    }
  }
}
```

----

源码：

. 第一步。尝试去获取锁。如果尝试获取锁成功，方法直接返回。

```java
tryAcquire(arg)

final boolean nonfairTryAcquire(int acquires) {
  //获取当前线程
 final Thread current = Thread.currentThread();
 //获取state变量值
 int c = getState();
 if (c == 0) { //没有线程占用锁
   if (compareAndSetState(0, acquires)) {
   //占用锁成功,设置独占线程为当前线程
 setExclusiveOwnerThread(current);
  return true;
     }
} else if (current == getExclusiveOwnerThread()) { //当前线程已经占用该锁
  int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        // 更新state值为新的重入次数
        setState(nextc);
        return true;
    }
    //获取锁失败
    return false;
```

非公平锁tryAcquire的流程是：检查state字段，若为0，表示锁未被占用，那么尝试占用，若不为0，检查当前锁是否被自己占用，若被自己占用，则更新state字段，表示重入锁的次数。如果以上两点都没有成功，则获取锁失败，返回false。

2.<font color="red">第二步，入队。由于上文中提到线程A已经占用了锁，所以B和C执行tryAcquire失败，并且入等待队列。如果线程A拿着锁死死不放，那么B和C就会被挂起</font>

```java
/**
 * 将新节点和当前线程关联并且入队列
 * @param mode 独占/共享
 * @return 新节点
 */
private Node addWaiter(Node mode) {
    //初始化节点,设置关联线程和模式(独占 or 共享)
    Node node = new Node(Thread.currentThread(), mode);
    // 获取尾节点引用
    Node pred = tail;
    // 尾节点不为空,说明队列已经初始化过
    if (pred != null) {
        node.prev = pred;
        // 设置新节点为尾节点
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    // 尾节点为空,说明队列还未初始化,需要初始化head节点并入队新节点
    enq(node);
    return node;
}
```

B、C线程同时尝试入队列，由于队列尚未初始化，tail==null，故至少会有一个线程会走到enq(node)。我们假设同时走到了enq(node)里

```java
/**
 * 初始化队列并且入队新节点
 */
private Node enq(final Node node) {
    //开始自旋
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            // 如果tail为空,则新建一个head节点,并且tail指向head
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            // tail不为空,将新节点入队
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
```

这里体现了经典的自旋+CAS组合来实现非阻塞的[原子操作](https://so.csdn.net/so/search?q=原子操作&spm=1001.2101.3001.7020)。由于compareAndSetHead的实现使用了unsafe类提供的CAS操作，所以只有一个线程会创建head节点成功。假设线程B成功，之后B、C开始第二轮循环，此时tail已经不为空，两个线程都走到else里面。假设B线程compareAndSetTail成功，那么B就可以返回了，C由于入队失败还需要第三轮循环。最终所有线程都可以成功入队。

当B、C入等待队列后，此时AQS队列如下：

![image-20220209151926305](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220209151926305.png)

3.第三步，挂起。B和C相继执行acquireQueued(final Node node, int arg)。这个方法让已经入队的线程尝试获取锁，若失败则会被挂起。

```java
/**
 * 已经入队的线程尝试获取锁
 */
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true; //标记是否成功获取锁
    try {
        boolean interrupted = false; //标记线程是否被中断过
        for (;;) {
            final Node p = node.predecessor(); //获取前驱节点
            //如果前驱是head,即该结点已成老二，那么便有资格去尝试获取锁
            if (p == head && tryAcquire(arg)) {
                setHead(node); // 获取成功,将当前节点设置为head节点
                p.next = null; // 原head节点出队,在某个时间点被GC回收
                failed = false; //获取成功
                return interrupted; //返回是否被中断过
            }
            // 判断获取失败后是否可以挂起,若可以则挂起
            if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                // 线程若被中断,设置interrupted为true
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
    //这⾥parkAndCheckInterrupt⽅法内部使⽤到了LockSupport.park(this)，顺便简单介绍⼀下park。LockSupport类是Java 6 引⼊的⼀个类，提供了基本的线程同步原语。LockSupport实际上是调⽤了Unsafe类⾥的函数，归结到Unsafe⾥，只有两个函数：park(boolean isAbsolute, long time)：阻塞当前线程unpark(Thread jthread)：使给定的线程停⽌阻塞
}
```

code里的注释已经很清晰的说明了acquireQueued的执行流程。假设B和C在竞争锁的过程中A一直持有锁，那么它们的tryAcquire操作都会失败，因此会走到第2个if语句中。我们再看下shouldParkAfterFailedAcquire和parkAndCheckInterrupt都做了哪些事吧。

```java
/**
 * 判断当前线程获取锁失败之后是否需要挂起.
 */
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    //前驱节点的状态
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)
        // 前驱节点状态为signal,返回true
        return true;
    // 前驱节点状态为CANCELLED
    if (ws > 0) {
        // 从队尾向前寻找第一个状态不为CANCELLED的节点
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus > 0);
        pred.next = node;
    } else {
        // 将前驱节点的状态设置为SIGNAL
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}
  
/**
 * 挂起当前线程,返回线程中断状态并重置
 */
private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this);
    return Thread.interrupted();
}
```

线程入队后能够挂起的前提是，它的前驱节点的状态为SIGNAL，它的含义是“Hi，前面的兄弟，如果你获取锁并且出队后，记得把我唤醒！”。所以shouldParkAfterFailedAcquire会先判断当前节点的前驱是否状态符合要求，若符合则返回true，然后调用parkAndCheckInterrupt，将自己挂起。如果不符合，再看前驱节点是否>0(CANCELLED)，若是那么向前遍历直到找到第一个符合要求的前驱，若不是则将前驱节点的状态设置为SIGNAL。

   整个流程中，如果前驱结点的状态不是SIGNAL，那么自己就不能安心挂起，需要去找个安心的挂起点，同时可以再尝试下看有没有机会去尝试竞争锁。

  最终队列可能会如下图所示

![image-20220209152503986](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220209152503986.png)

![image-20220302230610158](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220302230610158.png)

释放锁：

```java
public void unlock() {
    sync.release(1);
}
  
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}
```

如果理解了加锁的过程，那么解锁看起来就容易多了。流程大致为先尝试释放锁，若释放成功，那么查看头结点的状态是否为SIGNAL，如果是则唤醒头结点的下个节点关联的线程，如果释放失败那么返回false表示解锁失败。这里我们也发现了，每次都只唤起头结点的下一个节点关联的线程。

  最后我们再看下tryRelease的执行过程

```java
/**
 * 释放当前线程占用的锁
 * @param releases
 * @return 是否释放成功
 */
protected final boolean tryRelease(int releases) {
    // 计算释放后state值
    int c = getState() - releases;
    // 如果不是当前线程占用锁,那么抛出异常
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        // 锁被重入次数为0,表示释放成功
        free = true;
        // 清空独占线程
        setExclusiveOwnerThread(null);
    }
    // 更新state值
    setState(c);
    return free;
}
```

用一张流程图总结一下非公平锁的获取锁的过程。 

![image-20220209153016100](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220209153016100.png)



## 公平与非公平锁的实现

我们再来看看公平锁的实现：即使state=0，也不会立马进行CAS操作，还会进行一个hasQueuedPredecessors（判断自己是否需要排队）的判断。

```
static final class FairSync extends Sync {
        private static final long serialVersionUID = -3000897897090466540L;

        final void lock() {
            acquire(1);
        }

        /**
         * Fair version of tryAcquire.  Don't grant access unless
         * recursive call or no waiters or is first.
         */
        protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (!hasQueuedPredecessors() &&
                    compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0)
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
    }
```

hasQueuedPredecessors

hasQueuedPredecessors()是AbstractQueuedSynchronizer类的一个方法。

**AQS（AbstractQueuedSynchronizer）类的设计**

```
private transient volatile Node head;  // 队首
private transient volatile Node tail;  // 队尾 
private volatile int state;  // 锁状态，加锁成功则为1，重入++1，解锁则为0
```

**Node类的设计**

```
public class Node {
   volatile Node prev;
   volatile Node next;
   volatile Thread thread;
}
```

![image-20220105234525295](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105234525295.png)

**hasQueuedPredecessors()方法**



```java
// 判断自己要不要排队
public final boolean hasQueuedPredecessors() {
        // The correctness of this depends on head being initialized
        // before tail and on head.next being accurate if the current
        // thread is first in queue.
        Node t = tail; // Read fields in reverse initialization order
        Node h = head;
        Node s;
        return h != t &&
            ((s = h.next) == null || s.thread != Thread.currentThread());
    }
```

【上锁过程重点】

- 锁对象：其实就是ReentrantLock的实例对象
- 自由状态：自由状态表示锁对象没有被别的线程持有，计数器为0
- 计数器：再lock对象中有一个字段state用来记录上锁次数，比如lock对象是自由状态则state为0，如果大于零则表示被线程持有了，当然也有重入那么state则>1
- waitStatus：仅仅是一个状态而已；ws是一个过渡状态，在不同方法里面判断ws的状态做不同的处理，所以ws=0有其存在的必要性
- tail：队列的队尾
- head：队列的对首
- ts：第二个给lock加锁的线程
- tf：第一个给lock加锁的线程
- tc：当前给线程加锁的线程
- tl：最后一个加锁的线程
- tn：随便某个线程 当然这些线程有可能重复，比如第一次加锁的时候tf==tc==tl==tn
- 节点：就是上面的Node类的对象，里面封装了线程，所以某种意义上node就等于一个线程

【不需要排队的两种情况】

1. 队列没有初始化，则不需要排队，直接去加锁，但是可能会失败；为什么会失败呢？ 假设两个线程同时来lock，都看到队列没有初始化，都认为不需要排队，都去进行CAS修改计数器；但是肯定有一个会失败，这个时候他就会初始化队列并排队。
2. 队列被初始化了，但是当前线程过来加锁，发觉队列当中头结点h就是自己，比如重入，因此不需要排队。

【`h != t` 判断首不等于尾这里要分三种情况】

1. 队列没有初始化，也就是第一个线程来加锁，h和t都是null，&&运算所以后面不执行，直接返回false，但是这个方法取反了，所以会直接去cas加锁。总结起来就是队列没有初始化，没人排队，那么我也不需要排队，直接上锁，直接去看能不能办理业务。

![image-20220105234650193](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105234650193.png)

2. 如果队列被初始化那么`h!=t`则成立，`h!=t` 返回true；但是是&&运算，故而还需要进行后续的判断 ，（有人可能会疑问，比如队列里面只有一个数据，那么头和尾都是同一个，`h!=t`怎么会成立呢？其实这是第三种情况--队列里面只有一个数据；这里先不考虑，假设现在队列里面有大于1个数据），继续判断把`h.next`赋值给s；s如果是头的下一个，则表示它是队列当中参与排队的线程而且是排在最前面的；为什么是s最前面不是h嘛？诚然h是队列里面的第一个，但是不是排队的第一个；因为h是持有锁的，但是不参与排队；这个也很好理解，比如你去买火车票，你如果是第一个这个时候售票员已经在给你服务了，你不算排队，你后面的才算排队。然后判断s是否等于空，其实就是判断队列里面是否只有一个数据；假设队列大于1个，那么肯定不成立（`s==null`---->false），因为大于一个`h.next`肯定不为空；由于是||运算如果返回false，还要判断`s.thread != Thread.currentThread()`；这里又分为两种情况：

- **2.1** `s.thread != Thread.currentThread()` 返回true，就是当前线程不等于在排队的第一个线程s。那么这个时候整体结果就是`h!=t：true`;（`s==null false` || `s.thread != Thread.currentThread() true`），方法结果最终返回true，那么去则需要去排队。其实这样符合情理，队列不为空，有人在排队，而且第一个排队的人和现在来参与竞争的人不是同一个，那么你就乖乖去排队。
- **2.2** `s.thread != Thread.currentThread()` 返回false，表示当前来参与竞争锁的线程和第一个排队的线程是同一个线程。那么这个时候整体结果就是`h!=t：true`; （`s==null false` || `s.thread != Thread.currentThread() false`），方法结果最终返回false，那么去则不需要去排队。不需要排队则调用`compareAndSetState(0, acquires)`去改变计数器尝试上锁；这里又分为两种情况：
- - **2.2.1** 第一种情况加锁成功？有人会问为什么会成功啊，很简单假如这个时候h也就是持有锁的那个线程执行完了，释放锁了，那么肯定成功啊；成功则执行 setExclusiveOwnerThread(current); 然后返回true 。
- - **2.2.2** 第二种情况加锁失败？有人会问为什么会失败啊。很简单假如这个时候h也就是持有锁的那个线程没执行完，没释放锁，那么肯定失败啊；失败则直接返回false，不会进else if。总结起来就是如果队列被初始化了，而且至少有一个人在排队那么自己也去排队；但是他会去看看那个第一个排队的人是不是自己，如果是自己那么他就去尝试加锁；尝试看看锁有没有释放。

3. 队列被初始化了，但是里面只有一个数据，什么情况下才会出现这种情况呢？可能有人会说ts加锁的时候里面就只有一个数据；其实不是，因为队列初始化的时候会虚拟一个h作为头结点，当前线程作为第一个排队的节点， 并且**AQS认为h永远是不排队的**。为什么这么做呢？假设你不虚拟节点出来那么ts就是h，因为这个时候tf可能没有执行完，ts得不到锁，故而ts其实需要排队的。那么为什么要虚拟为什么ts不直接排在tf之后呢？上面已经时说明白了，tf来上锁的时候队列都没有，它不进队列，故而ts无法排在tf之后，只能虚拟一个null节点出来。那么问题来了，究竟什么时候才会出现队列当中只有一个数据呢？假设原先队列里面有5个人在排队，当前面4个都执行完了，轮到第5个线程得到锁的时候，它会把自己设置成为头部，而尾部又没有，故而队列当中只有一个h就是第5个。至于为什么需要把自己设置成头部；其实已经解释了，因为这个时候第5个线程已经不排队了，它拿到锁了，所以它不参与排队，故而需要设置成为h。所以这个时间内，队列当中只有一个节点。这个时候队列已经初始化了，但是只有一个数据，并且这个数据所代表的线程是持有锁 。`h != t false` 由于后面是&&运算，故而返回false可以不参与运算，整个方法返回false；不需要排队。

![image-20220105234743641](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105234743641.png)

![image-20220105234814130](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105234814130.png)

t2入队，维护链表，告诉自己上、下一个节点是谁

**加锁过程总结**

如果是第一个线程tf，那么和队列无关，线程直接持有锁。并且也不会初始化队列，如果接下来的线程都是交替执行，那么永远和AQS队列无关，都是直接线程持有锁。

![image-20220105235207630](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105235207630.png)



> 所以在JDK1.6之前，ReentrantLock比synchronized关键字好的地方在于，假设线程都是交替执行，那么ReentrantLock肯定比synchronized关键字快。因为即使只有一个线程（没有高并发的情况下），synchronized关键字都要调用OS函数，性能低下，所以synchronized关键字是**重量级锁**；而使用ReentrantLock，那么所有代码都是在JDK内部解决的。

如果发生了竞争，比如tf持有锁的过程中T2来lock，那么这个时候就会初始化AQS，初始化AQS的时候会在队列的头部虚拟一个Thread为NULL的Node，因为队列当中的head永远是持有锁的那个node（除了第一次会虚拟一个，其他时候都是持有锁的那个线程锁封装的node），现在第一次的时候持有锁的是tf，而tf不在队列当中所以虚拟了一个node节点。队列当中的除了head之外的所有的node都在park，当tf释放锁之后unpark某个node之后（基本是队列当中的第二个，为什么是第二个呢？前面说过head永远是持有锁的那个node，当有时候也不会是第二个，比如第二个被cancel之后，至于为什么会被cancel，不在我们讨论范围之内，cancel的条件很苛刻，基本不会发生），node被唤醒。假设node是t2，那么这个时候会首先把t2变成head（sethead），在sethead方法里面会把t2代表的node设置为head，并且把node的Thread设置为null，为什么需要设置null？其实原因很简单，现在t2已经拿到锁了，node就不要排队了，那么node对Thread的引用就没有意义了。所以队列的head里面的Thread永远为null。



## lock的一些方法



Lock 接口的主要方法：

1. void lock(): 执行此方法时, 如果锁处于空闲状态, 当前线程将获取到锁. 相反, 如果锁已经
   被其他线程持有, 将禁用当前线程, 直到当前线程获取到锁.
2. boolean tryLock()：如果锁可用, 则获取锁, 并立即返回true, 否则返回false. 该方法和
   lock()的区别在于, tryLock()只是"试图"获取锁, 如果锁不可用, 不会导致当前线程被禁用,当前线程仍然继续往下执行代码. 而lock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行.

2）方法boolean tryLock（）的作用是，仅在调用时锁定未被另一个线程保持的情况下，才获取该锁定。 

创建测试用的项目tryLockTest，类MyService.java代码如下： 

```java
package service;
import java.util.concurrent.locks.ReentrantLock;
public class MyService {
public ReentrantLock lock = new ReentrantLock();
public void waitMethod() {
  if (lock.tryLock()) {
    System.out.println(Thread.currentThread().getName() + "获得锁");
  } else {
    System.out.println(Thread.currentThread().getName() + "没有获得锁");
  }
}
```


运行类代码如下：

```java
package test;
import service.MyService;
public class Run {
public static void main(String[] args) throws InterruptedException {
  final MyService service = new MyService();
  Runnable runnableRef = new Runnable() {
    @Override
    public void run() {
      service.waitMethod();
    }
  };
  Thread threadA = new Thread(runnableRef);
  threadA.setName("A");
  threadA.start();
  Thread threadB = new Thread(runnableRef);
  threadB.setName("B");
  threadB.start();
}
}

1
```

1. void unlock()：执行此方法时, 当前线程将释放持有的锁. 锁只能由持有者释放, 如果线程
   并不持有锁, 却执行该方法, 可能导致异常的发生.
2. Condition newCondition()：条件对象，获取等待通知组件。该组件和当前的锁绑定，
   当前线程只有获取了锁，才能调用该组件的await()方法，而调用后，当前线程将缩放锁。
3. getHoldCount() ：查询当前线程保持此锁的次数，也就是执行此线程执行lock 方法的次
   数。
4. getQueueLength（）：返回正等待获取此锁的线程估计数，比如启动10 个线程，1 个
   线程获得锁，此时返回的是9
5. getWaitQueueLength：（Condition condition）返回等待与此锁相关的给定条件的线
   程估计数。比如10 个线程，用同一个condition 对象，并且此时这10 个线程都执行了
   condition 对象的await 方法，那么此时执行此方法返回10
6. hasWaiters(Condition condition) ： 查询是否有线程等待与此锁有关的给定条件
   (condition)，对于指定contidion 对象，有多少线程执行了condition.await 方法
7. hasQueuedThread(Thread thread)：查询给定线程是否等待获取此锁
8. hasQueuedThreads()：是否有线程等待此锁
9. isFair()：该锁是否公平锁
10. isHeldByCurrentThread()： 当前线程是否保持锁锁定，线程的执行lock 方法的前后分
    别是false 和true
11. isLock()：此锁是否有任意线程占用
12. lockInterruptibly（）：如果当前线程未被中断，获取锁
13. tryLock（）：尝试获得锁，仅在调用时锁未被线程占用，获得锁
14. tryLock(long timeout TimeUnit unit)：如果锁在给定等待时间内没有被另一个线程保持，则获取该锁。
15. Condition 类的awiat 方法和Object 类的wait 方法等效
16. Condition 类的signal 方法和Object 类的notify 方法等效
17. Condition 类的signalAll 方法和Object 类的notifyAll 方法等效
18. ReentrantLock 类可以唤醒指定条件的线程，而object 的唤醒是随机的



## ReadWriteLock 读写锁

ReadWriteLock 读写锁

首先明确一下，不是说ReentrantLock 不好，只是ReentrantLock 某些时候有局限。如果使用ReentrantLock，可能本身是为了防止线程A 在写数据、线程B 在读数据造成的数据不一致，但这样， 如果线程C 在读数据、线程D 也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。因为这个，才诞生了读写锁ReadWriteLock。ReadWriteLock 是一个读写锁接口，ReentrantReadWriteLock 是ReadWriteLock 接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。

读写锁演变：

![image-20210829204615409](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210829204615409.png)





在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm 自己控制的，你只要上好相应的锁即可。

读锁
如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁
写锁
如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！
Java 中读写锁有个接口java.util.concurrent.locks.ReadWriteLock ， 也有具体的实现ReentrantReadWriteLock。

![image-20210813092621040](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813092621040.png)

jdk8中可以将写锁降级为读锁，但读锁不可以升级为写锁

![image-20210829204711775](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210829204711775.png)



## 读写互斥代码

4.2.3　类ReentrantReadWriteLock的使用：读写互斥

 创建Java项目ReadWriteLockBegin3，将ReadWriteLockBegin2中的所有源代码复制到项目ReadWriteLockBegin3中。 更改类Service.java代码如下： 

```java
package service;
import java.util.concurrent.locks.ReentrantReadWriteLock;
public class Service {
private ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
public void read() {
  try {
    try {
      lock.readLock().lock();
      System.out.println("获得读锁" + Thread.currentThread().getName()
          \+ " " + System.currentTimeMillis());
      Thread.sleep(10000);
    } finally {
      lock.readLock().unlock();
    }
  } catch (InterruptedException e) {
    e.printStackTrace();
  }
}
public void write() {
  try {
    try {
      lock.writeLock().lock();
      System.out.println("获得写锁" + Thread.currentThread().getName()
          \+ " " + System.currentTimeMillis());
      Thread.sleep(10000);
    } finally {
      lock.writeLock().unlock();
    }
  } catch (InterruptedException e) {
    e.printStackTrace();
  }
}
```




} 运行类Run.java代码更改如下： 

```java
package test;
import service.Service;
import extthread.ThreadA;
import extthread.ThreadB;
public class Run {
public static void main(String[] args) throws InterruptedException {
  Service service = new Service();
  ThreadA a = new ThreadA(service);
  a.setName("A");
  a.start();
  Thread.sleep(1000);
  ThreadB b = new ThreadB(service);
  b.setName("B");
  b.start();
}
}
```



此实验说明“读写”操作是互斥的，而且下一个示例说明“写读”操作也是互斥的。

```java
package test;
import service.Service;
import extthread.ThreadA;
import extthread.ThreadB;
public class Run {
public static void main(String[] args) throws InterruptedException {
  Service service = new Service();
  ThreadB b = new ThreadB(service);
  b.setName("B");
  b.start();
  Thread.sleep(1000);
  ThreadA a = new ThreadA(service);
  a.setName("A");
  a.start();
}
```





即只要出现“写操作”的过程，就是互斥的。： 

## tryLock 和lock 和lockInterruptibly 的区别

1. tryLock 能获得锁就返回true，不能就立即返回false，tryLock(long timeout,TimeUnitunit)，可以增加时间限制，如果超过该时间段还没获得锁，返回false
2. lock 能获得锁就返回true，不能的话一直等待获得锁
3. lock 和lockInterruptibly，如果两个线程分别执行这两个方法，但此时中断这两个线程，lock 不会抛出异常，而lockInterruptibly 会抛出异常。

## 什么是CAS



常见的lock free编程一般是基于CAS(Compare And Swap)操作：CAS(void *ptr, Any oldValue, Any newValue);
即查看内存地址ptr处的值，如果为oldValue则将其改为newValue，并返回true，否则返回false。X86平台上的CAS操作一般是通过CPU的CMPXCHG指令来完成的。CPU在执行此指令时会首先锁住CPU总线，禁止其它核心对内存的访问，然后再查看或修改*ptr的值。**简单的说CAS利用了CPU的硬件锁来实现对共享资源的串行使用。**，x86 指令集中有 **cmpxchg** 指令完成 CAS 功能

CAS 是compare and swap 的缩写， 即我们所说的比较交换。

实现原理： cas并发原语体现在java语言中就是sum.misc.Unsafe类中的各个方法，调用unsafe类中的cas方法jvm会帮我们实现cas汇编指令。这是一种完全依赖于硬件的功能，通过它实现了原子操作，由于cas是一种系统原语，原语属于操作系统用语的范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，执行过程中不允许被中断，也就是说cas是一条cpu原子指令，不会造成所谓数据不一致问题。

CAS 中有Unsafe 类中的compareAndSwapInt 方法， Unsafe 类中的compareAndSwapInt，是一个本地方法，该方法的实现位于unsafe.cpp 中
Unsafe.cpp:
先想办法拿到变量value 在内存中的地址。
通过Atomic::cmpxchg 实现比较替换，其中参数x 是即将更新的值，参数e 是原内存的值。
其中Atomic::cmpxchg 中对此指令加lock 前缀，而lock 前缀有两个特性1，禁止该指令与前面和后面的读写指令重排序

2，把写缓冲区的所有数据刷新到内存中
**这两点保证了内存屏障效果，保证了CAS 同时具有volatile 读和volatile 写的内存语义。**

源码位置：`hotspot/src/share/vm/prims/unsafe.cpp`

```javascript
#define FN_PTR(f) CAST_FROM_FN_PTR(void*, &f)

{CC"compareAndSwapObject", CC"("OBJ"J"OBJ""OBJ")Z",  FN_PTR(Unsafe_CompareAndSwapObject)},

{CC"compareAndSwapInt",  CC"("OBJ"J""I""I"")Z",      FN_PTR(Unsafe_CompareAndSwapInt)},

{CC"compareAndSwapLong", CC"("OBJ"J""J""J"")Z",      FN_PTR(Unsafe_CompareAndSwapLong)},
```

上述三个方法，最终在 hotspot 源码实现中都会调用统一的 **cmpxchg** 函数，可以在 hotspot 源码中找到核心代码。

cas 是一种基于锁的操作， 而且是乐观锁。在java 中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后， 下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源， 比如通过给记录加version 来获取数据， 性能较悲观锁有很大的提高。

![image-20220324205043489](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220324205043489.png)

CAS算法是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数
需要读写的内存值 V
进行比较的值 A
拟写入的新值 B

(或者说：1. 变量内存地址，V表示

2. 旧的预期值，A表示
3. 准备设置的新值，B表示)

当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试



当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（**比较和替换是一个原子操作**）。一般情况下是一个自旋操作，即不断的重试。

CAS 操作包含三个操作数—— 要更新的变量（ V）、预期原值（A）和新值(B)。如果内存地址里面的值和A 的值是一样的，那么就将内存里面的值更新成B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a 线程获取地址里面的值被b 线程修改了（要更新的变量被修改了）， 那么a 线程需要自旋，到下次循环才有可能机会执行。

1. 如果有⼀个多个线程共享的变量 i 原本等于5，我现在在线程A中，想把它设置为新的值6;
2. 我们使⽤CAS来做这个事情；
3. ⾸先我们⽤i去与5对⽐，发现它等于5，说明没有被其它线程改过，那我就把它设置为新的值6，此次CAS成功， i 的值被设置成了6；
4. 如果不等于5，说明 i 被其它线程改过了（⽐如现在 i 的值为2），那么我就什么也不做，此次CAS失败， i 的值仍然为2。

java.util.concurrent.atomic 包下的类大多是使用CAS 操作来实现的
( AtomicInteger,AtomicBoolean,AtomicLong)。

<font color="red"> CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功。</font>

CAS 机制所保证的是一个变量的原子性操作，而不能保证整个代码块的原子性。（比较和交换是一个原子操作）
比如需要保证3 个变量共同进行原子性的更新， 就不得不使用synchronized 了。
CAS 造成CPU 利用率增加（原因：长时间自旋可能导致开销大，假如CAS长时间不成功会一直自旋，会给CPU带来很大的开销）
之前说过了CAS 里面是一个循环判断的过程，如果线程一直没有获取到状态，cpu资源会一直被占用。

**自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销**。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

1、synchronized 是悲观锁，属于抢占式，会引起其他线程阻塞。
2、volatile 提供多线程共享变量可见性和禁止指令重排序优化。
3、CAS 是基于冲突检测的乐观锁（ 非阻塞）

![image-20230213180338761](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20230213180338761.png)

Unsafe类中的compareAndSwapInt，是一个本地方法，该方法的实现位于`unsafe.cpp`中



```c
UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x))
  UnsafeWrapper("Unsafe_CompareAndSwapInt");
  oop p = JNIHandles::resolve(obj);
  jint* addr = (jint *) index_oop_from_field_offset_long(p, offset);
  return (jint)(Atomic::cmpxchg(x, addr, e)) == e;
UNSAFE_END
```

1. 先想办法拿到变量value在内存中的地址。
2. 通过`Atomic::cmpxchg`实现比较替换，其中参数x是即将更新的值，参数e是原内存的值。



----------------------------------

![image-20210813090235909](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813090235909.png)

CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.**所以我们可以使用锁（同一时间只有一个线程能访问代码块）或者利用AtomicReference类把多个共享变量合并成一个共享变量（相当于把多个变量放到一个对象里面）来操作。**

![image-20210920170601129](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210920170601129.png)

比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。**从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。**

Java中有AtomicStampedReference来解决这个问题，**他加入了预期标志和更新后标志两个字段**，更新时不光检查当前值是否等于预期值，还要检查当前的标志是否等于预期标志，全部相等的话才会更新。

**循环时间长问题**：作为乐观锁的一种实现，当多线程竞争资源激烈的情况下，而且锁定的资源处理耗时，那么其他线程就要考虑自旋的次数限制，避免过度的消耗 CPU。另外，可以考虑上文示例代码中提到的 LongAdder 来解决，以空间换时间的方式，来解决 CAS 大量失败后长时间占用 CPU 资源，加大了系统性能开销的问题。JDK1.8新增一个[原子性](https://so.csdn.net/so/search?q=原子性&spm=1001.2101.3001.7020)操作类LongAdder，用于代替AtomicLong的功能，因为在非常高并发的请求下，AtomicLong的性能是一个很大的瓶颈，因为AtomicLong采用的CAS算法失败后还是通过无限循环的自旋锁不断的尝试。

AtomicLong 是基于 CAS 方式自旋更新的；LongAdder 是把 value 分成若干cell，并发量低的时候，直接 CAS 更新值，成功即结束。并发量高的情况，CAS更新某个cell值和需要时对cell数据扩容，成功结束；更新失败自旋 CAS 更新 cell值。取值的时候，调用 sum() 方法进行每个cell累加。

AtomicLong 包含有原子性的读、写结合的api；LongAdder 没有原子性的读、写结合的api，能保证结果最终一致性。
低并发场景AtomicLong 和 LongAdder 性能相似，高并发场景 LongAdder 性能优于 AtomicLong。

**解决cas只能保证一个共享变量的原子性**：可以将多个共享变量封装成一个类再使用原子引用来解决问题

1.
对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。
2.
对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。
📣📣📣补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 **Lock-Free** 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。**在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。**



## jvm对java原生锁做了哪些优化

![image-20210812234715160](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210812234715160.png)

![image-20210812234824877](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210812234824877.png)





## AQS框架是什么

AQS是 AbstractQueuedSynchronizer 的简称，即 抽象队列同步器 ，从字⾯意思上理解:
抽象：抽象类，只实现⼀些主要逻辑，有些⽅法由⼦类实现；
队列：使⽤先进先出（FIFO）队列存储数据；
同步：实现了同步的功能。
那AQS有什么⽤呢？AQS是⼀个⽤来构建锁和同步器的框架，使⽤AQS能简单且⾼效地构造出应⽤⼴泛的同步器，⽐如我们提到的ReentrantLock，Semaphore，ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。

[AQS底层原理及源码分析详解_m0_46566541的博客-CSDN博客_aqs底层原理](https://blog.csdn.net/m0_46566541/article/details/119141525)

![image-20220204132029307](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220204132029307.png)

**AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。**

CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。

AQS内部使⽤了⼀个volatile的变量state来作为资源的标识，也即表示同步状态。当线程调用 lock 方法时 ，如果 state=0，说明没有任何线程占有共享资源的锁，可以获得锁并将 state=1；如果 state=1，则说明有线程目前正在使用共享变量，其他线程必须加入同步队列进行等待。

AQS 通过 Node 内部类构成的一个双向链表结构的同步队列，来完成线程获取锁的排队工作，当有线程获取锁失败后，就被添加到队列末尾。  Node 类是对要访问同步代码的线程的封装，包含了线程本身及其状态叫 waitStatus（有五种不同 取值，分别表示是否被阻塞，是否等待唤醒，是否已经被取消等），每个 Node 结点关联其 prev 结点和 next 结点，方便线程释放锁后快速唤醒下一个在等待的线程，是一个 FIFO 的过程。 o Node 类有两个常量，SHARED 和 EXCLUSIVE，分别代表共享模式和独占模式。所谓共享模式是一个锁允许多条线程同时操作（信号量Semaphore 就是基于 AQS 的共享模式实现的），独占模式是同一个时间段只能有一个线程对共享资源进行操作，多余的请求线程需要排队等待（如 ReentranLock）。

AQS 通过内部类 ConditionObject 构建等待队列（可有多个），当 Condition 调用 wait() 方法后，线程将会加入等待队列中，而当 Condition 调用 signal() 方法后，线程将从等待队列转移动同步队列中进行锁竞争。

AQS 和 Condition 各自维护了不同的队列，在使用 Lock 和 Condition 的时候，其实就是两个队列的互相移动。

同时定义了⼏个获取和修改state的protected⽅法，⼦类可以覆盖这些⽅法来实现⾃⼰的逻辑：
getState()
setState()
compareAndSetState()

以上三种操作都是原子操作

1、AQS是一个JAVA线程同步的框架。是JDK中很多锁工具的核心实现框架。
2、在AQS中,维护了一个信号量 state和一个线程组成的双向链表队列（CLH）。其中,这个线程队列,是用来给线程排队的,而state就像是一个红绿灯,用来控制线程排队或放行的。在不同的场景下,有不用的意义。

private volatile int state;//共享变量，使用volatile修饰保证线程可见性



在可重入锁这个场景下,以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。

```java
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();//如果获取资源失败，就通过addWaiter(Node.EXCLUSIVE)⽅法把这个线程插⼊到等待队列中
}
//当然，获取资源的⽅法除了acquire外，还有以下三个：
acquireInterruptibly：申请可中断的资源（独占模式）
acquireShared：申请共享模式的资源
acquireSharedInterruptibly：申请可中断的资源（共享模式）
可中断的意思是，在线程中断时可能会抛出 InterruptedException
    
    
```

再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。

状态信息通过procted类型的getState，setState，compareAndSetState进行操作

```java
//返回同步状态的当前值
protected final int getState() {  
        return state;
}
 // 设置同步状态的值
protected final void setState(int newState) { 
        state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
```

==AQS具备特性==
阻塞等待队列
共享/独占
公平/非公平
可重入
允许中断

除了Lock外，Java.concurrent.util当中同步器的实现如Latch,Barrier,BlockingQueue等，
都是基于AQS框架实现
一般通过定义内部类Sync继承AQS
将同步器所有调用都映射到Sync对应的方法

state表示资源的可用状态
State三种访问方式:getState()、setState()、compareAndSetState()
AQS定义两种资源共享方式:

<font color="blue">Exclusive-独占，只有一个线程能执行，如ReentrantLock</font>

<font color="blue">Share-共享，多个线程可以同时执行，如Semaphore/CountDownLatch 。</font>

AQS中关于这两种资源共享模式的定义源码（均在内部类Node中）。我们来看看Node的结构：

```java
static final class Node {
// 标记⼀个结点（对应的线程）在共享模式下等待
static final Node SHARED = new Node();
// 标记⼀个结点（对应的线程）在独占模式下等待
static final Node EXCLUSIVE = null;
// waitStatus的值，表示该结点（对应的线程）已被取消
static final int CANCELLED = 1;
// waitStatus的值，表示后继结点（对应的线程）需要被唤醒
static final int SIGNAL = -1;
// waitStatus的值，表示该结点（对应的线程）在等待某⼀条件
static final int CONDITION = -2;
/*waitStatus的值，表示有资源可⽤，新head结点需要继续唤醒后继结点*/（共享模式下，多线程并
static final int PROPAGATE = -3;
// 等待状态，取值范围，-3，-2，-1，0，1
volatile int waitStatus;
volatile Node prev; // 前驱结点
volatile Node next; // 后继结点
volatile Thread thread; // 结点对应的线程
Node nextWaiter; // 等待队列⾥下⼀个等待条件的结点
// 判断共享模式的⽅法
final boolean isShared() {
return nextWaiter == SHARED;
}
Node(Thread thread, Node mode) { // Used by addWaiter
this.nextWaiter = mode;
this.thread = thread;
}
// 其它⽅法忽略，可以参考具体的源码
}
// AQS⾥⾯的addWaiter私有⽅法
private Node addWaiter(Node mode) {
// 使⽤了Node的这个构造函数
Node node = new Node(Thread.currentThread(), mode);
// 其它代码省略
}
```



==AQS定义两种队列==
注意：通过Node我们可以实现两个队列，⼀是通过prev和next实现CLH队列(线程同步队列,双向队列)，⼆是nextWaiter实现Condition条件上的等待线程队列(单向队列)，这个Condition主要⽤在ReentrantLock类中。

Condition接口的主要实现类是AQS的内部类`ConditionObject`，**每个Condition对象都包含一个等待队列**。该队列是Condition对象实现等待/通知的关键。

调用condition的await方法，将会使当前线程进入等待队列并释放锁(先加入等待队列再释放锁)，同时线程状态转为等待状态.

调用condition的signal方法时，将会把等待队列的首节点移到同步队列的尾部，然后唤醒该节点。
被唤醒，并不代表就会从await方法返回，也不代表该节点的线程能获取到锁，它一样需要加入到锁的竞争acquireQueued方法中去，只有成功竞争到锁，才能从await方法返回。

1、Condition是个接口，基本的方法就是await()和signal()方法。

2、Condition依赖于Lock接口，生成一个Condition的基本代码是lock.newCondition()，

![image-20220218025423692](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220218025423692.png)

不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。

**AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法：**
isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。

AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。

AQS实际上以双向队列的形式连接所有的Entry，比方说ReentrantLock，所有等待的线程都被放在一个Entry中并连成双向队列，前面一个线程使用ReentrantLock好了，则双向队列实际上的第一个Entry开始运行。
AQS定义了对双向队列所有的操作，而只开放了tryLock和tryRelease方法给开发者使用，开发者可以根据自己的实现重写tryLock和tryRelease方法，以实现自己的并发功能。

AQS内部用一个volatile修饰的int类型的成员变量state来控制同步状态。

- **state = 0：表示没有线程正在独占共享资源的锁。**
- **state = 1：表示有线程正在共享资源的锁。**

AQS虽说是一个抽象类，但是其内部没有一个方法是抽象方法，因为AQS只是基础的组件，作者并不希望使用者对其直接进行操作，更倾向于其作为基础组件，为其实现类提供基础的帮助。

AQS采用的是模板方法模式，其内部除了提供并发的操作核心方法以及同步队列的操作之外，还提供了一些模板方法让子类自己实现，如加锁解锁。

AQS作为基础的组件，封装的都是核心的并发操作，实际上还分为两种模式，共享模式和独占模式，如Reentrantlock，ReentrantReadWriteLock（写锁部分）都是独占锁，ReentrantReadWriteLock（读锁部分）就是共享锁。
这两种模式的解锁和加锁逻辑都不一样，但是AQS只关注内部的公共方法的实现，不关心外部的具体实现，所以提供了模板方法给子类。

要实现独占模式，则需要实现tryAcquire（加锁）和tryRelease（解锁），而实现共享模式则需要实现tryAcquireShared（加锁）和tryReleaseShared（解锁），无论是共享模式还是独占模式，其底层实现都是同一个AQS，只是加锁和解锁逻辑不一样，所以，根据自己的需求自定义锁也就变得简单。

看看AQS提供的5个模板方法：

![image-20211224130633343](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211224130633343.png)

AQS的作用基本有了概念，那么AQS到底怎么工作的呢？
先来看看它的内部类：Node

![image-20211224130707412](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211224130707412.png)




有的属性基本看注释就能看懂啥意思，让我们看看waitStatus的5个常数的含义

CANCELLED：值为1，在同步队列中等待超时或被中断，需要从同步队列中取消该Node的节点，其节点的waitStatus为CANCELLED，即结束状态，进入该状态后的节点将不会再变化。
SIGNAL：值为-1，被标识为该等待唤醒状态的后序结点，当其前序节点的线程释放了同步锁被取消，将会通知该节点的后序节点的线程执行。就是处于唤醒状态，只要前序节点释放锁，就会通知标识为SIGNAL状态的后序节点的线程执行。
CONDITION：值为-2，与Condition相关，该标识的节点处于等待队列中（后面会说）节点的线程等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的节点将从等待队列转移到同步队列中，等待获取同步锁。
PROPAGATE：值为-3，与共享模式相关，在共享模式中，该状态标识节点的线程处于可运行状态。
0状态：值为0，代表初始状态

为了方便理解，这边加入Reentrantlock子类实现代码

```java
final void lock() {
	//cas操作设置state的值，如果state为0，则说明当前共享资源没有线程占用，设置为1，成功后设置独占线程为当前线程。
     if (compareAndSetState(0, 1))
         setExclusiveOwnerThread(Thread.currentThread());
     else
     //如果state不为0，则说明有线程独占了，进入AQS核心方法，上图可见，随后进入tryAcquire方法
         acquire(1);
}

//这是子类具体实现方法实现锁的逻辑，进入nonfairTryAcquire方法
protected final boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires);
}

//acquires = 1
final boolean nonfairTryAcquire(int acquires) {
	//获取当前线程
    final Thread current = Thread.currentThread();
    //获取state状态
    int c = getState();
    //如果状态为0，跟之前一样，则进入cas设置，并将独占线程设置为自己，返回true
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    //如果state不为0，且当前线程为独占线程，进行+1，也就是重入锁的实现。
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    //如果都不满足，表示既有独占线程，当前线程又不是独占线程，则要进入同步队列，等待锁的释放。这一步完进入AQS核心代码也就是第一个图
    return false;
}
```



```java
public final void acquire(int arg) {
	// 看完重入锁的加锁实现源码后，应该就了解了第一个方法的具体作用，arg = 1，tryAcquire提供给子类实现，具体实现看子类，都是操作state
	//当第一个方法放回false，！false为true的时候，表示线程需要进入同步队列，设置当前线程的状态为独占模式，也就是Node.EXCLUSIVE。进入addWaiter方法
      if (!tryAcquire(arg) &&
          acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
          selfInterrupt();
  }


private Node addWaiter(Node mode) {
	//将当前线程封装成Node节点。
   Node node = new Node(Thread.currentThread(), node);
   // tail默认为null，如果tail不为空，说明同步队列已经有节点，因为Node pred = tail，则cas比满足条件，则将node节点加入队尾。
   Node pred = tail;
   if (pred != null) {
       node.prev = pred;
       if (compareAndSetTail(pred, node)) {
           pred.next = node;
           return node;
       }
   }
   //如果是第一个节点，则进入enq方法
   enq(node);
   return node;
}

private Node enq(final Node node) {
	//通过自旋的方式
	//该部分用图表示
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
//上面的两个函数比较好理解，就是在队列的尾部插入新的Node节点，但是需要注意的是由于AQS中会存在多个线程同时争夺资源的情况，因此肯定会出现多个线程同时插入节点的操作，在这里是通过CAS自旋的方式保证了操作的线程安全性，需要说明的是通过这种方式多个线程同时插入节点，不能保证节点的顺序。

```

`release(int)`方法是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。这也正是unlock()的语义，当然不仅仅只限于unlock()。下面是release()的源码：

```java
  public final boolean release(int arg) {
        if (tryRelease(arg)) {
            Node h = head;
            if (h != null && h.waitStatus != 0)
                unparkSuccessor(h);
            return true;
        }
        return false;
    }
 protected boolean tryRelease(int arg) {
        throw new UnsupportedOperationException();
    }

    private void unparkSuccessor(Node node) {

        int ws = node.waitStatus;
        if (ws < 0)
            compareAndSetWaitStatus(node, ws, 0);

  
        Node s = node.next;
        if (s == null || s.waitStatus > 0) {
            s = null;
            for (Node t = tail; t != null && t != node; t = t.prev)
                if (t.waitStatus <= 0)
                    s = t;
        }
        if (s != null)
            LockSupport.unpark(s.thread);
    }
```

与acquire()方法中的tryAcquire()类似，tryRelease()方法也是需要独占模式的自定义同步器去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。但要注意它的返回值，上面已经提到了，release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false。
  `unparkSuccessor(Node)`方法用于唤醒等待队列中下一个线程。这里要注意的是，下一个线程并不一定是当前节点的next节点，而是下一个可以用来唤醒的线程，如果这个节点存在，调用`unpark()`方法唤醒。
  总之，release()是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。



来看ReentrantLock源码：

```java
public class ReentrantLock implements Lock, java.io.Serializable {
    private static final long serialVersionUID = 7373984872572414699L;
    /** Synchronizer providing all implementation mechanics */
    private final Sync sync;
    
    
    abstract static class Sync extends AbstractQueuedSynchronizer {
         abstract void lock();//有公平实现和非公平实现
            final boolean nonfairTryAcquire(int acquires) {
                //首先查看这个对象是否已经被加锁，如果未被加锁则用cas方法试图获得锁，如果获得锁成功则将获得这个锁的线程设置为自己，如果已经被加锁则判断是否是自己加的锁 如果是自己加锁则加重入锁并修改state值，否则返回false
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0) // overflow
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
        final ConditionObject newCondition() {
            return new ConditionObject();
        }

        // Methods relayed from outer class

        final Thread getOwner() {
            return getState() == 0 ? null : getExclusiveOwnerThread();
        }

        final int getHoldCount() {
            return isHeldExclusively() ? getState() : 0;
        }
    }
```

## aqs组件

![](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220204140024503.png)

还有reentrantlock

semaphoredemo:

```java
public class SemaphoreExample1 {
    // 请求的数量
    private static final int threadCount = 550;

    public static void main(String[] args) throws InterruptedException {
        // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢）
        ExecutorService threadPool = Executors.newFixedThreadPool(300);
        // 一次只能允许执行的线程数量。
        final Semaphore semaphore = new Semaphore(20);

        for (int i = 0; i < threadCount; i++) {
            final int threadnum = i;
            threadPool.execute(() -> {// Lambda 表达式的运用
                try {
                    semaphore.acquire();// 获取一个许可，所以可运行线程数量为20/1=20
                    test(threadnum);
                    semaphore.release();// 释放一个许可
                } catch (InterruptedException e) {
                    // TODO Auto-generated catch block
                    e.printStackTrace();
                }

            });
        }
        threadPool.shutdown();
        System.out.println("finish");
    }

    public static void test(int threadnum) throws InterruptedException {
        Thread.sleep(1000);// 模拟请求的耗时操作
        System.out.println("threadnum:" + threadnum);
        Thread.sleep(1000);// 模拟请求的耗时操作
    }
}
```



![image-20210813091747913](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813091747913.png)

![image-20210813091920874](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813091920874.png)

aqs类图

AbstractOwnableSynchronizer：抽象类，定义了存储独占当前线程的属性和设置，获取当前线程的方法。
AbstractQueuenSynchronize：抽象类，AQS框架核心类，内部以虚拟队列的方式管理线程的锁获取与锁释放，其中获取锁（tryAcquire方法）和释放锁（tryRelease方法）并没有提供默认的实现，需要子类重写方法的具体逻辑，目的是为了使开发人可以自定义获取锁和释放锁的方式。
Node：AbstractQueuenSynchronize的内部类，用于构建虚拟队列（双向链表），为每个进入同步队列的线程封装成Node对象加入队列，管理需要获取锁的线程。
Sync：抽象类，是ReentrantLock的内部类，继承了AbstractQueuenSynchronize，实现了tryRelease方法，并提供抽象方法lock，供子类实现
NonfairSync：Reentrantlock的内部类，继承Sync，非公平锁的实现类
FairSync：Reentrantlock的内部类，继承Sync，公平锁的实现类
Reentrantlock：实现了Lock接口，创建时默认为非公平锁。



AQS 核心源码分析
1 获取锁流程图

![image-20211010114637741](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211010114637741.png)



![image-20211010114555128](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211010114555128.png)

compareAndSetState 赋值成功则获取锁

ReentrantLock 实现了非公平锁和公平锁，所以在调用 lock.lock(); 时，会有不同的实现类：

1. 非公平锁，会直接使用 CAS 进行抢占，修改变量 state 值。如果成功则直接把自己的线程设置到 exclusiveOwnerThread ，也就是获得锁成功。 不成功后续分析
2. 公平锁，则不会进行抢占，而是规规矩矩的进行排队。 老实人





(AQS)acquire

```java
public final void acquire(int arg)

 { 

if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) 
    selfInterrupt();

}
```


整个这块代码里面包含了四个方法的调用，如下：

1. tryAcquire ，分别由继承 AQS 的公平锁（ FairSync ）、非公平锁 NonfairSync ）实现。
2. addWaiter ，该方法是 AQS 的私有方法，主要用途是方法 tryAcquire 返回 false以后，也就是获取锁失败以后，把当前请求锁的线程添加到队列中，并返回 Node节点。
3. acquireQueued ，负责把 addWaiter 返回的 Node 节点添加到队列结尾，并会执行获取锁操作以及判断是否把当前线程挂起。
4. selfInterrupt ，是 AQS 中的 Thread.currentThread().interrupt() 方
   法调用，它的主要作用是在执行完 acquire 之前自己执行中断操作。

```java
private Node addWaiter(Node mode) { 
    Node node = new Node(Thread.currentThread(), mode); 
    Node pred = tail; // 如果队列不为空, 使用 CAS 方式将当前节点设为尾节点
    if (pred != null) { 
        node.prev = pred; 
        if (compareAndSetTail(pred, node)) 
    { 
        pred.next = node; 
        return node; 
    }
        } // 队列为空、CAS失败，将节点插入队列 
    enq(node); 
    return node; 
}
```

当执行方法 addWaiter ，那么就是 !tryAcquire = true ，也就是
tryAcq uire 获取锁失败了。
 接下来就是把当前线程封装到 Node 节点中，加入到 FIFO 队列中。 因为先进先
出，所以后来的队列加入到队尾
 compareAndSetTail 不一定一定成功，因为在并发场景下，可能会出现操作
失败。那么失败后，则需要调用 enq 方法，该方法会自旋操作，把节点入队列。



1、AQS是一个JAVA线程同步的框架。是JDK中很多锁工具的核心实现框架。
2、在AQS中,维护了一个信号量 state和一个线程组成的双向链表队列。其中,这个线程队列,是用来给线程排队的,而state就像是一个红绿灯,用来控制线程排队或放行的。在不同的场景下,有不用的意义。
在可重入锁这个场景下, states就用来表示加的次数。0标识无锁,每加一次锁, states就加1.释放锁 state就减1



**基于 AQS 实现的锁有哪些？**

![image-20211010151725197](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211010151725197.png)

Semaphore ，信号量锁。主要用于控制流量，它的作用是限制某段代码块的并发数。Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。比如：数据库连接池给你分配 10个链接，那么让你来一个连一个，连到 10 个还没有人释放，那你就等等。
 CountDownLatch ，闭锁。 Latch 门闩的意思，比如：说四个人一个漂流艇，坐满了就推下水。



## 写一个简单的 AQS 同步类

在学习 ReentrantLock 中应用的 AQS 之前，先实现一个简单的同步类，来体会下 AQS 的作用。

```java
public class SyncLock { 
    private final Sync sync; 
    public SyncLock() 
    {
        sync = new Sync(); 
    } 
    public void lock()
    { 
        sync.acquire(1); 
    } 
    public void unlock()
    { 
        sync.release(1);
    }
    private static class Sync extends AbstractQueuedSynchronizer { 
        @Override 
        protected boolean tryAcquire(int arg) { 
            return compareAndSetState(0, 1);
            @Override protected boolean tryRelease(int arg) 
            { 
                setState(0); return true; 
            } // 该线程是否正在独占资源，只有用到 Condition 才需要去实现
            @Override 
            protected boolean isHeldExclusively() 
            { 
                return getState() == 1; 
            } 
        }
```

这个实现的过程属于 ReentrantLock 简版，主要包括如下内容：

1. Sync 类继承 AbstractQueuedSynchronizer ，并重写方法 tryAcquire 、
   tryRelease 、 isHeldExclusively 。
2. 这三个方法基本是必须重写的，如果不重写在使用的时候就会抛异常
   UnsupportedOperationException 。
3. 重写的过程也比较简单，主要是使用 AQS 提供的 CAS 方法。以预期值为 0 ，写入更新值 1 ，写入成功则获取锁成功。其实这个过程就是对 state 使用 unsafe本地方法，传递偏移量 stateOffset 等参数，进行值交换操作。
   unsafe.compareAndSwapInt(this, stateOffset, expect,update)
4. 最后提供 lock 、 unlock 两个方法，实际的类中会实现 Lock 接口中的相应方法，这里为了简化直接自定义这样两个方法。

```java
@Test 
public void test_SyncLock() throws InterruptedException 
{ 
    final SyncLock lock = new SyncLock(); 
    for (int i = 0; i < 10; i++) 
    { 
        Thread.sleep(200); 
        new Thread(new TestLock(lock),String.valueOf(i)).start();
     Thread.sleep(100000); } 
    static class TestLock implements Runnable 
    { 
        private SyncLock lock; 
        public TestLock(SyncLock lock) throws InterruptedException 
        { 
            this.lock = lock; 
        } 
        @Override public void run() { 
            try { 
                lock.lock(); 
                Thread.sleep(1000); System.out.println(String.format("Thread %s Completed", Thread.currentThread().getName())); 
            } catch (Exception e) 
            { 
                e.printStackTrace(); 
            } finally { 
                lock.unlock(); 
            } 
        } 
    }
    
```

## 除了 ReetrantLock，你还接触过 JUC 中的哪些并发工具？

通常所说的并发包（JUC）也就是 java.util.concurrent 及其子包，集中了 Java 并发的各种基础工具类，具体主要包括几个方面： 

 提供了 CountDownLatch、CyclicBarrier、Semaphore 等，比 Synchronized 更加高级，可以实现更加丰富多线程操作的同步结构。

提供了 ConcurrentHashMap、有序的 ConcunrrentSkipListMap，或者通过类似快照机制实现线程安全的动态数组 CopyOnWriteArrayList 等，各种线程安全的容器。 

 提供了 ArrayBlockingQueue、SynchorousQueue 或针对特定场景的 PriorityBlockingQueue 等，各种并发队列实现。 

 强大的 Executor 框架，可以创建各种不同类型的线程池，调度任务运行等。

# CPU为何要有高速缓存

CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\O速度和CPU运算速度之间的不匹配问题。
在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。

带有高速缓存的CPU执行计算的流程

1. 程序以及数据被加载到主内存
2. 指令和数据被加载到CPU的高速缓存
3. CPU执行指令，把结果写到高速缓存
4. 高速缓存中的数据写回主内存

目前流行的多级缓存结构
由于CPU的运算速度超越了1级缓存的数据I\O能力，CPU厂商又引入了多级的缓存结构。
多级缓存结构

![image-20211223170723477](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211223170723477.png)



多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。

# 缓存一致性协议MESI

现在的处理器都是多核处理器，并且每个核都带有多个缓存（指令缓存和数据缓存，见下图）。为什么需要缓存呢，这是因为CPU访问内存的速度比较慢，所以在CPU和内存之间加了个缓存以提高访问速度。既然每个核都有缓存，那么假设两个核或者多个核同时访问同一个变量时这些缓存是如何进行同步的呢（缓存细分为一个个缓存行），这就有了MESI协议。

MESI解决多CPU的数据不一致性问题

MESI中每个缓存行都有四个状态，分别是E（exclusive）、M（modified）、S（shared）、I（invalid）。下面我们介绍一下这四个状态分别代表什么意思。

M：代表该缓存行中的内容被修改了，并且该缓存行只被缓存在该CPU中。这个状态的缓存行中的数据和内存中的不一样，在未来的某个时刻它会被写入到内存中（当其他CPU要读取该缓存行的内容时。或者其他CPU要修改该缓存对应的内存中的内容时（个人理解CPU要修改该内存时先要读取到缓存中再进行修改），这样的话和读取缓存中的内容其实是一个道理）。

E：E代表该缓存行对应内存中的内容只被该CPU缓存，其他CPU没有缓存该缓存对应内存行中的内容。这个状态的缓存行中的内容和内存中的内容一致。该缓存可以在任何其他CPU读取该缓存对应内存中的内容时变成S状态。或者本地处理器写该缓存就会变成M状态。

S:该状态意味着数据不止存在本地CPU缓存中，还存在别的CPU的缓存中。这个状态的数据和内存中的数据是一致的。当有一个CPU修改该缓存行对应的内存的内容时会使该缓存行变成 I 状态。

I：代表该缓存行中的内容时无效的

![image-20211223170912674](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211223170912674.png)

![image-20211223161124188](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211223161124188.png)

![image-20211223161159370](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211223161159370.png)

双核读取
那么执行流程是：
CPU A发出了一条指令，从主内存中读取x。
CPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。
CPU B发出了一条指令，从主内存中读取x。
CPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储
于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。

![image-20211223171132988](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211223171132988.png)

**修改数据**
那么执行流程是：
CPU A 计算完成后发指令需要修改x.
CPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无
效)
CPU A 对x进行赋值。

![image-20211223171201377](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211223171201377.png)

**同步数据**
那么执行流程是：
CPU B 发出了要读取x的指令。
CPU B 通知CPU A,CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）
CPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）。

![image-20211223171301734](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211223171301734.png)



## 缓存行伪共享

什么是伪共享？
CPU缓存系统中是以缓存行（cache line）为单位存储的。目前主流的CPU Cache 的
Cache Line 大小都是64Bytes。在多线程情况下，如果需要修改“共享同一个缓存行的变
量”，就会无意中影响彼此的性能，这就是伪共享（False Sharing）。
举个例子: 现在有2个long 型变量 a 、b，如果有t1在访问a，t2在访问b，而a与b刚好在同一个
cache line中，此时t1先修改a，将导致b被刷新！
怎么解决伪共享？
Java8中新增了一个注解：@sun.misc.Contended。加上这个注解的类会自动补齐缓
存行，需要注意的是此注解默认是无效的，需要在jvm启动时设置 -XX:-
RestrictContended 才会生效。

![image-20211223215829670](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211223215829670.png)



## Java中如何获取到线程dump文件

死循环、死锁、阻塞、页面打开慢等问题，打线程dump是最好的解决问题的途径。所谓线程dump也就是线程堆栈，获取到线程堆栈有两步：
1、获取到线程的pid，可以通过使用jps命令，在Linux环境下还可以使用ps -ef | grep java
2、打印线程堆栈，可以通过使用jstack pid命令，在Linux环境下还可以使用kill -3 pid
另外提一点，Thread类提供了一个getStackTrace()方法也可以用于获取线程堆栈。这是一个实例方法，因此此方法是和具体线程实例绑定的，每次获取获取到的是具体某个线程当前运行的堆栈，



## 如何在两个线程间共享数据？

第一种：将共享数据封装到一个对象中，把这个共享数据所在的对象传递给不同的Runnable

```java
class ShareData {
private int x = 0;
public synchronized void addx(){
x++;
System.out.println("x++ : "+x);
}
public synchronized void subx(){
x--;
System.out.println("x-- : "+x);
}
}
public class ThreadsVisitData {
public static ShareData share = new ShareData();
public static void main(String[] args) {
//final ShareData share = new ShareData();
new Thread(new Runnable() {
public void run() {
for(int i = 0;i<100;i++){
share.addx();
}
}
}).start();
new Thread(new Runnable() {
public void run() {
for(int i = 0;i<100;i++){
share.subx();
}
}
}).start();
}
}
```

输出：

![image-20210923003503709](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210923003503709.png)





第二种：将这些Runnable对象作为某一个类的内部类，共享的数据作为外部类的成员变量，对共享数据的操作分配给外部类的方法来完成，以此实现对操作共享数据的互斥和通信，作为内部类的Runnable来操作外部类的方法，实现对数据的操作

# 线程让出cpu 的情况：

1. 当前运行线程主动放弃CPU，JVM 暂时放弃CPU 操作（基于时间片轮转调度的JVM 操作系
统不会让线程永久放弃CPU，或者说放弃本次时间片的执行权），例如调用yield()方法。
2. 当前运行线程因为某些原因进入阻塞状态，例如阻塞在I/O 上。
3. 当前运行线程结束，即运行完run()方法里面的任务。

# 进程调度算法

线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是协同式线程调度（Cooperative Threads-Scheduling）和抢占式线程调度（Preemptive Threads-Scheduling）。

 如果使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上。协同式多线程的最大好处是实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以没有什么线程同步的问题。Lua语言中的“协同例程”就是这类实现。它的坏处也很明显：线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。很久以前的Windows 3.x系统就是使用协同式来实现多进程多任务的，相当不稳定，一个进程坚持不让出CPU执行时间就可能会导致整个系统崩溃。 

如果使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定（在Java中，Thread.yield（）可以让出执行时间，但是要获取执行时间的话，线程本身是没有什么办法的）。在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度。与前面所说的Windows 3.x的例子相对，在Windows 9x/NT内核中就是使用抢占式来实现多进程的，当一个进程出了问题，我们还可以使用任务管理器把这个进程“杀掉”，而不至于导致系统崩溃。 虽然Java线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配一点执行时间，另外的一些线程则可以少分配一点

**优先调度算法**

1. 先来先服务调度算法（FCFS）
    当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS 算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机，特点是：算法比较简单，可以实现基本上的公平。
2. 短作业(进程)优先调度算法
    短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重
    新调度。该算法未照顾紧迫型作业。

**高优先权优先调度算法**
为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。
当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程。

1. 非抢占式优先权算法
在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时。这种调度算法主要用于批处理系统中；
也可用于某些对实时性要求不严的实时系统中。
2. 抢占式优先权调度算法
在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)
的执行，重新将处理机分配给新到的优先权最高的进程。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。
2．高响应比优先调度算法
在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行
得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时间的增加而以速率a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的
变化规律可描述为：

# Java中如何唤醒一个阻塞的线程

首先，如果是IO阻塞，普通方法无法终止线程，第二，如果线程是因为调用wait,sleep等方法而进入阻塞状态，可以使用中断线程，并且抛出InterruptedException异常来唤醒它。

对阻塞方法的大致分类：

(1)会抛出InterruptedException的方法：wait、sleep、join、Lock.lockInterruptibly等，针对这类方法，我们在线程内部处理好异常(要不完全内部处理，要不把这个异常抛出去)，然后就可以实现唤醒。

(2)不会抛InterruptedException的方法：Socket的I/O,同步I/O，Lock.lock等。对于I/O类型，我们可以关闭他们底层的通道，比如Socket的I/O，关闭底层套接字，然后抛出异常处理就好了;比如同步I/O，关闭底层Channel然后处理异常。对于Lock.lock方法，我们可以改造成Lock.lockInterruptibly方法去实现。





## 虚假唤醒

用while(判断条件)代替if(判断条件)解决虚假唤醒问题

联想飞机过安检时下去了再上飞机还需要再次安检，虚假唤醒时则只进行一次安检





## 守护线程（ Daemon）和用户线程（ User）

java 中的线程分为两种：守护线程（ Daemon）和用户线程（ User）

所谓后台(daemon)线程，也叫守护线程，是指在程序运行的时候在后台提供一种通用服务的线程，
并且这个线程并不属于程序中不可或缺的部分。

守护线程都是为JVM中所有非守护线程的运行提供便利服务： 只要当前JVM实例中尚存在任何一个非守护线程没有结束，守护线程就全部工作；**只有当最后一个非守护线程结束时，守护线程随着JVM一同结束工作**。

因此，当所有的非后台线程结束时，程序也就终止了，同时会杀死进程中的所有后台线程。反过来说， 只要有任何非后台线程还在运行，程序就不会终止。

比如：JVM的垃圾回收线程就是Daemon线程，Finalizer也是守护线程。

任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on)；true 则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()须在Thread.start()之前调用，否则运行时会抛出异常。
两者的区别：
唯一的区别是判断虚拟机(JVM)何时离开，Daemon 是为其他线程提供服务，如果全部的User Thread 已经撤离， Daemon 没有可服务的线程，JVM 撤离。也可以理解为守护线程是JVM 自动创建的线程（ 但不一定），用户线程是程序创建的线程；比如JVM 的垃圾回收线程是一个守护线程，当所有线程已经撤离，不再产生垃圾，守护线程自然就没事可干了，==当垃圾回收线程是Java 虚拟机上仅剩的线程时，Java 虚拟机会自动离开。==
扩展：Thread Dump 打印出来的线程信息， 含有daemon 字样的线程即为守护进程，可能会有：服务守护进程、编译守护进程、windows 下的监听Ctrl+break的守护进程、Finalizer 守护进程、引用处理守护进程、GC 守护进程。

thread.setDaemon(true)必须在thread.start()之前设置，否则会抛出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。在Daemon线程中产生的新线程也是Daemon的。守护线程不能用于去访问固有资源，比如读写操作或者计算逻辑。因为它会在任何时候甚至在一个操作的中间发生中断。Java自带的多线程框架，比如ExecutorService，会将守护线程转换为用户线程，所以如果要使用后台线程就不能用Java的线程池。

进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元。
一个程序至少有一个进程,一个进程至少有一个线程。

## 如何创建守护线程？以及在什么场合来使用它？
任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on）on)；true则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。
守护线程相当于后台管理者 比如 : 进行内存回收,垃圾清理等工作



## 你对线程优先级的理解是什么？

每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OSdependent)。
可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。



## 什么是多线程中的上下文切换？

因为单核cpu也支持多线程，是通过Cpu给每个线程分配时间片来实现这个机制的，cpu通过不停切换时间片来让线程都执行，速度非常快，看起来就像同时执行一样，在上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行。从这个角度来看，上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们
需要记住每本书当前读到的页码。
在程序中，上下文切换过程中的“页码”信息是保存在进程控制块（PCB）中的。PCB还经常被称
作“切换桢”（switchframe）。“页码”信息会一直保存到CPU的内存中，直到他们被再次使用。
上下文切换是存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。上下文切换是
多任务操作系统和多线程环境的基本特征。

上下文
📣是指某一时间点 CPU 寄存器和程序计数器的内容。

寄存器
是 CPU 内部的数量较少但是速度很快的内存（与之对应的是 CPU 外部相对较慢的 RAM 主内存）。寄存器通过对常用值（通常是运算的中间值）的快速访问来提高计算机程序运行的速度。
 程序计数器
是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置，具体依赖于特定的系统。



线程上下文切换
巧妙地利用了时间片轮转的方式, CPU 给每个任务都服务一定的时间，然后把当前任务的状态保存下来，在加载下一任务的状态后，继续服务下一任务，<font color="red">任务的状态保存及再加载, 这段过程就叫做上下文切换。</font>时间片轮转的方式使多个任务在同一颗CPU 上执行变成了可能。

![image-20220130015621224](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220130015621224.png)

PCB-“切换桢”
上下文切换可以认为是内核（操作系统的核心）在 CPU 上对于进程（包括线程）进行切换，上下文切换过程中的信息是保存在进程控制块（PCB, process control block）中的。PCB 还经常被称作“切换桢”（switchframe）。信息会一直保存到CPU 的内存中，直到他们被再次使用。



多线程会共同使用一组计算机上的CPU，而线程数大于给程序分配的CPU 数量时，为了让各个线程都有执行的机会，就需要轮转使用CPU。不同的线程切换使用CPU发生的切换数据等就是上下文切换。

**单核CPU也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。**时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程时同时执行的，时间片一般是几十毫秒（ms）。
**操作系统中，CPU时间分片切换到另一个就绪的线程，则需要保存当前线程的运行的位置，同时需要加载需要恢复线程的环境信息**。



## 什么是线程调度器(Thread Scheduler)和时间分片(TimeSlicing)？
线程调度器是一个操作系统服务，它负责为Runnable状态的线程分配CPU时间。一旦创建一个线程并启动它，它的执行便依赖于线程调度器的实现。
时间分片是指将可用的CPU时间分配给可用的Runnable线程的过程。分配CPU时间可以基于线程优先级或者线程等待的时间。

线程调度器是一个操作系统服务，它负责为Runnable 状态的线程分配CPU 时间**。线程调度并不受到Java 虚拟机控制**，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）





## 无饥饿无障碍无锁

对于非公平锁来说，系统允许高优先级的线程插队。这样有可能导致低优先级线程产生饥饿。但如果锁是公平的，按照先来后到的规则，那么饥饿就不会产生，不管新来的线程优先级多高，要想获得资源，就必须乖乖排队，这样所有的线程都有机会执行。

无障碍(Obstruction-Free)
无障碍是一种最弱的非阻塞调度。两个线程如果无障碍地执行，那么不会因为临界区的问题导致一方被挂起。换言之，大家都可以大摇大摆地进入临界区了。那么大家一起修改共享数据，把数据改坏了怎么办呢？对于无障碍的线程来说，一旦检测到这种情况，它就会立即对自己所做的修改进行回滚，确保数据安全。但如果没有数据竞争发生，那么线程就可以顺利完成自己的工作，走出临界区。
如果说阻塞的控制方式是悲观策略，也就是说，系统认为两个线程之间很有可能发生不幸的冲突，因此以保护共享数据为第一优先级，**相对来说，非阻塞的调度就是一种乐观的策略。它认为多个线程之间很有可能不会发生冲突，或者说这种概率不大**。因此大家都应该无障碍地执行，但是一旦检测到冲突，就应该进行回滚。

从这个策略中也可以看到，无障碍的多线程程序并不一定能顺畅运行。因为当临界区中存在严重的冲突时，所有的线程可能都会不断地回滚自己的操作，而没有一个线程可以走出临界区。这种情况会影响系统的正常执行。所以，我们可能会非常希望在这一堆线程中，至少可以有一个线程能够在有限的时间内完成自己的操作，而退出临界区。至少这样可以保证系统不会在临界区中进行无限的等待。
**一种可行的无障碍实现可以依赖一个"一致性标记"来实现。线程在操作之前，先读取并保存这个标记，在操作完成后，再次读取，检查这个标记是否被更改过，如果两者是一致的，则说明资源访问没有冲突**。如果不一致，则说明资源可能在操作过程中与其他线程冲突，需要重试操作。而任何对资源有修改操作的线程，在修改数据前，都需要更新这个一致性标记，表示数据不再安全。

无锁(Lock-Free)

无锁的并行都是无障碍的。在无锁的情况下，所有的线程都能尝试对临界区进行访问，但不同的是，无锁的并发保证必然有一个线程能够在有限步内完成操作离开临界区。
在无锁的调用中，一个典型的特点是可能会包含一个无穷循环。在这个循环中，线程会不断尝试修改共享变量。如果没有冲突，修改成功，那么程序退出，否则继续尝试修改。但无论如何，无锁的并行总能保证有一个线程是可以胜出的，不至于全军覆没。至于临界区中竞争失败的线程，他们必须不断重试，直到自己获胜。如果运气很不好，总是尝试不成功，则会出现类似饥饿的先写，线程会停止。
下面就是一段无锁的示意代码，如果修改不成功，那么循环永远不会停止。

```java
while(!atomicVar.compareAndSet(localVar, localVar+1)){
localVal = atomicVar.get();
}
```

无等待
无锁只要求有一个线程可以在有限步内完成操作，而无等待则在无锁的基础上更进一步扩展。它要求所有线程都必须在有限步内完成，这样不会引起饥饿问题。如果限制这个步骤的上限，还可以进一步分解为有界无等待和线程数无关的无等待等几种，他们之间的区别只是对循环次数的限制不同。
一种典型的无等待结果就是RCU(Read Copy Update)。它的基本思想是，对数据的读可以不加控制。因此，所有的读线程都是无等待的，它们既不会被锁定等待也不会引起任何冲突。但在写数据的时候，先获取原始数据的副本，接着只修改副本数据(这就是为什么读可以不加控制)，修改完成后，在合适的时机回写数据。



当一个线程拿不到锁的时候，有以下两种基本的等待策略。

 策略1：放弃CPU，进入阻塞状态，等待后续被唤醒，再重新被操作系统调度。 策略2：不放弃CPU，空转，不断重试，也就是所谓的“自旋”。 很显然，如果是单核的CPU，只能用策略1。因为如果不放弃CPU，那么其他线程无法运行，也就无法释放锁。但对于多CPU或者多核，策略2就很有用了，因为没有线程切换的开销。 AtomicInteger的实现就用的是“自旋”策略，如果拿不到锁，就会一直重试。 有一点要说明：这两种策略并不是互斥的，可以结合使用。如果拿不到锁，先自旋几圈；如果自旋还拿不到锁，再阻塞，synchronized关键字就是这样的实现策略。 除了AtomicInteger，AtomicLong也是同样的原理

监视器

## 生产者消费者模型的作用是什么

生产者消费者模型的作用是什么
这个问题很理论，但是很重要：
1、通过平衡生产者的生产能力和消费者的消费能力来提升整个系统的运行效率，这是生产者消费者模型最重要的作用
2、解耦，这是生产者消费者模型附带的作用，解耦意味着生产者和消费者之间的联系少，联系越少越可以独自发展而不需要收到相互的制约

多线程环境下，经常需要多个线程能够并发和协作。这时，就需要了解一个重要的多线程并发协作模型“生产者-消费者模式”，如图11-17所示。 什么是生产者。生产者指的是负责生产数据的模块（这里的模块指的可能是方法、对象、线程、进程等）。 什么是消费者。==消费者指的是负责处理数据的模块==（这里的模块指的可能是方法、对象、线程、进程等）。 什么是缓冲区。消费者不能直接使用生产者的数据，它们之间有个“缓冲区”。生产者将生产好的数据放入“缓冲区”，消费者从“缓冲区”拿出要处理的数据。==缓冲区是实现并发操作的核心==。缓冲区的设置有3个好处： 实现线程的并发协作。有了缓冲区以后，生产者线程只需要往缓冲区里面放置数据，而不需要管消费者消费的情况；同样，消费者只需要从缓冲区拿出数据处理即可，不需要考虑生产者生产的情况。这样，就从逻辑上实现了“生产者线程”和“消费者线程”的分离。 解耦了生产者和消费者。生产者不需要和消费者直接打交道。 解决忙闲不均，提高效率。生产者生产数据慢时，但在缓冲区仍有数据，不影响消费者消费；消费者处理数据慢时，生产者仍然可以继续往缓冲区里面放置数据。  

守护线程是一种特殊的线程，在后台默默地完成一些系统性的服务，比如垃圾回收线程、JIT线程都是守护线程。与之对应的是用户线程，用户线程可以理解为是系统的工作线程，它会完成这个程序需要完成的业务操作。如果用户线程全部结束了，意味着程序需要完成的业务操作已经结束了，系统可以退出了。所以当系统只剩下守护进程的时候，java虚拟机会自动退出。
java线程分为用户线程和守护线程，线程的daemon属性为true表示是守护线程，false表示是用户线程。

设置守护线程，需要在start()方法之前进行

如果写：

t1.start();
t1.setDaemon(true);
程序会报错。



这个问题很理论，但是很重要：
1）通过平衡生产者的生产能力和消费者的消费能力来提升整个系统的运行效率，这是生产者消费者模型最重要的作用
2）解耦，这是生产者消费者模型附带的作用，解耦意味着生产者和消费者之间的联系少，联系越少越可以独自发展而不需要收到相互的制约

线程并发协作（也叫线程通信）通常用于生产者-消费者模式，情景如下： 

（1）生产者和消费者共享同一个资源，并且生产者和消费者之间相互依赖，互为条件。 

（2）对于生产者，没有生产产品之前，消费者要进入等待状态。而生产了产品之后，又需要马上通知消费者消费。 

（3）对于消费者，在消费之后，要通知生产者已经消费结束，需要继续生产新产品以供消费。 

（4）在生产者-消费者问题中，仅使用synchronized是不够的。synchronized可阻止并发更新同一个共享资源，虽然实现了同步，但它不能用来实现不同线程之间的消息传递（通信）。 






14、为什么 wait()方法和 notify()/notifyAll()方法要在同步块中被调用这是 JDK 强制的，wait()方法和 notify()/notifyAll()方法在调用前都必须先获得对象的锁
15、wait()方法和 notify()/notifyAll()方法在放弃对象监视器时有什么
区别
wait()方法和 notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：
wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线
程剩余代码执行完毕才会放弃对象监视器。 





## 乐观锁 悲观锁 自旋锁 和其他锁的概念

乐观锁：就像它的名字一样，对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争不总是会发生，因此它不需要持有锁，将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。

乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的**原子变量类就是使用了乐观锁的一种实现方式CAS实现的**。在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复读-比较-写的操作。== java中的乐观锁基本都是通过CAS操作实现的==，CAS是一种更新的原子操作，比较当前值跟传入值是否一样，一样则更新，否则失败。解决的是丢失更新问题

CAS 是 compareAndSet 的缩写，它的应用场景就是对一个变量进行值变更，在变更时会传入两个参数：一个是预期值、另外一个是更新值。如果被更新的变量预期值与传入值一致，则可以变更。
CAS 的具体操作使用到了 unsafe 类，底层用到了本地方法 unsafe.compareAndSwapInt 比较交换方法。
CAS 是一种无锁算法，这种操作是 CPU 指令集操作，只有一步原子操作，速度非常快。而且 CAS 避免了请求操作系统来裁定锁问题，直接由 CPU 搞定，但也不是没有开销，比如 Cache Miss





------------------------------

![image-20210813091417227](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813091417227.png)

悲观锁是就是悲观思想，对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像synchronized，不管三七二十一，直接上了锁就操作资源了。即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block直到拿到锁。java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如RetreenLock。

两种锁的使用场景
从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，**所以一般多写的场景下用悲观锁就比较合适。**



自旋锁的优缺点？
自旋锁不会引起调用者休眠，如果自旋锁已经被别的线程保持，调用者就一直循环在那里看是否该自旋
锁的保持者释放了锁。由于自旋锁不会引起调用者休眠，所以自旋锁的效率远高于互斥锁。
虽然自旋锁效率比互斥锁高，但它会存在下面两个问题：

 1、自旋锁一直占用CPU，在未获得锁的情况下，一直运行，如果不能在很短的时间内获得锁，会导致CPU效率降低。 

2、试图递归地获得自旋锁会引起死锁。递归程序决不能在持有自旋锁时调用它自己，也决不能在递归调用时试图获得相同的自旋锁。
由此可见，我们要慎重的使用自旋锁，自旋锁适合于锁使用者**保持锁时间比较短并且锁竞争不激烈的情况**。正是由于自旋锁使用者一般保持锁时间非常短，因此选择自旋而不是睡眠是非常必要的，自旋锁的效率远高于互斥锁。

自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，==这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。==
自旋锁的默认大小是10次，可以调整：-XX：PreBlockSpin
如果自旋n次失败了，就会升级为重量级的锁。重量级的锁，在 1.3 Monitor 对象中已经介绍。



## 自旋锁详细解释

举一个简单的例子： 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。
1.
操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。
2.
在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。
3.
操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。
4.
操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。

这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。



【自旋锁：】

自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。 线程自旋是需要消耗cup的，说白了就是让cup在做无用功，如果一直获取不到锁，那线程也不能一直占用cup自旋做无用功，所以需要设定一个自旋等待的最大时间。 如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。

自旋锁的优缺点

 自旋锁尽可能的减少线程的阻塞，**这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，**==因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗==，这些操作会导致线程发生两次上下文切换！ 但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，占着XX不XX，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。所以这种情况下我们要关闭自旋锁； 自旋锁时间阈值（1.6引入了适应性自旋锁） 自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋的周期选的额外重要！

JVM对于自旋周期的选择：

jdk1.5这个限度是一定的写死的，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间，同时JVM还针对当前CPU的负荷情况做了较多的优化，如果平均负载小于CPUs则一直自旋，如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞，如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞，如果CPU处于节电模式则停止自旋，自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差），自旋时会适当放弃线程优先级之间的差异

自旋锁的开启 JDK1.6中

-XX:+UseSpinning开启；

 -XX:PreBlockSpin=10 为自旋次数； JDK1.7后，去掉此参数，由jvm控制；







锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀；
11. JDK 1.6 中默认是开启偏向锁和轻量级锁，可以通过-XX:-UseBiasedLocking 来禁用偏向锁。

一个简单自旋锁：

```csharp
public class SpinLock implements Lock {
    /**
     *  use thread itself as  synchronization state
     *  使用Owner Thread作为同步状态，比使用一个简单的boolean flag可以携带更多信息
     */
    private AtomicReference<Thread> owner = new AtomicReference<>();
    /**
     * reentrant count of a thread, no need to be volatile
     */
    private int count = 0;

    @Override
    public void lock() {
        Thread t = Thread.currentThread();
        // if re-enter, increment the count.
        if (t == owner.get()) {
            ++count;
            return;
        }
        //spin
        while (owner.compareAndSet(null, t)) {
        }
    }

    @Override
    public void unlock() {
        Thread t = Thread.currentThread();
        //only the owner could do unlock;
        if (t == owner.get()) {
            if (count > 0) {
                // reentrant count not zero, just decrease the counter.
                --count;
            } else {
                // compareAndSet is not need here, already checked
                owner.set(null);
            }
        }
    }
}
```

owner属性持有锁当前拥有者的线程的引用，如果该引用为null，则表示锁未被占用，不为null则被占用。

这里用AtomicReference是为了使用它的原子性的compareAndSet方法（CAS操作），解决了多线程并发操作导致数据不一致的问题，确保其他线程可以看到锁的真实状态。

**缺点：**

1. CAS操作需要硬件的配合；
2. 保证各个CPU的缓存（L1、L2、L3、跨CPU Socket、主存）的数据一致性，通讯开销很大，在多处理器系统上更严重；
3. 没法保证公平性，不保证等待进程/线程按照FIFO顺序获得锁。



Ticket Lock 是为了解决上面的公平性问题，类似于现实中银行柜台的排队叫号：锁拥有一个服务号，表示正在服务的线程，还有一个排队号；每个线程尝试获取锁之前先拿一个排队号，然后不断轮询锁的当前服务号是否是自己的排队号，如果是，则表示自己拥有了锁，不是则继续轮询。

当线程释放锁时，将服务号加1，这样下一个线程看到这个变化，就退出自旋。

```csharp
public class TicketLock implements Lock {
    private AtomicInteger serviceNum = new AtomicInteger(0);
    private AtomicInteger ticketNum = new AtomicInteger(0);
    private final ThreadLocal<Integer> myNum = new ThreadLocal<>();

    @Override
    public void lock() {
        myNum.set(ticketNum.getAndIncrement());
        while (serviceNum.get() != myNum.get()) {
        }
    }

    @Override
    public void unlock() {
        serviceNum.compareAndSet(myNum.get(), myNum.get() + 1);
        myNum.remove();
    }
}
```

**缺点：**
 Ticket Lock 虽然解决了公平性的问题，但是多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum ，每次读写操作都必须在多个处理器缓存之间进行缓存同步，这会导致繁重的系统总线和内存的流量，大大降低系统整体的性能。

下面介绍的CLH锁和MCS锁都是为了解决这个问题的。

详情见：

[几种自旋锁的java实现 - 简书 (jianshu.com)](https://www.jianshu.com/p/824b2e4f1eed)





# 是共享的，为什么在堆中会有内存不可⻅问题？
这是因为现代计算机为了⾼效，往往会在⾼速缓存区中缓存共享变量，因为cpu访问缓存区⽐访问内存要快得多。
线程之间的共享变量存在主内存中，每个线程都有⼀个私有的本地内存，存储了该线程以读、写共享变量的副本。本地内存是Java内存模型的⼀个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器等。
Java线程之间的通信由Java内存模型（简称JMM）控制，从抽象的⻆度来说，JMM定义了线程和主内存之间的抽象关系。JMM的抽象示意图如图所示

1. 所有的共享变量都存在主内存中。
2. 每个线程都保存了⼀份该线程使⽤到的共享变量的副本。
3. 如果线程A与线程B之间要通信的话，必须经历下⾯2个步骤：
i. 线程A将本地内存A中更新过的共享变量刷新到主内存中去。
ii. 线程B到主内存中去读取线程A之前已经更新过的共享变量。
所以，线程A⽆法直接访问线程B的⼯作内存，线程间通信必须经过主内存

那么怎么知道这个共享变量的被其他线程更新了呢？这就是JMM的功劳了，也是JMM存在的必要性之⼀。JMM通过控制主内存与每个线程的本地内存之间的交互，来提供内存可⻅性保证。
Java中的volatile关键字可以保证多线程操作共享变量的可⻅性以及禁⽌指令重排序，synchronized关键字不仅保证可⻅性，同时也保证了原⼦性（互斥性）。在更底层，JMM通过内存屏障来实现内存的可⻅性以及禁⽌重排序。
为了程序员的⽅便理解，提出了happens-before，它更加的简单易懂，从⽽避免了程序员为了理解内存可⻅性⽽去学习复杂的重排序规则以及这些规则的具体实现⽅法。

# **原生锁机制在多机部署场景下失效**

系统A是一个电商系统，目前是一台机器部署，系统中有一个用户下订单的接口，但是用户下订单之前一定要去检查一下库存，确保库存足够了才会给用户下单。

由于系统有一定的并发，所以会预先将商品的库存保存在redis中，用户下单的时候会更新redis的库存。

此时系统架构如下：

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy8xSjZJYkljUENMWk8zWktNem0zVm1jNUw2aWNFeDdKdEEzUVdMajAyUk96YlM5TmMzV3M1bkNOQVhTMFJvS2Z2R1h6aWJYd0hBY1VTUHJyUWJvdVNuSTlnLzY0MA?x-oss-process=image/format,png)

但是这样一来会**产生一个问题**：假如某个时刻，redis里面的某个商品库存为1，此时两个请求同时到来，其中一个请求执行到上图的第3步，更新数据库的库存为0，但是第4步还没有执行。

而另外一个请求执行到了第2步，发现库存还是1，就继续执行第3步。

这样的结果，是导致卖出了2个商品，然而其实库存只有1个。

很明显不对啊！这就是典型的库存超卖问题

此时，我们很容易想到解决方案：用锁把2、3、4步锁住，让他们执行完之后，另一个线程才能进来执行第2步。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy8xSjZJYkljUENMWk8zWktNem0zVm1jNUw2aWNFeDdKdEFPeEhPNmd4aWNxanpKQWNHRVZMaWFpYmlhZmduaWJzWGJTY0ZJOUZld1lyazIwVVN3UTdIdmFEanlXUS82NDA?x-oss-process=image/format,png)

按照上面的图，在执行第2步时，使用Java提供的synchronized或者ReentrantLock来锁住，然后在第4步执行完之后才释放锁。

这样一来，2、3、4 这3个步骤就被“锁”住了，多个线程之间只能串行化执行。

但是好景不长，整个系统的并发飙升，一台机器扛不住了。现在要增加一台机器，如下图：

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy8xSjZJYkljUENMWk8zWktNem0zVm1jNUw2aWNFeDdKdEE1QXhsUndGQ2NFWGljUXFUaEdDZVRtZFd2eWJiRm9TUko0WEZFV0lrQ0F0RWFsUW1qWVdEUVdnLzY0MA?x-oss-process=image/format,png)

增加机器之后，系统变成上图所示，我的天！

假设此时两个用户的请求同时到来，但是落在了不同的机器上，那么这两个请求是可以同时执行了，还是会出现库存超卖的问题。

为什么呢？因为上图中的两个A系统，运行在两个不同的JVM里面，他们加的锁只对属于自己JVM里面的线程有效，对于其他JVM的线程是无效的。

因此，这里的问题是：Java提供的原生锁机制在多机部署场景下失效了

这是因为两台机器加的锁不是同一个锁(两个锁在不同的JVM里面)。

那么，我们只要保证两台机器加的锁是同一个锁，问题不就解决了吗？

此时，就该[分布式锁](https://so.csdn.net/so/search?q=分布式锁&spm=1001.2101.3001.7020)隆重登场了，分布式锁的思路是：

在整个系统提供一个**全局、唯一**的获取锁的“东西”，然后每个系统在需要加锁时，都去问这个“东西”拿到一把锁，这样不同的系统拿到的就可以认为是同一把锁。

至于这个“东西”，可以是Redis、[Zookeeper](https://so.csdn.net/so/search?q=Zookeeper&spm=1001.2101.3001.7020)，也可以是数据库。

# 线程安全问题

线程安全是指要控制**多个线程对某个资源的有序访问或修改**，而在这些线程之间没有产生冲突。

在Java里，线程安全一般体现在两个方面：
1、多个thread对同一个java实例的访问（read和modify）不会相互干扰，它主要体现在关键字synchronized。如ArrayList和Vector，HashMap和Hashtable（后者每个方法前都有synchronized关键字）。如果你在interator一个List对象时，其它线程remove一个element，问题就出现了。
2、每个线程都有自己的字段，而不会在多个线程之间共享。它主要体现在java.lang.ThreadLocal类，而没有Java关键字支持，如像static、transient那样。



# 线程安全性（原子性+可见性）

i++不是线程安全的（不保证原子性），适用atomicinteger可以使之线程安全

一个类如果不是线程安全的，我们就说它在多线程环境下直接使用存在线程安全问题。线程安全问题概括来说表现为3个方面：原子性、可见性和有序性。 



线程安全需要保证几个基本特征？

原子性，简单说就是相关操作不会中途被其他线程干扰，一般通过同步机制实现。
可见性，是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，通常被解释为将
线程本地状态反映到主内存上，volatile 就是负责保证可见性的。
有序性，是保证线程内串行语义，避免指令重排等。

1、对象的状态：对象的状态是指存储在状态变量中的数据，对象的状态可能包括其他依赖对象的域。在对象的状态中包含了任何可能影响其外部可见行为的数据。
2、一个对象是否是线程安全的，取决于它是否被多个线程访问。这指的是在程序中访问对象的方式，而不是对象要实现的功能。当多个线程访问某个状态变量并且其中有一个线程执行写入操作时， 必须采用同步机制来协同这些线程对变量的访问。同步机制包括synchronized、volatile 变量、显式锁、原子变量

3、有三种方式可以修复线程安全问题：
1）不在线程之间共享该状态变量
2）将状态变量修改为不可变的变量
3）在访问状态变量时使用同步

 原子（Atomic）的字面意思是不可分割的（Indivisible）。对于涉及共享变量访问的操作，若该操作从其执行线程以外的任意线程来看是不可分割的，那么该操作就是原子操作，相应地我们称该操作具有原子性（Atomicity）。 许多资料都会提及原子操作的定义中的“不可分割”，但是很少有资料会对其含义做进一步的解释。而弄清楚“不可分割”的具体含义是理解原子性的关键所在**。所谓“不可分割”，其中一个含义是指访问（读、写）某个共享变量的操作从其执行线程以外的任何线程来看，该操作要么已经执行结束要么尚未发生，即其他线程不会“看到”该操作执行了部分的中间效果。**
原子操作是针对访问共享变量的操作而言的。也就是说，==仅涉及局部变量访问的操作无所谓是否是原子的==，或者干脆把这一类操作都看成原子操作，例如，在清单2-3中，nextSequence（int sequence）中的操作就是这样一类操作。 原子操作是从该操作的执行线程以外的线程来描述的，也就是说它只有在多线程环境下有意义。换言之，单线程环境下一个操作无所谓是否具有原子性，或者我们干脆把这一类操作都看成原子操作。

📣实现原子性：

总的来说，Java中有两种方式来实现原子性。一种是使用锁（Lock）。锁具有排他性，即它能够保障一个共享变量在任意一个时刻只能够被一个线程访问。这就排除了多个线程在同一时刻访问同一个共享变量而导致干扰与冲突的可能，即消除了竞态。另一种是利用处理器提供的专门CAS（Compare-and-Swap）指令，**CAS指令实现原子性的方式与锁实现原子性的方式实质上是相同的，差别在于锁通常是在软件这一层次实现的，而CAS是直接在硬件（处理器和内存）这一层次实现的**，它可以被看作“硬件锁”。 在Java语言中，long型和double型以外的任何类型的变量的写操作都是原子操作，即对基础类型（long/double除外，仅包括byte、boolean、short、char、float和int）的变量和引用型变量的写操作都是原子的。这点由Java语言规范（JLS，Java Language Specification）规定，由Java虚拟机具体实现。 

【可见性】在多线程环境下，一个线程对某个共享变量进行更新之后，后续访问该变量的线程可能无法立刻读取到这个更新的结果，甚至永远也无法读取到这个更新的结果。这就是线程安全问题的另外一个表现形式：可见性（Visibility）。 如果一个线程对某个共享变量进行更新之后，后续访问该变量的线程可以读取到该更新的结果，那么我们就称这个线程对该共享变量的更新对其他线程可见，否则我们就称这个线程对该共享变量的更新对其他线程不可见。可见性就是指一个线程对共享变量的更新的结果对于读取相应共享变量的线程而言是否可见的问题。多线程程序在可见性方面存在问题意味着某些线程读取到了旧数据（Stale Data），而这可能导致程序出现我们所不期望的结果。

4、线程安全性的定义：当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步，这个类都能表现出正确的行为，那么就称这个类是线程安全的。
**5、无状态变量一定是线程安全的，比如局部变量。**对于局部变量（包括形式参数和方法体内定义的变量），由于不同的线程各自访问的是各自的那一份局部变量，因此局部变量的使用不会导致竞态！例如，如下所示的nextSequence（）的方法体同时具备了check-then-act模式与read-modify-write模式的代码结构，但是由于其使用的变量sequence是一个局部变量（形式参数），因此它不会导致竞态。 

清单2-3　不会出现竞态的一个例子 

```java
public class NoRaceCondition {

 public int nextSequence(int sequence) {

  // 以下语句使用的是局部变量而非状态变量，并不会产生竞态
  if (sequence >= 999) {
   sequence = 0;
  } else {
   sequence++;
  }
  return sequence;
 }

}
```

 

6、读取-修改-写入操作序列，如果是后续操作是依赖于之前读取的值，那么这个序列必须是串行执行的。在并发编程中，由于不恰当的执行时序而出现不正确的结果是一种非常重要的情况，它称为竞态条件（Race Condition）。最常见的竞态条件类型就是先检查后执行的操作，通过一个可能失效的观测结果来决定下一步的操作。

==竞态的两种模式==：read-modify-write（读—改—写）和check-then-act（检测而后行动）。

 read-modify-write（读—改—写）操作，该操作可以被细分为这样几个步骤：读取一个共享变量的值（read），然后根据该值做一些计算（modify），接着更新该共享变量的值（write）。例如，在清单2-1中，nextSequence（）中的“sequence++”就是read-modify-write模式的一个实例。“sequence++”实际上相当于如下伪代码表示的几个指令的组合。

 load(sequence,r1);// 指令①read：从内存将sequence的值读到寄存器r1（读取共享变量值）
increment(r1);// 指令② modify：将寄存器r1的值增加1（根据共享变量值做一些计算）
store(sequence,r1);// 指令③ write：将寄存器r1的内容写入sequence对应的内存空间（更新共享变量）
**一个线程在执行完指令①之后到开始（或者正在）执行指令②的这段时间内其他线程可能已经更新了共享变量（sequence）的值**，这就使得该线程在执行指令②时使用的是共享变量的旧值（读脏数据）。接着，该线程把根据这个旧值计算出来的结果更新到共享变量，**而这又使得其他线程对该共享变量所做的更新被“覆盖”，即造成了更新丢失。**读者也可以根据二维表分析法自行分析多个线程并发执行上述代码的时候可能导致丢失更新和读脏数据的问题。 check-then-act（检测而后行动）操作，该操作可以被细分为这样几个步骤：读取某个共享变量的值，根据该变量的值决定下一步的动作是什么。

例如，在清单2-1中，nextSequence（）中的if-else语句就是该模式的一个实例。

```java
 if (sequence >= 999) { // 子操作①check：检测共享变量的值
 sequence = 0; // 子操作②act：下一步的操作

} else {
 sequence++;
}
```

  <font color="red">一个线程在执行完子操作①到开始（或者正在）执行子操作②的这段时间内，其他线程可能已经更新了共享变量的值而使得if语句中的条件变为不成立，那么此时该线程仍然会执行子操作②，尽管这个子操作所需的前提（if语句中的条件）实际上并未成立！ </font>





7、复合操作：要避免竞态条件问题，就必须在某个线程修改该变量时，通过某种方式防止其他线程使用这个变量，从而确保其他线程只能在修改操作完成之前或之后读取和修改状态，而不是在修改状态的过程中。假定有两个操作A 和B，如果从执行A 的线程看，当另一个线程执行B 时，要么将B 全部执行完，要么完全不执行B，那么A 和B 对彼此来说就是原子的。原子操作是指，对于访问同一个状态的所有操作来说，这个操作是一个以原子方式执行的操作。
**为了确保线程安全性，读取-修改-写入序列必须是原子的，将其称为复合操作。**复合操作包含了一组必须以原子方式执行的接口以确保线程安全性。原子操作是多线程环境下的一个概念，它是针对访问共享变量的操作而言的。原子操作的“不可分割”包括以下两层含义。 访问（读、写）某个共享变量的操作从其执行线程以外的任何线程来看，该操作要么已经执行结束要么尚未发生，**即其他线程不会“看到”该操作执行了部分的中间效果**。 访问同一组共享变量的原子操作是不能够被交错的。 
8、在无状态的类中添加一个状态时，如果这个状态完全由线程安全的对象来管理，那么这个类仍然是线程安全的。（比如原子变量）
9、如果多个状态是相关的，需要同时被修改，那么对多个状态的操作必须是串行的，需要进行同步。要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。
10、内置锁：synchronized(object){同步块}
Java 的内置锁相当于一种互斥体，这意味着最多只有一个线程能持有这种锁，当线程A 尝试获取一个由线程B 持有的锁时，线程A 必须等待或阻塞，直到线程B 释放这个锁。如果B永远不释放锁，那么A 也将永远地等待下去。



Java标准库中的一些类如ArrayList、HashMap和SimpleDateFormat，都是非线程安全的，在多线程环境下直接使用它们可能导致一些非预期的结果，甚至是一些灾难性的结果。比如，多线程环境下多个线程共享同一个HashMap实例（而不采取任何控制措施）可能导致死循环（表现为主机上的某个处理器使用率一直为100%）和内存泄漏（最后可能导致Java虚拟机崩溃）。一般来说，Java标准库中的类在其API文档（JavaDoc）中会说明其是否是线程安全的（没有说明其是否是线程安全的，则可能是也可能不是线程安全的）。 【为什么会死循环？】



# 异步编程

![image-20210914123827465](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210914123827465.png)

![image-20210914123953106](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210914123953106.png)

![image-20210914124043349](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210914124043349.png)

![image-20210914124146029](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210914124146029.png)

![image-20210914124227016](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210914124227016.png)

![image-20210914124348721](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210914124348721.png)

![image-20210914124507866](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210914124507866.png)







#  多线程基础

多线程除了增加编码难度外，它还在执行过程中带来实际的损耗，包括资源开销和上下文切换开销**。资源开销主要包括其本身占用的内存资源、执行时线程本地栈开销以及对这些线程进行管理的开销**。而上下文切换开销则是因为CPU由一个线程切换到另外一个线程是需要做==现场保护和现场恢复==工作，包括线程标识、寄存器内存、线程状态、线程优先级、线程资源清单等等。如下图所示，假设线程一和线程二由某个CPU执行。线程一执行一段时间后将相关信息保存到现场数据结构中，而线程数据结构存放在主存储中，然后从线程二对应的现场数据结构中恢复线程二相关信息，完成现场恢复后线程二开始执行。接下去的过程反过来，由线程二切换到线程一。 

final 修饰的变量是线程安全的

一个简易计时器：

```java
 private static int count;
    public static void main(String  [] args) {
        count = args.length >= 1 ? Integer.valueOf(args[0]) : 60;
        int remaining;
        while (true) {
            remaining = countDown();
            if (0 == remaining) {
                break;
            } else {
                System.out.println("Remaining " +count + " second(s)");
            }

            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                // 什么也不做
            }
        }
        System.out.println("Done.");
    }

    private static int countDown() {
        return count--;
    }
```

# sleep(0)的作用



Thread.Sleep(0)的作用，就是“触发操作系统立刻重新进行一次CPU竞争”。竞争的结果也许是当前线程仍然获得CPU控制权，也许会换成别的线程获得CPU控制权。这也是我们在大循环里面经常会写一句Thread.Sleep(0) ，因为这样就给了其他线程比如Paint线程获得CPU控制权的权力，这样界面就不会假死在那里。
另外，虽然上面提到说“除非它自己放弃使用 CPU ，否则将完全霸占 CPU”，但这个行为仍然是受到制约的——操作系统会监控你霸占CPU的情况，如果发现某个线程长时间霸占CPU，会强制使这个线程挂起，因此在实际上不会出现“一个线程一直霸占着 CPU 不放”的情况。至于我们的大循环造成程序假死，并不是因为这个线程一直在霸占着CPU。
实际上在这段时间操作系统已经进行过多次CPU竞争了，只不过其他线程在获得CPU控制权之后很短时间内马上就退出了，于是就又轮到了这个线程继续执行循环，于是就又用了很久才被操作系统强制挂起。。。因此反应到界面上，看起来就好像这个线程一直在霸占着CPU一样。 

当高优先级的线程sleep(5000)后，低优先级就有机会执行了。
总之，sleep()可以使低优先级的线程得到执行的机会，当然也可以让同优先级、高优先级的线程有执行的机会。



查看状态：

```java


public class examples {
    private boolean flag = false;
    public static void main(String[] args) throws InterruptedException{
        Thread new1  = new Thread(){
          
            @Override
            public void run()
            {
                try {
                    System.out.println( Class.forName("com.Thread2.examples").getName());
                }catch (ClassNotFoundException e)
                {}

              

            }
        };
        new1.setName("athread");
        System.out.println("before start:"+new1.getState());//before start:NEW
        new1.start();
        System.out.println("after start:"+new1.getState());//after start:RUNNABLE

        Thread.sleep(2);
        System.out.println("after sleep:"+new1.getState());//after sleep:TERMINATED
       // new1.interrupt();

        System.out.println(new1.getState());//TERMINATED
    }
}

```



# 多线程的状态

注意：等待状态是调用wait进入的等待

阻塞是遇见sychonized关键字未获取到锁进入锁池等待

![image-20220130015347534](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220130015347534.png)

![image-20220130015403868](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220130015403868.png)

![image-20220130015433030](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220130015433030.png)

阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃CPU 使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：
（一）、等待阻塞：运行的线程执行wait()方法，JVM 会把该线程放入等待池中。(wait会释放持有的锁)
（二）、同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM 会把该线程放入锁池中。
（三）、其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O 请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O 处理完毕时，线程重新转入就绪状态。（注意,sleep 是不会释放持有的锁）

## 结束线程的方法：

1.设置退出标志，使线程正常退出，正常地退出run()方法后线程结束。

例如：

```java
public class MyThread extends Thread {
    public volatile boolean exit = false; 
        public void run() { 
        while (!exit){
            //do something
        }
    } 
}
```



2.使用interrupt()方法终止线程。

然而interrupte()方法并不会立即执行中断操作；

如果在中断时，线程正处于非阻塞状态，则将中断标志修改为true,而在此基础上，一旦进入阻塞状态，则按照阻塞状态的情况来进行处理；例如，一个线程在运行状态中，其中断标志被设置为true,则此后，**一旦线程调用了wait、jion、sleep方法中的一种，立马抛出一个InterruptedException，且中断标志被清除，**重新设置为false。

我们可以总结，调用线程类的interrupted方法，其本质只是设置该线程的中断标志，将中断标志设置为true，并根据线程状态决定是否抛出异常。因此，通过interrupted方法真正实现线程的中断原理是：开发人员根据中断标志的具体值，来决定如何退出线程。

```java
public class ThreadTest {
 
    static class MyThread extends Thread {
        @Override
        public void run() {
            while (!isInterrupted()){ //非阻塞过程中通过判断中断标志来退出
                try{
                    Thread.sleep(5*1000);//阻塞过程捕获中断异常来退出
                }catch(InterruptedException e){
                    e.printStackTrace();
                    System.out.println("ThreadSafe:run()"+e.getMessage());
                    break;//捕获到异常之后，执行break跳出循环。
                }
            }
        }
    }
 
    public static void main(String[] args) throws Exception {
        Thread thread = new ThreadSafe();
        thread.start();
        System.out.println("在50秒之内按任意键中断线程!");
        System.in.read();
        thread.interrupt();
        Thread.sleep(5000);
        System.out.println("线程已经退出!thread.is" + thread.isAlive());
    }
 
}
```

：Thread.interrupt()并不能使得线程被中断，线程还是会执行。实际只是改变了被调用线程的内部中断状态：如果该线程被阻塞在Wait join sleep方法中，那么它的中断标志将被清除，还将收到一个interruptedException

3.使用stop方法强制终止线程（不推荐使用）

4.使用volatile开关控制

 由于线程的interrupt标识很有可能被擦除，或者逻辑单元中不会调用任何可中断方法，所以使用volatile修饰的开关flag关闭线程也是一种常用的做法，具体如下：

```java
 package com.wangwenjun.concurrent.chapter03;

import java.util.concurrent.TimeUnit;

public class FlagThreadExit
{

  static class MyTask extends Thread
  {

​    private volatile boolean closed = false;

​    @Override
​    public void run()
​    {
​      System.out.println("I will start work");
​      while (!closed && !isInterrupted())
​      {
​        //正在运行
​      }
​      System.out.println("I will be exiting.");
​    }
​    public void close()
​    {
​      this.closed = true;
​      this.interrupt();
​    }
  }

  public static void main(String[] args) throws InterruptedException
  {

​    MyTask t = new MyTask();
​    t.start();
​    TimeUnit.MINUTES.sleep(1);
​    System.out.println("System will be shutdown.");
​    t.close();
  }
```



上面的例子中定义了一个closed开关变量，并且是使用volatile修饰（关于volatile关键字会在本书的第3部分中进行非常细致地讲解，volatile关键字在Java中是一个革命性的关键字，非常重要，它是Java原子变量以及并发包的基础）运行上面的程序同样也可以关闭线程。 



## start() run()

start与run区别

1. start（）方法来启动线程，真正实现了多线程运行。这时无需等待run方法体代码执行完毕，可以直接继续执行下面的代码。start是一个native方法，通过在操作系统上启动一个新线程，并最终执行run方法来启动一个线程。run方法是线程类的具体实现逻辑。
2.  通过调用Thread类的start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。 
3. .方法run()称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运行run函数当中的代码。 Run方法运行结束， 此线程终止。然后CPU再调度其它线程。

调用start方法才会启动一个线程并使线程进入就绪状态，当分配了时间片以后就可以开始运行了，Start方法会执行线程相应的准备工作然后自动执行run方法的内容，而直接执行run方法会把这个方法当成main线程下的一个普通方法，并不会在某一个线程中执行它，并不是多线程工作。【总结：调用start方法才可以启动线程并进入就绪状态，而run方法只是一个普通方法调用，还是在主线程中执行】


自己试验的一个代码：当main先结束休眠时会抛出异常

```java
    public static class ThreadSafe extends Thread {
        public void run() {
                try{
                    System.out.println("开始了线程");
                    Thread.sleep(3*1000);//阻塞过程捕获中断异常来退出
                    System.out.println("结束休眠");
                }catch(InterruptedException e){
                    System.out.println("异常");
                    e.printStackTrace();
                }
            }
    }
    public static void main(String[] args) throws InterruptedException {
      ThreadSafe threadSafe = new ThreadSafe();
      threadSafe.start();
        System.out.println("main方法输出");
      Thread.sleep(2500);
        System.out.println("main结束休眠");
      threadSafe.interrupt();
    }
```

![image-20210725165426172](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210725165426172.png)

如果改成

```java
  public static void main(String[] args) throws InterruptedException {
      ThreadSafe threadSafe = new ThreadSafe();
      threadSafe.start();
        System.out.println("main方法输出");
      Thread.sleep(3000);
        System.out.println("main结束休眠");
      threadSafe.interrupt();
  }
```

则不会抛出异常

![image-20210725165514050](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210725165514050.png)



如果改成

```java
 public static void main(String[] args) throws InterruptedException {
      ThreadSafe threadSafe = new ThreadSafe();
      threadSafe.run();
        System.out.println("main方法输出");
      Thread.sleep(3100);
        System.out.println("main结束休眠");
      threadSafe.interrupt();

    }
```

相当于只有run()方法体执行完毕之后才会执行System.out.println("main方法输出");

结果：

![image-20210725165623487](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210725165623487.png)





## Interrupted Exception（）函数与interrupt（）函数 

interrupt()方法是一个实例方法，它通知目标线程中断，也就是设置中断标志位为true，中断标志位表示当前线程已经被中断了。**中断一个线程，其本意是给这个线程一个通知信号，会影响这个线程内部的一个中断标识位。这个线程本身并不会因此而改变状态(如阻塞，终止等)**。isInterrupted()方法也是一个实例方法，它判断当前线程是否被中断（通过检查中断标志位）。最后一个方法interrupted()是一个静态方法，返回boolean类型，也是用来判断当前线程是否被中断，**但是同时会清除当前线程的中断标志位的状态。**

1. 调用interrupt()方法并不会中断一个正在运行的线程。也就是说处于Running 状态的线程并不会因为被中断而被终止，仅仅改变了内部维护的中断标识位而已。
2. 若调用sleep()而使线程处于TIMED-WATING 状态，这时调用interrupt()方法，会抛出InterruptedException,从而使线程提前结束TIMED-WATING 状态。

3. 许多声明抛出InterruptedException 的方法(如Thread.sleep(long mills 方法))，抛出异常前，都会清除中断标识位，所以抛出异常后，调用isInterrupted()方法将会返回false。
4. 中断状态是线程固有的一个标识位，可以通过此标识位安全的终止线程。比如,你想终止一个线程thread 的时候，可以调用thread.interrupt()方法，在线程的run 方法内部可以根据thread.isInterrupted()的值来优雅的终止线程。



Java中interrupted 和isInterruptedd方法的区别？
interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。
Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。当中断线程调用静态方法Thread.interrupted()来检查中断状态时，中断状态会被清零。
非静态方法isInterrupted()用来查询其它线程的中断状态且不会改变中断状态标识。简单的说就是任何抛出InterruptedException异常的方法都会将中断状态清零。
无论如何，一个线程的中断状态都有可能被其它线程调用中断来改变



 1.2.1 什么情况下会抛出Interrupted异常 Interrupt这个词很容易让人产生误解。从字面意思来看，好像是说一个线程运行到一半，把它中断了，然后抛出了InterruptedException异常，其实并不是。仍以上面的代码为例，假设while循环中没有调用任何的阻塞函数，就是通常的算术运算，或者打印一行日志，如下所示。 

```java
public void run(){
while(!stopped)
{
int a = 1,b = 2;
int c = a+b;
System.out.println("..");
}
}
```

这个时候，在主线程中调用一句t.interrupt（），请问该线程是否会抛出异常？答案是不会。 再举一个例子，假设这个线程阻塞在一个 synchronized 关键字的地方，正准备拿锁，如下代码所示。  

```java
public void run(){
while(!stopped)
{
synchronized(obj1){
int a = 1,b = 2;
int c = a+b;
System.out.println("..");
}
}
}
```

这个时候，在主线程中调用一句t.interrupt（），请问该线程是否会抛出异常？答案是不会。 **实际上，只有那些声明了会抛出 InterruptedException 的函数才会抛出异常**，也就是下面这些常用的函数：

```java
public static native void sleep(long mills) throws InterruptedException ;
public final void wait() throws InterruptedException {...}
public final void join() throws InterruptedException {...}
```

这里强调一点，Object.wait()方法并不能随便调用。它必须包含在对应的synchronize语句汇总，无论是wait()方法或者notify()方法都需要首先获取目标独享的一个监视器。

使用interrupt()方法来中断线程有两种情况：

1. 线程处于阻塞状态：如使用了sleep,同步锁的wait,socket中的receiver,accept等方法时，会使线程处于阻塞状态。当调用线程的interrupt()方法时，会抛出InterruptException异常。**阻塞中的那个方法抛出这个异常，通过代码捕获该异常，然后break跳出循环状态，从而让我们有机会结束这个线程的执行。**通常很多人认为只要调用interrupt方法线程就会结束，实际上是错的， 一定要先捕获InterruptedException异常之后通过break来跳出循环，才能正常结束run方法。 
2. 线程未处于阻塞状态：使用isInterrupted()判断线程的中断标志来退出循环。当使用interrupt()方法时，中断标志就会置true，和使用自定义的标志来控制循环是一样的道理。

```java

public class tthread {
    public static class ThreadSafe extends Thread {
        public void run() {
            while (!isInterrupted()){ //非阻塞过程中通过判断中断标志来退出
                try{
                    System.out.println("开始了线程");
                    Thread.sleep(5*1000);//阻塞过程捕获中断异常来退出
                }catch(InterruptedException e){
                    System.out.println("异常");
                    e.printStackTrace();
                    break;//捕获到异常之后，执行break跳出循环
                }
            }
            if(isInterrupted())
                System.out.println("中断");
        }
    }

    public static void main(String[] args) throws InterruptedException {
      ThreadSafe threadSafe = new ThreadSafe();
      threadSafe.start();
      Thread.sleep(3000);
      threadSafe.interrupt();
        //如果注释掉//threadSafe.interrupt(); 则会一直输出”开始了线程“

    }
}

```



![image-20210725164619161](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210725164619161.png)





## join()

join() 方法，等待其他线程终止，在当前线程中调用一个线程的 join() 方法，则当前线程转为阻塞状态，回到另一个线程结束，当前线程再由阻塞状态变为就绪状态，等待 cpu 的宠幸。

为什么要用join()方法？
很多情况下，主线程生成并启动了子线程，需要用到子线程返回的结果，也就是需要主线程需要在子线程结束后再结束，这时候就要用到 join() 方法。

```java
System.out.println(Thread.currentThread().getName() + "线程运行开始!");
Thread6 thread1 = new Thread6();
thread1.setName("线程B");
thread1.join();
System.out.println("这时thread1 执行完毕之后才能执行主线程");
```

如果线程A调用线程B的jion方法，那么线程A的运行会暂停，直到线程B运行结束

### 希望 B 在 A 全部打印 完后再开始打印:

```java
private static void demo2() {  
    Thread A = new Thread(new Runnable() {  
        @Override  
        public void run() {  
            printNumber("A");  
        }  
    });  
    Thread B = new Thread(new Runnable() {  
        @Override  
        public void run() {  
            System.out.println("B 开始等待 A");  
            try {  
                A.join();  // A.join() 方法会让 B 一直等待直到 A 运行完毕。
            } catch (InterruptedException e) {  
                e.printStackTrace();  
            }  
            printNumber("B");  
        }  
    });  
    B.start();  
    A.start();  
}  


```



## sleep方法和wait方法有什么区别

对于sleep()方法，我们首先要知道该方法是属于Thread类中的。而wait()方法，则是属于Object类中的。
sleep()方法导致了程序暂停执行指定的时间，让出cpu给其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态。在调用sleep()方法的过程中，线程不会释放对象锁。
当调用wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池准备，获取对象锁进入运行状态

1. sleep 是线程类（Thread）的方法，导致此线程暂停执行指定时间，给执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep 不会释放对象锁。sleep()使当前线程进入**阻塞状态**，在指定时间内不会执行。
2. wait 是Object 类的方法，对此对象调用wait 方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify 方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态

wait必须放在同步块或同步⽅法中，⽽sleep可以在任意位置、

sleep 必须捕获异常，而wait，notify 和notifyAll 不需要捕获异常在sleep 的过程中过程中有可能被其他对象调用它的interrupt(),产生InterruptedException 异常，如果你的程序不捕获这个异常，线程就会异常终止，进入TERMINATED 状态，如果你的程序捕获了这个异常，那么程序就会继续执行catch 语句块(可能还有finally 语句块)以及以后的代码



## 线程的sleep()方法和yield()方法有什么区别？

① sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；

比如有两个线程同时执行(没有Synchronized)，一个线程优先级为MAX_PRIORITY，另一个为MIN_PRIORITY，如果没有Sleep()方法，只有高优先级的线程执行完成后，低优先级的线程才能执行；但当高优先级的线程sleep(5000)后，低优先级就有机会执行了。总之，sleep()可以使低优先级的线程得到执行的机会，当然也可以让同优先级、高优先级的线程有执行的机会

yield()方法只会给相同优先级或更高优先级的线程以运行的机会；
② 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态；
③ sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常；
④ sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性。





## wait() notify()

wait()方法是object的方法而不是Thread的方法

Object的wait（long timeout）方法会导致当前线程进入阻塞，直到有其他线程调用了Object的notify或者notifyAll方法才能将其唤醒，或者阻塞时间到达了timeout时间而自动唤醒**。该方法用来将当前线程置入“预执行队列”中，并在wait所在代码处停止执行，直到接到通知或者中断为止。   wait方法必须拥有该对象的monitor，也就是wait方法必须在同步方法中使用**。 当前线程执行了该对象的wait方法之后，将会放弃对该monitor的所有权并且进入与该对象关联的wait set中，也就是说一旦线程执行了某个object的wait方法之后，它就会释放对该对象monitor的所有权，其他线程也会有机会继续争抢该monitor的所有权。

图2.6显示了wait()方法和nofiy()方法的工作流程细节。其中T1和T2表示两个线程。T1在正确执行wait()方法钱，必须获得object对象的监视器。而wait()方法在执行后，会释放这个监视器。这样做的目的是使其他等待在object对象上的线程不至于因为T1的休眠而全部无法正常执行。

![image-20210725123500824](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210725123500824.png)

线程T2在notify()方法调用前，也必须获得object对象的监视器。所幸，此时T1已经释放了这个监视器，因此，T2可以顺利获得object对象的监视器。接着，T2执行了notify()方法尝试唤醒一个等待线程，这里假设唤醒了T1。T1在被唤醒后，要做的第一件事并不是执行后续代码，而是要尝试重新获得object对象的监视器，而这个监视器也正是T1在wait()方法执行前所持有的那个。如果暂时无法获得，
则T1还必须等待这个监视器。当监视器顺利获得后，T1才可以在真正意义上继续执行。 

==wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别==
wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：**wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器。**

例子：

```java

public class tthread {
    static Object object = new Object();
    public static class T1 extends Thread
    {
        @Override
        public void run(){
            synchronized (object)
            {
                System.out.println("t1 is beginning");
                try {
                    System.out.println("t1 will wait:");
                    object.wait();
                }
                catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
                System.out.println("t1 end!v");
            }
        }
    }

    public static class t2 extends Thread{
        @Override
        public void run()
        {
            System.out.println("t2 start");
            synchronized (object)
            {
                object.notify();
                System.out.println("t2刚刚执行完notify");
                try {
                    System.out.println("t2休眠2秒");
                  Thread.sleep(2000);
                }
                catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
                System.out.println("t2 end");
            }
        }
    }

    public static void main(String[] args) {
        new T1().start();
        new t2().start();
    }
}

```

注意下打印结果，**T2调用notify方法之后，T1并不能立即继续执行，而是要等待T2释放objec投递锁之后，T1重新成功获取锁后**，才能继续执行。因此最后2行日志相差了2秒（因为T2调用notify方法后休眠了2秒）。
注意：Object.wait()方法和Thread.sleep()方法都可以让现场等待若干时间。除wait()方法可以被唤醒外，另外一个主要的区别就是wait()方法会释放目标对象的锁，而Thread.sleep()方法不会释放锁

![image-20210725130421892](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210725130421892.png)

上面过程需要：创建一个两个线程可以共享的对象锁，其中一个调用wait()方法后交出锁的控制权，之后由另一个线程的notify()唤醒

☻☻☻为什么wait()方法和notify()/notifyAll()方法要在同步块中被调用
这是JDK强制的，wait()方法和notify()/notifyAll()方法在调用前都必须先获得对象的锁



## notify() notifyAll()



notify可能会导致死锁，而notifyAll则不会
任何时候只有一个线程可以获得锁，也就是说只有一个线程可以运行synchronized 中的代码
使用notifyall,可以唤醒 所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。
wait() 应配合while循环使用，不应使用if，务必在wait()调用前后都检查条件，如果不满足，必须调用notify()唤醒另外的线程来处理，自己继续wait()直至条件满足再往下执行。
notify() 是对notifyAll()的一个优化，但它有很精确的应用场景，并且要求正确使用。不然可能导致死锁。正确的场景应该是 WaitSet中等待的是相同的条件，唤醒任一个都能正确处理接下来的事项，如果唤醒的线程无法正确处理，务必确保继续notify()下一个线程，并且自身需要重新回到WaitSet中.





## condition唤醒指定种类的线程

通过此实验可以得知，使用ReentrantLock对象可以唤醒指定种类的线程，这是控制部分线程行为的方便方式。

```java
package service;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
public class MyService {
private Lock lock = new ReentrantLock();
public Condition conditionA = lock.newCondition();
public Condition conditionB = lock.newCondition();
public void awaitA() {
  try {
    lock.lock();
    System.out.println("begin awaitA时间为" + System.currentTimeMillis()
        \+ " ThreadName=" + Thread.currentThread().getName());
    conditionA.await();
    System.out.println(" end awaitA时间为" + System.currentTimeMillis()
        \+ " ThreadName=" + Thread.currentThread().getName());
  } catch (InterruptedException e) {
    e.printStackTrace();
  } finally {
    lock.unlock();
  }
}
public void awaitB() {
  try {
    lock.lock();
    System.out.println("begin awaitB时间为" + System.currentTimeMillis()
        \+ " ThreadName=" + Thread.currentThread().getName());
    conditionB.await();
    System.out.println(" end awaitB时间为" + System.currentTimeMillis()
        \+ " ThreadName=" + Thread.currentThread().getName());
  } catch (InterruptedException e) {
    e.printStackTrace();
  } finally {
    lock.unlock();
  }
}
public void signalAll_A() {
  try {
    lock.lock();
    System.out.println(" signalAll_A时间为" + System.currentTimeMillis()
        \+ " ThreadName=" + Thread.currentThread().getName());
    conditionA.signalAll();
  } finally {
    lock.unlock();
  }
}
public void signalAll_B() {
  try {
    lock.lock();
    System.out.println(" signalAll_B时间为" + System.currentTimeMillis()
        \+ " ThreadName=" + Thread.currentThread().getName());
    conditionB.signalAll();
  } finally {
    lock.unlock();
  }
}
}
```

```java
public class ThreadA extends Thread
{
    private MyService myservice;
    public ThreadA(MyService myservice)
    {
        super();
        this.service = service;
    }
    @Override
    public void run()
    {
        service.awaitA();
    }
}

public class ThreadB extends Thread
{
    private MyService myservice;
    public ThreadB(MyService myservice)
    {
        super();
        this.service = service;
    }
    @Override
    public void run()
    {
        service.awaitA();
    }
}
```



类Run.java代码如下： 

```java
package test;
import service.MyService;
import extthread.ThreadA;
import extthread.ThreadB;
public class Run {
public static void main(String[] args) throws InterruptedException {
  MyService service = new MyService();
  ThreadA a = new ThreadA(service);
  a.setName("A");
  a.start();
  ThreadB b = new ThreadB(service);
  b.setName("B");
  b.start();
  Thread.sleep(3000);
  service.signalAll_A();
}
}


```

结果是只有a被唤醒

## 使用Condition实现顺序执行 

使用Condition对象可以对线程执行的业务进行排序规划。 创建实验用的项目condition123，类F.java代码如下： 

```java
package finaltools;
public class F {
volatile public static int nextPrintWho = 1;
} 
```



创建运行类Run.java代码如下： 

```java
package test.run;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.ReentrantLock;
public class Run {
volatile private static int nextPrintWho = 1;
private static ReentrantLock lock = new ReentrantLock();
final private static Condition conditionA = lock.newCondition();
final private static Condition conditionB = lock.newCondition();
final private static Condition conditionC = lock.newCondition();
public static void main(String[] args) {
  Thread threadA = new Thread() {
    public void run() {
      try {
        lock.lock();
        while (nextPrintWho != 1) {
          conditionA.await();
        }
        for (int i = 0; i < 3; i++) {
          System.out.println("ThreadA " + (i + 1));
        }
        nextPrintWho = 2;
        conditionB.signalAll();
      } catch (InterruptedException e) {
        e.printStackTrace();
      } finally {
        lock.unlock();
      }
    }
  };
  Thread threadB = new Thread() {
    public void run() {
      try {
        lock.lock();
        while (nextPrintWho != 2) {
          conditionB.await();
        }
        for (int i = 0; i < 3; i++) {
          System.out.println("ThreadB " + (i + 1));
        }
        nextPrintWho = 3;
        conditionC.signalAll();
      } catch (InterruptedException e) {
        e.printStackTrace();
      } finally {
        lock.unlock();
      }
    }
  };
  Thread threadC = new Thread() {
    public void run() {
      try {
        lock.lock();
        while (nextPrintWho != 3) {
          conditionC.await();
        }
        for (int i = 0; i < 3; i++) {
          System.out.println("ThreadC " + (i + 1));
        }
        nextPrintWho = 1;
        conditionA.signalAll();
      } catch (InterruptedException e) {
        e.printStackTrace();
      } finally {
        lock.unlock();
      }
    }
  };
  Thread[] aArray = new Thread[5];
  Thread[] bArray = new Thread[5];
  Thread[] cArray = new Thread[5];
  for (int i = 0; i < 5; i++) {
    aArray[i] = new Thread(threadA);
    bArray[i] = new Thread(threadB);
    cArray[i] = new Thread(threadC);
    aArray[i].start();
    bArray[i].start();
    cArray[i].start();
  }
}
}


```



## 么是阻塞（Blocking）和非阻塞（Non-Blocking）？
阻塞和非阻塞通常用来形容多线程间的相互影响。比如一个线程占用了临界区资源，**那么其他所有需要这个资源的线程就必须在这个临界区中进行等待。等待会导致线程挂起，这种情况就是阻塞。**此时，如果占用资源的线程一直不愿意释放资源，那么其他所有阻塞在这个临界区上的线程都不能工作。
非阻塞的意思与之相反，**它强调没有一个线程可以妨碍其他线程执行。所有的线程都会尝试不断前向执行。**





## suspend() yield()

线程挂起使用线程实例方法suspend()，恢复线程使用线程实例方法resume()，这2个方法都过时了，不建议使用

系统不推荐使用suspend()方法去挂起线程是因为suspend()方法导致线程暂停的同时，并不会释放任何锁资源。此时，其他任何线程想要访问被它占用的锁时，都会被牵连，导致无法正常运行。直到在对应的线程上进行了resume()方法操作，被挂起的线程才能继续，从而其他所有阻塞在相关锁上的线程也可以继续执行。但是，如果resume()方法操作意外地在suspend()方法前就被执行了，
那么被挂起的线程可能很难有机会被继续执行了。并且，更严重的是：它所占用的锁不会被释放，因此可能会导致整个系统工作不正常。而且，对于被挂起的线程，从它线程的状态上看，居然还是
Runnable状态，这也会影响我们队系统当前状态的判断。



public static native void yield();

yield是谦让的意思，这是一个静态方法，一旦执行，它会让当前线程出让CPU，但需要注意的是，出让CPU并不是说不让当前线程执行了，当前线程在出让CPU后，还会进行CPU资源的争夺，但是能否再抢到CPU的执行权就不一定了。因此，对Thread.yield()方法的调用好像就是在说：我已经完成了一些主要的工作，我可以休息一下了，可以让CPU给其他线程一些工作机会了。

yield 会使当前线程让出CPU 执行时间片，与其他线程一起重新竞争CPU 时间片。一般情况下，优先级高的线程有更大的可能性成功竞争得到CPU 时间片，但这又不是绝对的，有的操作系统对线程优先级并不敏感。





1.2.2 轻量级阻塞与重量级阻塞 

能够被中断的阻塞称为轻量级阻塞，对应的线程状态是WAITING或者TIMED_WAITING；而像 synchronized 这种不能被中断的阻塞称为重量级阻塞，对应的状态是 BLOCKED。

初始线程处于NEW状态，调用start（）之后开始执行，进入RUNNING或者READY状态。如果没有调用任何的阻塞函数，线程只会在RUNNING和READY之间切换，也就是系统的时间片调度。这两种状态的切换是操作系统完成的，开发者基本没有机会介入，除了可以调用yield（）函数，放弃对CPU的占用。 一旦调用了图中的任何阻塞函数，线程就会进入WAITING或者TIMED_WAITING状态，两者的区别只是前者为无限期阻塞，后者则传入了一个时间参数，阻塞一个有限的时间。如果使用了synchronized关键字或者synchronized块，则会进入BLOCKED状态。 除了常用的阻塞/唤醒函数，还有一对不太常见的阻塞/唤醒函数，LockSupport.park（）/unpark（）。这对函数非常关键，Concurrent包中Lock的实现即依赖这一对操作原语。 

**故而t.interrupted（）的精确含义是“唤醒轻量级阻塞”，而不是字面意思“中断一个线程”。** 

1.2.3 t.isInterrupted（）与Thread.interrupted（）的区别 

**因为 t.interrupted（）相当于给线程发送了一个唤醒的信号，所以如果线程此时恰好处于WAITING或者TIMED_WAITING状态，就会抛出一 个InterruptedException，并且线程被唤醒。**而如果线程此时并没有被阻塞，则线程什么都不会做。但在后续，线程可以判断自己是否收到过其他线程发来的中断信号，然后做一些对应的处理，这也是本节要讲的两个函数。 这两个函数都是线程用来判断自己是否收到过中断信号的，前者是非静态函数，后者是静态函数。二者的区别在于，前者只是读取中断状态，不修改状态；后者不仅读取中断状态，还会重置中断标志位。 



(一个小问题)

下面自己写的一个代码，发现每次输出结果都不一样：

```java
    public static void main(String[] args) throws InterruptedException{
        Thread new1  = new Thread(){

            @SneakyThrows
            @Override
            public void run()
            {
              while (true)
              {
                  if(this.isInterrupted()) {
                      System.out.println("退出！");
                      break;
                  }
                  else {
                      System.out.println("new thread");

                  }
              }


            }
        };
        new1.setName("athread");

        new1.start();
        System.out.println("no.1"+new1.isInterrupted());//输出false
      new1.interrupt();
        System.out.println(new1.isInterrupted());//输出true
        System.out.println(new1.getState());//runnable
        System.out.println(new1.isInterrupted());
    }
```

下面分别是两个结果：

no.1false
true
退出！
RUNNABLE
false



no.1false
new thread
退出！
true
TERMINATED
false





##  Thread.sleep(0)的作用是什么
由于Java采用抢占式的线程调度算法，因此可能会出现某条线程常常获取到CPU控制权的情况，为了让某些优先级比较低的线程也能获取到CPU控制权，**可以使用Thread.sleep(0)手动触发一次操作系统分配时间片的操作，这也是平衡CPU控制权的一种操作。**

##   如何优雅的设置睡眠时间？



jdk1.5后，弓|入了一个枚举TimeUnit,对sleep方法提供了很好的封装。

比如要表达2小时22分55秒899毫秒。

Thread,sleep(8575899L);

TimeUnit・HOURS・sleep(3);

TimeUnit-MINUTES. sleep(22); •

TimeUnit ・ SECONDS・ sleep(55);

TimeUnit・MILLISECONDS・sleep(899);





## LockSupport 工具

定义了一组公共静态方法，提供了最基本的线程阻塞和唤醒功能。
实际上是调用了unsafe里的函数

void park()
阻塞当前线程，如果调用unpark(Tluead thread)方法或者当前线程被中断.才 能从park()方法返回

void parkNanos(long nanos)
阻塞当前线程，最长不超过nanos纳秒.返回条件在park()的基础上增加了 超时返回

void parkUntil(long deadline)
阻塞当前线程,直到deadline时间(从1970年开始到deadline时间的毫秒数)

void unpark(Thread thiead)
唤醒处于阻塞状态的线程thread



## 线程类的构造方法、静态块是被哪个线程调用的

这是一个非常刁钻和狡猾的问题。请记住：**线程类的构造方法、静态块是被new这个线程类所在的线程所调用的，而run方法里面的代码才是被线程自身所调用的。**
如果说上面的说法让你感到困惑，那么我举个例子，假设Thread2中new了Thread1，main函数中new了Thread2，那么：
1、Thread2的构造方法、静态块是main线程调用的，Thread2的run()方法是Thread2自己调用的
2、Thread1的构造方法、静态块是Thread2调用的，Thread1的run()方法是Thread1自己调用的





## run()方法抛出异常时的处理机制



因为run()方法不支持throws语句，所以当线程对象的run()方法抛出非运行异常时，我们必须捕获并且处理它们。当运行时异常从run()方法中抛出时，默认行为是在控制台输出堆栈记录并且退出程序。
好在，java提供给我们一种在线程对象里捕获和处理运行时异常的一种机制。实现用来处理运行时异常的类，**这个类实现UncaughtExceptionHandler接口并且实现这个接口的uncaughtException()方法**。示例：

```java
public class Main2 {
public static void main(String[] args) {
    Task task = new Task();
Thread thread = new Thread(task);
thread.setUncaughtExceptionHandler(new ExceptionHandler());
thread.start();
}
}
class Task implements Runnable{
@Override
public void run() {
int numero = Integer.parseInt("TTT");
}
}
class ExceptionHandler implements UncaughtExceptionHandler{
@Override
public void uncaughtException(Thread t, Throwable e) {
System.out.printf("An exception has been captured\n");
System.out.printf("Thread: %s\n", t.getId());
System.out.printf("Exception: %s: %s\n",
e.getClass().getName(),e.getMessage());
System.out.printf("Stack Trace: \\n");
e.printStackTrace(System.out);
System.out.printf("Thread status: %s\n",t.getState());
}
}
```







当一个线程抛出了异常并且没有被捕获时（这种情况只可能是运行时异常），**JVM检查这个线程是否被预置了未捕获异常处理器**。如果找到，JVM将调用线程对象的这个方法，并将线程对象和异常作为传入参数。
**Thread类还有另一个方法可以处理未捕获到的异常，即静态方法**
**setDefaultUncaughtExceptionHandler()。**这个方法在应用程序中为所有的线程对象创建了一个异常处理器。
当线程抛出一个未捕获到的异常时，JVM将为异常寻找以下三种可能的处理器。
首先，它查找线程对象的未捕获异常处理器。
如果找不到，JVM继续查找线程对象所在的线程组（ThreadGroup）的未捕获异常处理器。
如果还是找不到，如同本节所讲的，JVM将继续查找默认的未捕获异常处理器。
如果没有一个处理器存在，JVM则将堆栈异常记录打印到控制台，并退出程序。



## 同步方法和同步块，哪个是更好的选择
同步块，这意味着同步块之外的代码是异步执行的，这比同步整个方法更提升代码的效率。请知道一条原则：同步的范围越小越好。
借着这一条，我额外提一点，虽说同步的范围越少越好，但是在Java虚拟机中还是存在着一种叫做锁粗化的优化方法，这种方法就是把同步范围变大，即将锁的作用域变大。这是有用的，比方说StringBuffer，它是一个线程安全的类，自然最常用的append()方法是一个同步方法，**我们写代码的时候会反复append字符串，这意味着要进行反复的加锁->解锁，这对性能不利，因为这意味着Java虚拟机在这条线程上要反复地在内核态和用户态之间进行切换**，因此Java虚拟机会将多次append方法调用的代码进行一个锁粗化的操作，将多次的append的操作扩展到append方法的头尾，变成一个大的同步块，这样就减少了加锁-->解锁的次数，有效地提升了代码执行的效率。



## 怎么唤醒一个阻塞的线程

BLOCKED：一个线程发起一个阻塞式I/O（Blocking I/O）操作后，或者申请一个由其他线程持有的独占资源（比如锁）时，相应的线程会处于该状态。处于BLOCKED状态的线程并不会占用处理器资源。当阻塞式I/O操作完成后，或者线程获得了其申请的资源，该线程的状态又可以转换为RUNNABLE。 

WAITING：一个线程执行了某些特定方法之后就会处于这种等待其他线程执行另外一些特定操作的状态。能够使其执行线程变更为WAITING状态的方法包括：Object.wait（）、Thread.join（）和LockSupport.park（Object）。能够使相应线程从WAITING变更为RUNNABLE的相应方法包括：Object.notify（）/notifyAll（）和LockSupport.unpark（Object））。

如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程， 并且通过抛出InterruptedException 来唤醒它；如果线程遇到了IO 阻塞，无能为力，因为IO 是操作系统实现的，Java 代码并没有办法直接接触到操作系统。

**获取锁的线程释放锁只会有两种情况：**
1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有；
2）线程执行发生异常，此时JVM 会让线程自动释放锁。



## Java 中用到的线程调度算法是什么

抢占式。一个线程用完CPU 之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。

## 什么是线程安全,实现线程安全的方式

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量 的值也和预期的是一样的，就是线程安全的。一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误


线程安全 - 如果线程执行过程中不会产生共享资源的冲突，则线程安全。
线程不安全 - 如果有多个线程同时在操作主内存中的变量，则线程不安全
实现线程安全的三种方式
1）互斥同步

　临界区：syncronized、ReentrantLock

互斥同步锁也叫做阻塞同步锁，特征是会对没有获取锁的线程进行阻塞。

要理解互斥同步锁，首选要明白什么是互斥什么是同步。简单的说互斥就是非你即我，同步就是顺序访问。互斥同步锁就是以互斥的手段达到顺序访问的目的。操作系统提供了很多互斥机制比如信号量，互斥量，临界区资源等来控制在某一个时刻只能有一个或者一组线程访问同一个资源。

Java里面的互斥同步锁就是Synchorized和ReentrantLock，前者是由语言级别实现的互斥同步锁，理解和写法简单但是机制笨拙，在JDK6之后性能优化大幅提升，即使在竞争激烈的情况下也能保持一个和ReentrantLock相差不多的性能，所以JDK6之后的程序选择不应该再因为性能问题而放弃synchorized。ReentrantLock是API层面的互斥同步锁，需要程序自己打开并在finally中关闭锁，和synchorized相比更加的灵活，体现在三个方面：等待可中断，公平锁以及绑定多个条件。但是如果程序猿对ReentrantLock理解不够深刻，或者忘记释放lock，那么不仅不会提升性能反而会带来额外的问题。另外synchorized是JVM实现的，可以通过监控工具来监控锁的状态，遇到异常JVM会自动释放掉锁。而ReentrantLock必须由程序主动的释放锁。

互斥同步锁都是可重入锁。但是因为涉及到核心态和用户态的切换，因此比较消耗性能。JVM开发团队在JDK5-JDtteK6升级过程中采用了很多锁优化机制来优化同步无竞争情况下锁的性能。比如：自旋锁和适应性自旋锁，轻量级锁，偏向锁，锁粗化和锁消除。


　　信号量 semaphore
　　互斥量　mutex
2）非阻塞同步
　　CAS（Compare And Swap）

非阻塞同步锁也叫乐观锁，相比悲观锁来说，它会先进行资源在工作内存中的更新，然后根据与主存中旧值的对比来确定在此期间是否有其他线程对共享资源进行了更新，如果旧值与期望值相同，就认为没有更新，可以把新值写回内存，否则就一直重试直到成功。它的实现方式依赖于处理器的机器指令：CAS（Compare And Swap）

**JUC中提供了几个Automic类以及每个类上的原子操作就是乐观锁机制**。

不激烈情况下，性能比synchronized略逊，而激烈的时候，也能维持常态。激烈的时候，Atomic的性能会优于ReentrantLock一倍左右。但是其有一个缺点，就是只能同步一个值，一段代码中只能出现一个Atomic的变量，多于一个同步无效。因为他不能在多个Atomic之间同步。 

非阻塞锁是不可重入的，否则会造成死锁。


3）无同步方案
可重入代码
　 使用Threadlocal 类来包装共享变量，做到每个线程有自己的copy线程本地存储



## 如何确保线程安全？
对非安全的代码进行加锁控制
使用线程安全的类
多线程并发情况下，线程共享的变量改为方法级的局部变量



## 什么是竞态条件？你怎样发现和解决竞争？
当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件。
在临界区中使用适当的同步就可以避免竞态条件。
临界区实现方法有两种，一种是用synchronized，一种是用Lock显式锁实现。





## 举例说明同步和异步。
如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就必须进行同步存取（数据库操作中的排他锁就是最好的例子）。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。事实上，所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。



## 手动停止线程

不使用stop停止线程？
当run() 或者 call() 方法执行完的时候线程会自动结束,如果要手动结束一个线程，你可以用volatile 布尔变量来退出run()方法的循环或者是取消任务来中断线程。
**使用自定义的标志位决定线程的执行情况**

```java
public class SafeStopThread implements Runnable{
private volatile boolean stop=false;//此变量必须加上volatile
int a=0;
@Override
public void run() {
// TODO Auto-generated method stub
while(!stop){
synchronized ("") {
a++;
try {
Thread.sleep(100);
} catch (Exception e) {
// TODO: handle exception
}
a--;
String tn=Thread.currentThread().getName();
System.out.println(tn+":a="+a);
}
}
//线程终止
public void terminate(){
stop=true;
}
public static void main(String[] args) {
SafeStopThread t=new SafeStopThread();
Thread t1=new Thread(t);
t1.start();
for(int i=0;i<5;i++){
new Thread(t).start();
}
t.terminate();
}
}
```





## 单例模式的线程安全性

老生常谈的问题了，首先要说的是单例模式的线程安全意味着： 某个类的实例在多线程环境下只会被创建一次出来。单例模式有很多种的写法， 我总结一下：
1、饿汉式单例模式的写法：线程安全
2、懒汉式单例模式的写法：非线程安全
3、双检锁单例模式的写法：线程安全



### 指令重排序是什么

指令重排是为了提高在多处理器环境下程序的运行效率，怎么提高？
比如 两个处理器同时处理两个共享变量  
处理器1  变量a++ 变量b++
处理器2  变量a++ 变量b++
这个时候两个处理器都先执行a++操作 为了保证数据的安全 肯定要一
个一个来，一个一个来的话那么势必要有一个处理器处于闲置状态等
待另一个处理器操作共享变量完成它才能运行，这样的话就造成了cpu
资源的浪费。


简单地说，每⼀个指令都会包含多个步骤，每个步骤可能使⽤不同的硬件。因此，流⽔线技术产⽣了，它的原理是指令1还没有执⾏完，就可以开始执⾏指令2，⽽不⽤等到指令1执⾏结束之后再执⾏指令2，这样就⼤⼤提⾼了效率。**指令重排对于提⾼CPU处理性能⼗分必要。虽然由此带来了乱序的问题，但是这点牺牲是值得的**

当进行指令重排优化后 可能会变成这样啦
处理器1  变量a++ 变量b++
处理器2  变量b++ 变量a++ 
当处理器1操作a的时候 处理器2在操作b 
通过重排了指令的执行顺序 避免了cpu资源的浪费
一个代码例子：

```java
 public volatile boolean testMark=false; // 共享变量
 Map configOptions;
 char[] configText;

//线程1 逻辑
{
   //模拟读取配置信息， 当读取完成后把 testMark 设置为ture 作为通知 其他线程 配置可以读取了
   configOptions=new HashMap<>();
   //读取配置文件信息
   configText=readConfigFile(fileName);
   //把配置文件信息放入configOptions 
   processConfigOptions(configText,configOptions);
   //标志位设为ture
   testMark=true;
}

//线程2逻辑
{
   //循环判断testMark 等待testMark为true
   while(!testMark ){
   		
   }
   //读取配置信息
   doSomethingWithConfig();
}
```

如果不禁止 指令重排 线程1 中 把 testMark=true; 重排到了 加载配置信息前面
这个时候线程2 会立即发现 testMark=true; 并进行 配置信息的读取 但是 线程1 仅仅是先执行了testMark=true; 配置文件加载 还没执行，configOptions没有数据 这个时候你如果进行这个中操作 configOptions.get(“token”);就会报错。




-------------------

注意：

volatile关键字很重要的两个特性:

1、保证变量在线程间可见，对volatile变量所有的写操作都能立即反应到其他线程中，换句话说，volatile变量在各个线程中是一致的（得益于java内存模型—"先行发生原则"）；

2、禁止指令的重排序优化；





📣📣📣但是有一点：

```java
private static final int THREADS_CONUT = 20;
    public static volatile int count = 0;
 
    public static void increase() {
        count++;
    }
 
    public static void main(String[] args) {
        Thread[] threads = new Thread[THREADS_CONUT];
        for (int i = 0; i < THREADS_CONUT; i++) {
            threads[i] = new Thread(new Runnable() {
                @Override
                public void run() {
                    for (int i = 0; i < 1000; i++) {
                        increase();
                    }
                }
            });
            threads[i].start();
        }
 
        while (Thread.activeCount() > 1) {
            Thread.yield();
        }
        System.out.println(count);
    }


```

**测试结果每次都是输出小于20000的数字。这又是为什么？ 上面的论据是正确的，也就是上面标红的内容，但是这个论据并不能得出"基于volatile变量的运算在并发下是安全的"这个结论，因为核心点在于java里的运算（比如自增）并不是原子性的。**

可以改成


​    public static AtomicInteger count = new AtomicInteger(0);

结果每次都输出20000





编译后的汇编指令中，有volatile关键字和没有volatile关键字，主要差别在于多了一个 lock addl $0x0,(%rsp)，也就是lock的前缀指令。
lock指令相当于一个内存屏障，它保证如下三点：

1. 将本处理器的缓存写入内存。
2. 重排序时不能把后面的指令重排序到内存屏障之前的位置。
3. 如果是写入动作会导致其他处理器中对应的内存无效。



用图来演示一下使用关键字volatile时出现非线程安全的原因。

变量在内存中工作的过程如图2-80所示。 

![image-20211013172358191](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211013172358191.png)

由上，我们可以得出以下结论。 

1）read和load阶段：从主存复制变量到当前线程工作内存； 

2）use和assign阶段：执行代码，改变共享变量值； 

3）store和write阶段：用工作内存数据刷新主存对应变量的值。

关键字volatile提示线程每次从共享内存中读取变量，而不是从私有内存中读取，这样就保证了同步数据的可见性。但在这里需要注意的是：如果修改实例变量中的数据，比如i++，也就是i=i+1，则这样的操作其实并不是一个原子操作，也就是非线程安全的。**表达式i++的操作步骤分解如下**：

 1）从内存中取出i的值； 

2）计算i的值； 

3）将i的值写到内存中。 

**假如在第2步计算值的时候，另外一个线程也修改i的值，那么这个时候就会出现脏数据**。解决的办法其实就是使用synchronized关键字，这个知识点在前面的案例中已经介绍过了。所以说volatile本身并不处理数据的原子性，而是强制对数据的读写及时影响到主内存的。

　使用原子类进行i++操作 

除了在i++操作时使用synchronized关键字实现同步外，还可以使用AtomicInteger原子类进行实现。 原子操作是不能分割的整体，没有其他线程能够中断或检查正在原子操作中的变量。一个原子（atomic）类型就是一个原子操作可用的类型，它可以在没有锁的情况下做到线程安全（thread-safe）。 创建测试项目AtomicIntegerTest，文件AddCountThread.java代码如下： 

```java
package extthread;
import java.util.concurrent.atomic.AtomicInteger;
public class AddCountThread extends Thread {
  private AtomicInteger count = new AtomicInteger(0);
  @Override
  public void run() {
    for (int i = 0; i < 10000; i++) {
      System.out.println(count.incrementAndGet());
    }
  }
}
```



文件Run.java代码如下： 

```java
package test;
import extthread.AddCountThread;
public class Run {
  public static void main(String[] args) {
    AddCountThread countService = new AddCountThread();
    Thread t1 = new Thread(countService);
    t1.start();
    Thread t2 = new Thread(countService);
    t2.start();
    Thread t3 = new Thread(countService);
    t3.start();
    Thread t4 = new Thread(countService);
    t4.start();
    Thread t5 = new Thread(countService);
    t5.start();
  }
} 
```









-----------------------------



## 什么是java内存模型 对jmm的理解

Java内存模型定义了一种多线程访问Java内存的规范。Java内存模型要完整讲不是这里几句话能说清楚的，我简单总结一下Java内存模型的几部分内容：
1、Java内存模型将内存分为了主内存和工作内存。类的状态，也就是类之间共享的变量，是存储在主内存中的，每次Java线程用到这些主内存中的变量的时候，会读一次主内存中的变量，并让这些内存在自己的工作内存中有一份拷贝，运行自己线程代码的时候，用到这些变量，操作的都是自己工作内存中的那一份。在线程代码执行完毕之后，会将最新的值更新到主内存中去
2、定义了几个原子操作，用于操作主内存和工作内存中的变量
3、定义了volatile变量的使用规则
4、happens-before，即先行发生原则，定义了操作A必然先行发生于操作B的一些规则，比如在同一个线程内控制流前面的代码一定先行发生于控制流后面的代码、一个释放锁unlock的动作一定先行发生于后面对于同一个锁进行锁定lock的动作等等，只要符合这些规则，则不需要额外做同步措施，如果某段**代码不符合所有的happens-before规则，则这段代码一定是线程非安全的**

为什么需要JMM？
随着CPU和内存的发展速度差异的问题，导致CPU的速度远快于内存，所以现在的CPU加入了高速
缓存，高速缓存一般可以分为L1、L2、L3三级缓存。基于上面的例子我们知道了这导致了缓存一致
性的问题，所以加入了缓存一致性协议，同时导致了内存可见性的问题，而编译器和CPU的重排序
导致了原子性和有序性的问题，JMM内存模型正是对多线程操作下的一系列规范约束，因为不可能
让陈雇员的代码去兼容所有的CPU，通过JMM我们才屏蔽了不同硬件和操作系统内存的访问差异，
这样保证了Java程序在不同的平台下达到一致的内存访问效果，同时也是保证在高效并发的时候程
序能够正确执行。

为了明确定义在多线程场景下，什么时候可以重排序，什么时候不能重排序，Java 引入了JMM（Java Memory Model），也就是Java内存模型（单线程场景不用说明，有as-if-serial语义保证）**。这个模型就是一套规范**，对上，是JVM和开发者之间的协定；==对下，是JVM和编译器、CPU之间的协定==。 定义这套规范，其实是要在开发者写程序的方便性和系统运行的效率之间找到一个平衡点。一方面，要让编译器和CPU可以灵活地重排序；另一方面，要对开发者做一些承诺，明确告知开发者不需要感知什么样的重排序，需要感知什么样的重排序。然后，根据需要决定这种重排序对程序是否有影响。如果有影响，就需要开发者显示地通过volatile、synchronized等线程同步机制来禁止重排序。 为了描述这个规范，JMM引入了happen-before，使用happen-before描述两个操作之间的内存可见性。那么，happen-before是什么呢？ 如果A happen-before B，意味着A的执行结果必须对B可见，也就是保证跨线程的内存可见性。A happen before B不代表A一定在B之前执行。因为，对于多线程程序而言，两个操作的执行顺序是不确定的。happen-before只确保如果A在B之前执行，则A的执行结果必须对B可见。定义了内存可见性的约束，也就定义了一系列重排序的约束。 基于happen-before的这种描述方法，JMM对开发者做出了一系列承诺： 

（1）单线程中的每个操作，happen-before 对应该线程中任意后续操作（也就是 as-if-serial语义保证）。 

（2）对volatile变量的写入，happen-before对应后续对这个变量的读取。 

（3）对synchronized的解锁，happen-before对应后续对这个锁的加锁。 …… 

对于非volatile变量的写入和读取，不在这个承诺之列。通俗来讲，就是JMM对编译器和CPU 来说，volatile 变量不能重排序；非 volatile 变量可以任意重排序。JMM 没有对非 volatile变量做这个承诺，所以出现了前面例子中的各种问题。   

![image-20211230134514484](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211230134514484.png)

==顺序⼀致性模型==有两⼤特性：
⼀个线程中的所有操作必须按照程序的顺序（即Java代码的顺序）来执⾏。

不管程序是否同步，所有线程都只能看到⼀个单⼀的操作执⾏顺序。即在顺序⼀致性模型中，每个操作必须是原⼦性的，且⽴刻对所有线程可⻅。



Java内存模型（JMM）对于正确同步多线程程序的内存⼀致性做了以下保证：
**如果程序是正确同步的，程序的执⾏将具有顺序⼀致性。** 即程序的执⾏结果和该程序在顺序⼀致性模型中执⾏的结果相同。这⾥的同步包括了使⽤ volatile 、 final 、 synchronized 等关键字来实现多线程下的同步。

如果程序员没有正确使⽤ volatile 、 final 、 synchronized ，那么即便是使⽤了同步（单线程下的同步），JMM也不会有内存可⻅性的保证，可能会导致你的程序出错，并且具有不可重现性，很难排查。

原子性：Java内存模型通过read、load、assign、use、store、write来保证原子性操作，此外还有lock和unlock，直接对应着synchronized关键字的monitorenter和monitorexit字节码指令。
可见性：可见性的问题在上面的回答已经说过，Java保证可见性可以认为通过volatile、synchronized、final来实现。
有序性：由于处理器和编译器的重排序导致的有序性问题，Java通过volatile、synchronized来保证。

happen-before规则
虽然指令重排提高了并发的性能，但是Java虚拟机会对指令重排做出一些规则限制，并不能让所有
的指令都随意的改变执行位置，主要有以下几点：
1. 单线程每个操作，happen-before于该线程中任意后续操作
2. volatile写happen-before与后续对这个变量的读
3. synchronized解锁happen-before后续对这个锁的加锁
4. final变量的写happen-before于final域对象的读，happen-before后续对final变量的读
5. 传递性规则，A先于B，B先于C，那么A一定先于C发生

到底工作内存和主内存是什么？
主内存可以认为就是物理内存，Java内存模型中实际就是虚拟机内存的一部分。**而工作内存就是**
**CPU缓存，他有可能是寄存器也有可能是L1\L2\L3缓存，都是有可能的。**

![image-20230213153208655](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20230213153208655.png)



## JMM中同步非同步程序的顺序⼀致性效果

在顺序⼀致性模型中，所有操作完全按照程序的顺序串⾏执⾏。但是JMM中，临界区内（同步块或同步⽅法中）的代码可以发⽣重排序（但不允许临界区内的代码“逃逸”到临界区之外，因为会破坏锁的内存语义）。
虽然线程A在临界区做了重排序，但是因为锁的特性，线程B⽆法观察到线程A在临界区的重排序。这种重排序既提⾼了执⾏效率，⼜没有改变程序的执⾏结果。
同时，JMM会在退出临界区和进⼊临界区做特殊的处理，使得在临界区内程序获得与顺序⼀致性模型相同的内存视图。
由此可⻅，JMM的具体实现⽅针是：在不改变（正确同步的）程序执⾏结果的前提下，尽量为编译期和处理器的优化打开⽅便之⻔

JMM中未同步程序的顺序⼀致性效果
对于未同步的多线程程序，JMM只提供最⼩安全性：线程读取到的值，要么是之前某个线程写⼊的值，要么是默认值，不会⽆中⽣有。
为了实现这个安全性，JVM在堆上分配对象时，⾸先会对内存空间清零，然后才会在上⾯分配对象（这两个操作是同步的）。

JMM没有保证未同步程序的执⾏结果与该程序在顺序⼀致性中执⾏结果⼀致。因为如果要保证执⾏结果⼀致，那么JMM需要禁⽌⼤量的优化，对程序的执⾏性能会产⽣很⼤的影响。
未同步程序在JMM和顺序⼀致性内存模型中的执⾏特性有如下差异：

1. 顺序⼀致性保证单线程内的操作会按程序的顺序执⾏；JMM不保证单线程内的操作会按程序的顺序执⾏。（因为重排序，但是JMM保证单线程下的重排序不影响执⾏结果）
2. 顺序⼀致性模型保证所有线程只能看到⼀致的操作执⾏顺序，⽽JMM不保证所有线程能看到⼀致的操作执⾏顺序。（因为JMM不保证所有操作⽴即可⻅）
3. JMM不保证对64位的long型和double型变量的写操作具有原⼦性，⽽顺序⼀致性模型保证对所有的内存读写操作都具有原⼦性。

##  volatile 变量和 atomic 变量有什么不同？

首先，volatile 变量和 atomic 变量看起来很像，但功能却不一样。
Volatile变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用volatile修饰count变量那么 count++ 操作就不是原子性的。
而AtomicInteger类提供的atomic方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。

# 什么是happens-before?

⼀⽅⾯，程序员需要JMM提供⼀个强的内存模型来编写代码；另⼀⽅⾯，编译器和处理器希望JMM对它们的束缚越少越好，这样它们就可以最可能多的做优化来提⾼性能，希望的是⼀个弱的内存模型。
JMM考虑了这两种需求，并且找到了平衡点，对编译器和处理器来说，只要不改变程序的执⾏结果（单线程程序和正确同步了的多线程程序），编译器和处理器怎么优化都⾏。
⽽对于程序员，JMM提供了happens-before规则（JSR-133规范），满⾜了程序员的需求——简单易懂，并且提供了⾜够强的内存可⻅性保证。**换⾔之，程序员只要遵循happens-before规则，那他写的程序就能保证在JMM中具有强的内存可⻅性。**
JMM使⽤happens-before的概念来定制两个操作之间的执⾏顺序。这两个操作可以在⼀个线程以内，也可以是不同的线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可⻅性保证。

happens-before关系的定义如下：
1. 如果⼀个操作happens-before另⼀个操作，那么第⼀个操作的执⾏结果将对第⼆个操作可⻅，⽽且第⼀个操作的执⾏顺序排在第⼆个操作之前。
2. 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执⾏。如果重排序之后的执⾏结果，与按happens-before关系来执⾏的结果⼀致，那么JMM也允许这样的重排序。
happens-before关系本质上和as-if-serial语义是⼀回事。

as-if-serial语义保证单线程内重排序后的执⾏结果和程序代码本身应有的结果是⼀致的，happens-before关系保证正确同步的多线程程序的执⾏结果不被重排序改变。
总之，如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可⻅的，不管它们在不在⼀个线程。

　先行发生原则 如果Java内存模型中所有的有序性都仅仅靠volatile和synchronized来完成，那么有一些操作将会变得很烦琐，但是我们在编写Java并发代码的时候并没有感觉到这一点，这是因为Java语言中有一个“先行发生”（happens-before）的原则。这个原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地解决并发环境下两个操作之间是否可能存在冲突的所有问题。 现在就来看看“先行发生”原则指的是什么。

先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值发送了消息、调用了方法等。这句话不难理解，但它意味着什么呢？我们可以举个例子来说明一下，如代码清单12-8中所示的这3句伪代码。

 代码清单12-8　





```java
 //以下操作在线程A中执行 

i=1;
//以下操作在线程B中执行

 j=i； 

//以下操作在线程C中执行 

i=2；
```

假设线程A中的操作“i=1”先行发生于线程B的操作“j=i”，那么可以确定在线程B的操作执行后，变量j的值一定等于1，得出这个结论的依据有两个：一是根据先行发生原则，“i=1”的结果可以被观察到；

二是线程C还没“登场”，线程A操作结束之后没有其他线程会修改变量i的值。现在再来考虑线程C，我们依然保持线程A和线程B之间的先行发生关系，而线程C出现在线程A和线程B的操作之间，但是线程C与线程B没有先行发生关系，那j的值会是多少呢？答案是不确定！1和2都有可能，因为线程C对变量i的影响可能会被线程B观察到，也可能不会，这时候线程B就存在读取到过期数据的风险，不具备多线程安全性。 

下面是Java内存模型下一些“天然的”先行发生关系，**这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用**。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，**它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。** 

程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 

管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。 

volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。 

线程启动规则（Thread Start Rule）：Thread对象的start（）方法先行发生于此线程的每一个动作。 

线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。 线程中断规则（Thread Interruption Rule）：对线程interrupt（）方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted（）方法检测到是否有中断发生。
对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize（）方法的开始。 

传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。 Java语言无须任何同步手段保障就能成立的先行发生规则就只有上面这些了，笔者演示一下如何使用这些规则去判定操作间是否具备顺序性，对于读写共享变量的操作来说，就是线程是否安全，**读者还可以从下面这个例子中感受一下“时间上的先后顺序”与“先行发生”之间有什么不同**。

演示例子如代码清单12-9所示。

```java
 private int value=0；

 pubilc void setValue

（int value）{
this.value=value；

 } 

public int getValue（）

{ return value； } 
```



代码清单12-9中显示的是一组再普通不过的getter/setter方法，假设存在线程A和B，线程A先（时间上的先后）调用了“setValue（1）”，然后线程B调用了同一个对象的“getValue（）”，那么线程B收到的返回值是什么？ 我们依次分析一下先行发生原则中的各项规则，由于两个方法分别由线程A和线程B调用，不在一个线程中，所以程序次序规则在这里不适用；由于没有同步块，自然就不会发生lock和unlock操作，所以管程锁定规则不适用；由于value变量没有被volatile关键字修饰，所以volatile变量规则不适用；后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，**因此我们可以判定尽管线程A在操作时间上先于线程B，但是无法确定线程B中“getValue（）”方法的返回结果，换句话说，这里面的操作不是线程安全的**。 那怎么修复这个问题呢？我们至少有两种比较简单的方案可以选择：要么把getter/setter方法都定义为synchronized方法，这样就可以套用管程锁定规则；要么把value定义为volatile变量，由于setter方法对value的修改不依赖value的原值，满足volatile关键字使用场景，这样就可以套用volatile变量规则来实现先行发生关系。 

通过上面的例子，我们可以得出结论：==一个操作“时间上的先发生”不代表这个操作会是“先行发生”==，那如果一个操作“先行发生”是否就能推导出这个操作必定是“时间上的先发生”呢？很遗憾，这个推论也是不成立的，一个典型的例子就是多次提到的“指令重排序”，

演示例子如代码清单12-10所示。

 //以下操作在同一个线程中执行 

int i=1；

 int j=2；

 两条赋值语句在同一个线程之中，根据程序次序规则，“int i=1”的操作先行发生于“int j=2”，但是“int j=2”的代码完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为我们在这条线程之中没有办法感知到这点。 上面两个例子综合起来证明了一个结论：**时间先后顺序与先行发生原则之间基本没有太大的关系，所以我们衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以先行发生原则为准**。 

⼀⽅⾯，程序员需要JMM提供⼀个强的内存模型来编写代码；另⼀⽅⾯，编译器和处理器希望JMM对它们的束缚越少越好，这样它们就可以最可能多的做优化来提⾼性能，希望的是⼀个弱的内存模型。
JMM考虑了这两种需求，并且找到了平衡点，对编译器和处理器来说，只要不改变程序的执⾏结果（单线程程序和正确同步了的多线程程序），编译器和处理器怎么优化都⾏。
⽽对于程序员，JMM提供了happens-before规则（JSR-133规范），满⾜了程序员的需求——简单易懂，并且提供了⾜够强的内存可⻅性保证。换⾔之，程序员只要遵循happens-before规则，那他写的程序就能保证在JMM中具有强的内存可⻅性。
JMM使⽤happens-before的概念来定制两个操作之间的执⾏顺序。这两个操作可以在⼀个线程以内，也可以是不同的线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可⻅性保证。
happens-before关系的定义如下：

1. 如果⼀个操作happens-before另⼀个操作，那么第⼀个操作的执⾏结果将对第⼆个操作可⻅，⽽且第⼀个操作的执⾏顺序排在第⼆个操作之前。

2. 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执⾏。如果重排序之后的执⾏结果，与按happens-before关系来执⾏的结果⼀致，那么JMM也允许这样的重排序。

happens-before关系本质上和as-if-serial语义是⼀回事。
as-if-serial语义保证单线程内重排序后的执⾏结果和程序代码本身应有的结果是⼀致的，happens-before关系保证正确同步的多线程程序的执⾏结果不被重排序改变。
总之，如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可⻅的，不管它们在不在⼀个线程

==在Java中，有以下天然的happens-before关系：==
程序顺序规则：⼀个线程中的每⼀个操作，happens-before于该线程中的任意后续操作。
监视器锁规则：对⼀个锁的解锁，happens-before于随后对这个锁的加锁。
volatile变量规则：对⼀个volatile域的写，happens-before于任意后续对这个volatile域的读。
传递性：如果A happens-before B，且B happens-before C，那么A happensbefore C。
start规则：如果线程A执⾏操作ThreadB.start()启动线程B，那么A线程的ThreadB.start（）操作happens-before于线程B中的任意操作、
join规则：如果线程A执⾏操作ThreadB.join（）并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。

举例：
int a = 1; // A操作
int b = 2; // B操作
int sum = a + b;// C 操作
System.out.println(sum);
根据以上介绍的happens-before规则，假如只有⼀个线程，那么不难得出：
1> A happens-before B
2> B happens-before C
3> A happens-before C
注意，真正在执⾏指令的时候，其实JVM有可能对操作A & B进⾏重排序，因为⽆论先执⾏A还是B，他们都对对⽅是可⻅的，并且不影响执⾏结果。
如果这⾥发⽣了重排序，这在视觉上违背了happens-before原则，但是JMM是允许这样的重排序的。





# 生产者 消费者模拟

我们假设⼀种场景，⽣产者⼀直⽣产资源，消费者⼀直消费资源，资源存储在⼀个缓冲池中，⽣产者将⽣产的资源存进缓冲池中，消费者从缓冲池中拿到资源进⾏消费，这就是⼤名鼎鼎的⽣产者-消费者模式。
该模式能够简化开发过程，⼀⽅⾯消除了⽣产者类与消费者类之间的代码依赖性，另⼀⽅⾯将⽣产数据的过程与使⽤数据的过程解耦简化负载。
我们⾃⼰coding实现这个模式的时候，因为需要让多个线程操作共享变量（即资源），所以很容易引发线程安全问题，造成重复消费和死锁，尤其是⽣产者和消费者存在多个的情况。另外，当缓冲池空了，我们需要阻塞消费者，唤醒⽣产者；当缓冲池满了，我们需要阻塞⽣产者，唤醒消费者，这些个等待-唤醒逻辑都需要⾃⼰实现。

这么容易出错的事情，JDK当然帮我们做啦，这就是阻塞队列(BlockingQueue)，你只管往⾥⾯存、取就⾏，⽽不⽤担⼼多线程环境下存、取共享变量的线程安全问题。
BlockingQueue是Java util.concurrent包下重要的数据结构，区别于普通的队
列，BlockingQueue提供了线程安全的队列访问⽅式，并发包下很多⾼级同
步类的实现都是基于BlockingQueue实现的。
BlockingQueue⼀般⽤于⽣产者-消费者模式，⽣产者是往队列⾥添加元素的线程，消费者是从队列⾥拿元素的线程。BlockingQueue就是存放元素的容器

PriorityBlockingQueue不会阻塞数据⽣产者（因为队列是⽆界的），⽽只会在没有可消费的数据时，阻塞数据的消费者。因此使⽤的时候要特别注意，**⽣产者⽣产数据的速度绝对不能快于消费者消费数据的速度，否则时间⼀⻓，会最终耗尽所有的可⽤堆内存空间**。对于使⽤默认⼤⼩的LinkedBlockingQueue也是⼀样的。

（LinkedBlockingQueue
由链表结构组成的有界阻塞队列。内部结构是链表，具有链表的特性。默认队列的⼤⼩是 Integer.MAX_VALUE ，也可以指定⼤⼩。此队列按照先进先出的原则对元素进⾏排序。）

4.一生产与一消费：

操作栈 本示例是使生产者向堆栈List对象中放入数据，使消费者从List堆栈中取出数据。List最大容量是1，实验环境只有一个生产者与一个消费者。 创建项目stack_1，类MyStack.java代码如下： 

```java
package entity;
import java.util.ArrayList;
import java.util.List;
public class MyStack {
private List list = new ArrayList();
synchronized public void push() {
  try {
    if (list.size() == 1) {
      this.wait();
    }
    list.add("anyString=" + Math.random());
    this.notify();
    System.out.println("push=" + list.size());
  } catch (InterruptedException e) {
    e.printStackTrace();
  }
}
synchronized public String pop() {
  String returnValue = "";
  try {
    if (list.size() == 0) {
      System.out.println("pop操作中的："
          \+ Thread.currentThread().getName() + " 线程呈wait状态");
      this.wait();
    }
    returnValue = "" + list.get(0);
    list.remove(0);
    this.notify();
    System.out.println("pop=" + list.size());
  } catch (InterruptedException e) {
    e.printStackTrace();
  }
  return returnValue;
}
}
```

生产者P.java服务代码如下： 

```java
package service;
import entity.MyStack;
public class P {
private MyStack myStack;
public P(MyStack myStack) {
  super();
  this.myStack = myStack;
}
public void pushService() {
  myStack.push();
}
```

消费者C.java服务代码如下： 

````java
package service;
import entity.MyStack;
public class C {
private MyStack myStack;
public C(MyStack myStack) {
  super();
  this.myStack = myStack;
}
````

自定义线程类：

![image-20211014211139111](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211014211139111.png)

运行类Run.java代码如下： 

```java
package test.run;
import service.P;
import service.C;
import entity.MyStack;
import extthread.P_Thread;
import extthread.C_Thread;
public class Run {
public static void main(String[] args) {
  MyStack myStack = new MyStack();
  P p = new P(myStack);
  C r = new C(myStack);
  P_Thread pThread = new P_Thread(p);
  C_Thread rThread = new C_Thread(r);
  pThread.start();
  rThread.start();
}
```


 程序运行结果是size（）不会大于1， 

**5.一生产与多消费——操作栈：**

解决wait条件改变与假死 

本示例是使用一个生产者向堆栈List对象中放入数据，而多个消费者从List堆栈中取出数据。List最大容量还是1。

 创建新的项目stack_2_old，将项目stack_1中的所有代码内容复制到stack_2_old项目中。更改Run.java代码如下： 

```java
package test.run;
import service.C;
import service.P;
import entity.MyStack;
import extthread.C_Thread;
import extthread.P_Thread;
public class Run {
public static void main(String[] args) throws InterruptedException {
  MyStack myStack = new MyStack();
  P p = new P(myStack);
  C r1 = new C(myStack);
  C r2 = new C(myStack);
  C r3 = new C(myStack);
  C r4 = new C(myStack);
  C r5 = new C(myStack);
  P_Thread pThread = new P_Thread(p);
  pThread.start();
  C_Thread cThread1 = new C_Thread(r1);
  C_Thread cThread2 = new C_Thread(r2);
  C_Thread cThread3 = new C_Thread(r3);
  C_Thread cThread4 = new C_Thread(r4);
  C_Thread cThread5 = new C_Thread(r5);
  cThread1.start();
  cThread2.start();
  cThread3.start();
  cThread4.start();
  cThread5.start();
}
```



程序运行后在某些几率下出现异常此问题的出现就是因为在MyStack.java类中使用了if语句作为条件判断，代码如下：

```java
 synchronized public void push() {
  try {
    if (list.size() == 1) {
      this.wait();
    }
    list.add("anyString=" + Math.random());
    this.notify();
    System.out.println("push=" + list.size());
  } catch (InterruptedException e) {
    e.printStackTrace();
  }
}
```



 因为条件发生改变时并没有得到及时的响应，所以多个呈wait状态的线程被唤醒，继而执行list.remove（0）代码而出现异常。解决这个办法是，将if改成while语句即可。更改MyStack.java类代码如下： 

```java
package entity;
import java.util.ArrayList;
import java.util.List;
public class MyStack {
private List list = new ArrayList();
synchronized public void push() {
  try {
    while (list.size() == 1) {
      this.wait();
    }
    list.add("anyString=" + Math.random());
    this.notify();
    System.out.println("push=" + list.size());
  } catch (InterruptedException e) {
    e.printStackTrace();
  }
}
synchronized public String pop() {
  String returnValue = "";
  try {
    while (list.size() == 0) {
      System.out.println("pop操作中的："          + Thread.currentThread().getName() + " 线程呈wait状态");
      this.wait();
    }
    returnValue = "" + list.get(0);
    list.remove(0);
    this.notify();
    System.out.println("pop=" + list.size()); 
  } catch (InterruptedException e) {
    e.printStackTrace();
  }
  return returnValue;
}
}
```

运行项目没有出现执行异常，却出现了“假死”情况，解决的办法当然还是使用notifyAll（）方法了。

# 阻塞队列的原理

阻塞队列的原理很简单，利⽤了Lock锁的多条件（Condition）阻塞控制。接下来我们分析ArrayBlockingQueue JDK 1.8 的源码。
⾸先是构造器，除了初始化队列的⼤⼩和是否是公平锁之外，还对同⼀个锁
（lock）初始化了两个监视器，分别是notEmpty和notFull。这两个监视器的作⽤⽬前可以简单理解为标记分组，当该线程是put操作时，给他加上监视器notFull,标记这个线程是⼀个⽣产者；当线程是take操作时，给他加上监视器notEmpty，标记这个线程是消费者。

```java
//数据元素数组
final Object[] items;
//下⼀个待取出元素索引
int takeIndex;
//下⼀个待添加元素索引
int putIndex;
//元素个数
int count;
//内部锁
final ReentrantLock lock;
//消费者监视器
private final Condition notEmpty;
//⽣产者监视器
private final Condition notFull;
public ArrayBlockingQueue(int capacity, boolean fair) {
//..省略其他代码
lock = new ReentrantLock(fair);
notEmpty = lock.newCondition();
notFull = lock.newCondition();
}
```

put操作的源码

```java
public void put(E e) throws InterruptedException {
checkNotNull(e);
final ReentrantLock lock = this.lock;
// 1.⾃旋拿锁
lock.lockInterruptibly();
try {
// 2.判断队列是否满了
while (count == items.length)
// 2.1如果满了，阻塞该线程，并标记为notFull线程，
// 等待notFull的唤醒，唤醒之后继续执⾏while循环。
notFull.await();
// 3.如果没有满，则进⼊队列
enqueue(e);
} finally {
lock.unlock();
}
}
private void enqueue(E x) {
// assert lock.getHoldCount() == 1;
// assert items[putIndex] == null;
final Object[] items = this.items;
items[putIndex] = x;
if (++putIndex == items.length)
putIndex = 0;
count++;
// 4 唤醒⼀个等待的线程
notEmpty.signal();
}
```

总结put的流程：
1. **所有执⾏put操作的线程竞争lock锁，拿到了lock锁的线程进⼊下⼀步，没有拿到lock锁的线程⾃旋竞争锁。**
2. 判断阻塞队列是否满了，如果满了，则调⽤await⽅法阻塞这个线程，并标记为notFull（⽣产者）线程，同时释放lock锁,等待被消费者线程唤醒。
3. 如果没有满，则调⽤enqueue⽅法将元素put进阻塞队列。注意这⼀步的线程还有⼀种情况是第⼆步中阻塞的线程被唤醒且⼜拿到了lock锁的线程。
4. 唤醒一个标记为notempty的线程

take操作的源码

```java
public E take() throws InterruptedException {
final ReentrantLock lock = this.lock;
lock.lockInterruptibly();
try {
while (count == 0)
notEmpty.await();
return dequeue();
} finally {
lock.unlock();
}
}
private E dequeue() {
// assert lock.getHoldCount() == 1;
// assert items[takeIndex] != null;
final Object[] items = this.items;
@SuppressWarnings("unchecked")
E x = (E) items[takeIndex];
items[takeIndex] = null;
if (++takeIndex == items.length)
takeIndex = 0;
count--;
if (itrs != null)
itrs.elementDequeued();
notFull.signal();
return x;
}
```

take操作和put操作的流程是类似的，总结⼀下take操作的流程：
1. 所有执⾏take操作的线程竞争lock锁，拿到了lock锁的线程进⼊下⼀步，没有拿到lock锁的线程⾃旋竞争锁。
2. 判断阻塞队列是否为空，如果是空，则调⽤await⽅法阻塞这个线程，并标记为notEmpty（消费者）线程，同时释放lock锁,等待被⽣产者线程唤醒。
3. 如果没有空，则调⽤dequeue⽅法。注意这⼀步的线程还有⼀种情况是第⼆步中阻塞的线程被唤醒且⼜拿到了lock锁的线程。
4. 唤醒⼀个标记为notFull（⽣产者）的线程。

tips:

1. put和tack操作都需要先获取锁，没有获取到锁的线程会被挡在第⼀道⼤⻔之外⾃旋拿锁，直到获取到锁。
2. 就算拿到锁了之后，也不⼀定会顺利进⾏put/take操作，需要判断队列是否可⽤（是否满/空），如果不可⽤，则会被阻塞，并释放锁。
3. 在第2点被阻塞的线程会被唤醒，但是在唤醒之后，依然需要拿到锁才能继续往下执⾏，否则，⾃旋拿锁，拿到锁了再while判断队列是否可⽤（这也是为什么不⽤if判断，⽽使⽤while判断的原因）



# if 和while

在多线程情况下，如果一个线程进入了if语句块中，在if语句块中执行了wait方法，该线程处于等待（wait）状态，如果该线程被唤醒（notify），不管if的条件是否发生了变化，该线程会执行wait之后的代码，并且会跳出if语句块执行if语句块外面的代码

如果是while，被唤醒了之后，会继续执行wait方法之后的代码，代码块里面的代码执行完了会继续判断条件，如果为true，会继续执行while语句块里面的代码，如果为false，才会执行判断语句块后面的代码 



方法join（long）的功能在内部是使用wait（long）方法来实现的，所以join（long）方法具有释放锁的特点。 

方法join（long）源代码如下：

```java
public final synchronized void join(long millis)
    throws InterruptedException {
  long base = System.currentTimeMillis();
  long now = 0;
  if (millis < 0) {
    throw new IllegalArgumentException("timeout value is negative");
  }
  if (millis == 0) {
    while (isAlive()) {
      wait(0);
    }
  } else {
    while (isAlive()) {
      long delay = millis - now;
      if (delay <= 0) {
        break;
      }
      wait(delay);
      now = System.currentTimeMillis() - base;
```



 从源代码中可以了解到，当执行wait（long）方法后，当前线程的锁被释放，那么其他线程就可以调用此线程中的同步方法了。 



# 通过管道进行线程间通信：

字节流 

在Java语言中提供了各种各样的输入/输出流Stream，使我们能够很方便地对数据进行操作，其中管道流（pipeStream）是一种特殊的流，用于在不同线程间直接传送数据。一个线程发送数据到输出管道，另一个线程从输入管道中读数据。通过使用管道，实现不同线程间的通信，而无须借助于类似临时文件之类的东西。 在Java的JDK中提供了4个类来使线程间可以进行通信： 

1）PipedInputStream和PipedOutputStream 

2）PipedReader和PipedWriter 创建测试用的项目pipeInputOutput。 类WriteData.java代码如下： 

```java
package service;

import java.io.IOException;
import java.io.PipedOutputStream;
public class WriteData {
  public void writeMethod(PipedOutputStream out) {
    try {
      System.out.println("write :");
      for (int i = 0; i < 300; i++) {
        String outData = "" + (i + 1);
        out.write(outData.getBytes());
        System.out.print(outData);
      }
      System.out.println();
      out.close();
    } catch (IOException e) {
      e.printStackTrace();
    }
  }
} 
```



类ReadData.java代码如下： 

```java
package service;
import java.io.IOException;
import java.io.PipedInputStream;
public class ReadData {
  public void readMethod(PipedInputStream input) {
    try {
      System.out.println("read :");
      byte[] byteArray = new byte[20];
      int readLength = input.read(byteArray);
      while (readLength != -1) {
        String newData = new String(byteArray, 0, readLength);
        System.out.print(newData);
        readLength = input.read(byteArray);
      }
      System.out.println();
      input.close();
    } catch (IOException e) {
      e.printStackTrace();
    }
  }
}


```

```java
public class ThreadRead extends Thread{
    public ReadData readData;
    public PipedInputStream in;
    public ThreadRead(ReadData reaeData,PipedInputStream in)
    {
        super();
        this.readData = reaeData;
        this.in = in;
    }
    @Override
    public void run()
    {
       readData.readMethod(in);
    }
}
```



```java
public class ThreadWrite extends Thread{
    public WriteData writeData;
    public PipedOutputStream out;
    public ThreadWrite(WriteData writeData,PipedOutputStream out)
    {
        super();
        this.writeData = writeData;
        this.out = out;
    }
    @Override
    public void run()
    {
        writeData.writeMethod(out);
    }
}
```



run:

```java
public class Run {
    public static void main(String[] args) {
        try {
            WriteData writeData = new WriteData();ReadData readData = new ReadData();
            PipedInputStream inputStream = new PipedInputStream();
            PipedOutputStream outputStream = new PipedOutputStream();
            // inputStream.connect(outputStream);
            outputStream.connect(inputStream);
            ThreadRead threadRead = new ThreadRead(readData, inputStream);
            threadRead.start();
            Thread.sleep(2000);
            ThreadWrite threadWrite = new ThreadWrite(writeData, outputStream);
            threadWrite.start();
        } catch (IOException e) {
            e.printStackTrace();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```





# 如何在两个线程之间共享数据

Java 里面进行多线程通信的主要方式就是共享内存的方式，共享内存主要的关注点有两个：可见性和有序性原子性。Java 内存模型（JMM）解决了可见性和有序性的问题，而锁解决了原子性的问题，理想情况下我们希望做到“同步”和“互斥”。有以下常规实现方法：
将数据抽象成一个类，并将数据的操作作为这个类的方法

1. 将数据抽象成一个类，并将对这个数据的操作作为这个类的方法，这么设计可以和容易做到同步，只要在方法上加”synchronized“

```java
public class MyData {
private int j=0;
public synchronized void add(){
j++;
System.out.println("线程"+Thread.currentThread().getName()+"j 为："+j);
}
public synchronized void dec(){
j--;
System.out.println("线程"+Thread.currentThread().getName()+"j 为："+j);
}
public int getData(){
return j;
}
}
public class AddRunnable implements Runnable{
MyData data;
public AddRunnable(MyData data){
this.data= data;
}
    public void run() {
data.add();
}
}
public class DecRunnable implements Runnable {
MyData data;
public DecRunnable(MyData data){
this.data = data;
}
public void run() {
data.dec();
}
}
public static void main(String[] args) {
MyData data = new MyData();
Runnable add = new AddRunnable(data);
Runnable dec = new DecRunnable(data);
for(int i=0;i<2;i++){
new Thread(add).start();
new Thread(dec).start();
}
```



# 线程安全的集合java.util.concurrent 包



## ConcurrentLinkedQueue

基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时 候，它会添加到队列的尾部，当我们获取一个元素时，它会返回队列头部的元素。它采用cas算法来实 现。（如需了解细节，见jdk中代码

阻塞队列是一个支持两个附加操作的队列，这两个附加操作支持阻塞的插入和移除方法。

1、 支持阻塞的插入方法：当队列满时，队列会阻塞插入元素的线程，直到队列不满。

2、 支持阻塞的移除方法：当队列空时，获取元素的线程会等待队列变为非空。

## ConcurrentHashMap



ConcurrentHashMap 是线程安全的HashMap 的实现，默认构造同样有initialCapacity 和loadFactor 属性，不过还多了一个concurrencyLevel 属性，三属性默认值分别为16、0.75 及16。其内部使用锁分段技术，维持这锁Segment 的数组，在Segment 数组中又存放着Entity[]数组，内部hash 算法将数据较均匀分布在不同锁中。
put 操作：并没有在此方法上加上synchronized，首先对key.hashcode 进行hash 操作，得到key 的hash 值。
hash 操作的算法和map也不同，根据此hash 值计算并获取其对应的数组中的Segment 对象(继承自ReentrantLock)，接着调用此Segment 对象的put 方法来完成当前操作。ConcurrentHashMap 基于concurrencyLevel 划分出了多个Segment 来对key-value 进行存储，从而避免每次put 操作都得锁住整个数组。在默认的情况下，最佳情况下可允许16 个线程并发无阻塞的操作集合对象，尽可能地减少并发时的阻塞现象。

首先对key.hashCode 进行hash 操作，基于其值找到对应的Segment 对象，调用其get 方法完成当前操作。而Segment 的get 操作首先通过hash 值和对象数组大小减1 的值进行按位与操作来获取数组上对应位置的HashEntry。在这个步骤中，可能会因为对象数组大小的改变，以及数组上对应位置的HashEntry 产生不一致性，那么ConcurrentHashMap 是如何保证的？
对象数组大小的改变只有在put 操作时有可能发生，**由于HashEntry 对象数组对应的变量是volatile 类型的，因此可以保证如HashEntry 对象数组大小发生改变，读操作可看到最新的对象数组大小。**
在获取到了HashEntry 对象后，怎么能保证它及其next 属性构成的链表上的对象不会改变呢？这点ConcurrentHashMap 采用了一个简单的方式，即HashEntry 对象中的hash、key、next 属性都是final 的，这也就意味着没办法插入一个HashEntry 对象到基于next 属性构成的链表中间或末尾。这样就可以保证当获取到HashEntry对象后，其基于next 属性构建的链表是不会发生变化的。

**Get方法：**

1.为输入的Key做Hash运算，得到hash值。

2.通过hash值，定位到对应的Segment对象

3.再次通过hash值，定位到Segment当中数组的具体位置。

**Put方法：**

1.为输入的Key做Hash运算，得到hash值。

2.通过hash值，定位到对应的Segment对象

3.获取可重入锁

4.再次通过hash值，定位到Segment当中数组的具体位置。

5.插入或覆盖HashEntry对象。

6.释放锁。

(jdk1.7)

ConcurrentHashMap 默认情况下采用将数据分为16 个段进行存储，并且16 个段分别持有各自不同的锁Segment，锁仅用于put 和remove 等改变集合对象的操作，基于volatile 及HashEntry 链表的不变性实现了读取的不加锁。这些方式使得ConcurrentHashMap 能够保持极好的并发支持，尤其是对于读远比插入和删除频繁的Map而言，而它采用的这些方法也可谓是对于Java 内存模型、并发机制深刻掌握的体现。

Size方法的目的是统计ConcurrentHashMap的总元素数量， 自然需要把各个Segment内部的元素数量汇总起来。

但是，如果在统计Segment元素数量的过程中，已统计过的Segment瞬间插入新的元素，这时候该怎么办呢？

ConcurrentHashMap的Size方法是一个嵌套循环，大体逻辑如下：



1.遍历所有的Segment。

2.把Segment的元素数量累加起来。

3.把Segment的修改次数累加起来。

4.判断所有Segment的总修改次数是否大于上一次的总修改次数。如果大于，说明统计过程中有修改，重新统计，尝试次数+1；如果不是。说明没有修改，统计结束。

5.如果尝试次数超过阈值，则对每一个Segment加锁，再重新统计。

6.再次判断所有Segment的总修改次数是否大于上一次的总修改次数。由于已经加锁，次数一定和上次相等。

7.释放锁，统计结束。



Segment 段
ConcurrentHashMap 和 HashMap 思路是差不多的，但是因为它支持并发操作，所以要复杂一些。整个 ConcurrentHashMap 由一个个 Segment 组成，Segment 代表”部分“或”一段“的意思，所以很多地方都会将其描述为分段锁。注意，行文中，我很多地方用了“槽”来代表一个segment。

线程安全（Segment 继承 ReentrantLock 加锁）
简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个Segment 是线程安全的，也就实现了全局的线程安全。

![image-20210817155321605](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210817155321605.png)



concurrencyLevel：并行级别、并发数、Segment 数，怎么翻译不重要，理解它。默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。

***\*JDK1.8分析\****

改进一：取消segments字段，直接采用`transient volatile HashEntry<K,V> table`保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率。

改进二：将原先table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构。对于hash表来说，最核心的能力在于将key hash之后能均匀的分布在数组中。如果hash之后散列的很均匀，那么table数组中的每个队列长度主要为0或者1。但实际情况并非总是如此理想，虽然ConcurrentHashMap类默认的加载因子为0.75，但是在数据量过大或者运气不佳的情况下，还是会存在一些队列长度过长的情况，如果还是采用单向列表方式，那么查询某个节点的时间复杂度为O(n)；因此，对于个数超过8(默认值)的列表，jdk1.8中采用了红黑树的结构，那么查询的时间复杂度可以降低到O(logN)，可以改进性能。



![image-20210817155438707](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210817155438707.png)

HashTable（线程安全）
Hashtable 是遗留类，很多映射的常用功能与HashMap 类似，不同的是它承自Dictionary 类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap 引入了分段锁。Hashtable 不建议在新代码中使用，不需要线程安全的场合可以用HashMap 替换，需要线程安全的场合可以用ConcurrentHashMap 替换。



ConcurrentHashMap的并发度是什么
ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗？



1 ConcurrentHashMap默认初始容量是多少？

从下面ConcurrentHashMap类的静态变量可以看出它的初始容量为16

2 ConCurrentHashmap 的key，value是否可以为null。

不行 如果key或者value为null会抛出空指针异常

3 ConCurrentHashmap 每次扩容是原来容量的几倍

2倍 在transfer方法里面会创建一个原数组的俩倍的node数组来存放原数据。

4 ConCurrentHashmap的数据结构是怎么样的？(后面会具体分析它的put方法)

在java1.8中，它是一个数组+链表+红黑树的数据结构。

5 存储在ConCurrentHashmap中每个节点是什么样的，有哪些变量

它是实现`Map.Entry<K,V>`接口。里面存放了hash，key，value，以及next节点。它的value和next节点是用volatile进行修饰，可以保证多线程之间的可见性。

6 ConCurrentHashmap的put过程是怎样的？

整体流程跟HashMap比较类似，大致是以下几步：

- 如果桶数组未初始化，则初始化；
- 如果待插入的元素所在的桶为空，则尝试把此元素直接插入到桶的第一个位置；
- 如果正在扩容，则当前线程一起加入到扩容的过程中；
- 如果待插入的元素所在的桶不为空且不在迁移元素，则锁住这个桶（分段锁）；
- 如果当前桶中元素以链表方式存储，则在链表中寻找该元素或者插入元素；
- 如果当前桶中元素以红黑树方式存储，则在红黑树中寻找该元素或者插入元素；
- 如果元素存在，则返回旧值；
- 如果元素不存在，整个Map的元素个数加1，并检查是否需要扩容；

添加元素操作中使用的锁主要有（自旋锁 + CAS + synchronized + 分段锁）。

7 java1.8中ConCurrentHashmap节点是尾插还是头插？

尾插法,见上述put方法。

8 java1.8中，ConCurrentHashmap什么情况下链表才会转换成红黑树进行存储？

链表长度大于8。数组长度大于64。从put源码和以下源码可以看出：并非一开始就创建红黑树结构，如果当前Node数组长度小于阈值`MIN_TREEIFY_CAPACITY`，默认为64，先通过扩大数组容量为原来的两倍以缓解单个链表元素过大的性能问题。

9 java1.8中，ConCurrentHashmap的get过程是怎样的？

- 计算 hash 值
- 根据 hash 值找到数组对应位置: (n - 1) & h
- 根据该位置处结点性质进行相应查找

如果该位置为 null，那么直接返回 null 就可以了

如果该位置处的节点刚好就是我们需要的，返回该节点的值即可

如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树，后面我们再介绍 find 方法如果以上 3 条都不满足，那就是链表，进行遍历比对即可

10 java1.8中，ConCurrentHashmap是如何计算它的size大小的？

对于size的计算，在扩容和`addCount()`方法就已经有处理了，可以注意一下Put函数，里面就有`addCount()`函数。

11 ConcurrentHashMap有哪些构造函数？

一共有五个，作用及代码如下：

```java
//无参构造函数
    public ConcurrentHashMap() {
    }
    //可传初始容器大小的构造函数
    public ConcurrentHashMap(int initialCapacity) {
        if (initialCapacity < 0)
            throw new IllegalArgumentException();
        int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?
                   MAXIMUM_CAPACITY :
                   tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
        this.sizeCtl = cap;
    }
    //可传入map的构造函数
    public ConcurrentHashMap(Map<? extends K, ? extends V> m) {
        this.sizeCtl = DEFAULT_CAPACITY;
        putAll(m);
    }
    //可设置阈值和初始容量
    public ConcurrentHashMap(int initialCapacity, float loadFactor) {
        this(initialCapacity, loadFactor, 1);
    }

    //可设置初始容量和阈值和并发级别
    public ConcurrentHashMap(int initialCapacity,
                             float loadFactor, int concurrencyLevel) {
        if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
            throw new IllegalArgumentException();
        if (initialCapacity < concurrencyLevel)   // Use at least as many bins
            initialCapacity = concurrencyLevel;   // as estimated threads
        long size = (long)(1.0 + (long)initialCapacity / loadFactor);
        int cap = (size >= (long)MAXIMUM_CAPACITY) ?
            MAXIMUM_CAPACITY : tableSizeFor((int)size);
        this.sizeCtl = cap;
    }
```

12 ConcurrentHashMap使用什么技术来保证线程安全？

jdk1.7：Segment+HashEntry来进行实现的；

jdk1.8：放弃了Segment臃肿的设计，采用`Node+CAS+Synchronized`来保证线程安全；

13 ConcurrentHashMap的get方法是否要加锁，为什么？

不需要，get方法采用了unsafe方法，来保证线程安全。

14 ConcurrentHashMap迭代器是强一致性还是弱一致性？HashMap呢？

弱一致性，HashMap强一致性。（什么意思？）

ConcurrentHashMap可以支持在迭代过程中，向map添加新元素，而HashMap则抛出了`ConcurrentModificationException`，因为HashMap包含一个修改计数器，当你调用他的`next()`方法来获取下一个元素时，迭代器将会用到这个计数器。

15 ConcurrentHashMap1.7和1.8的区别

jdk1.8的实现降低锁的粒度，jdk1.7锁的粒度是基于Segment的，包含多个HashEntry，而jdk1.8锁的粒度就是Node

数据结构：jdk1.7 Segment+HashEntry；jdk1.8 数组+链表+红黑树+CAS+synchronized



***\*并发环境下为什么使用ConcurrentHashMap\****

\1. HashMap在高并发的环境下，执行put操作会导致HashMap的Entry链表形成环形数据结构，从而导致Entry的next节点始终不为空，因此产生死循环获取Entry

\2. HashTable虽然是线程安全的，但是效率低下，当一个线程访问HashTable的同步方法时，其他线程如果也访问HashTable的同步方法，那么会进入阻塞或者轮训状态。

\3. 在jdk1.6中ConcurrentHashMap使用锁分段技术提高并发访问效率。首先将数据分成一段一段地存储，然后给每一段数据配一个锁，当一个线程占用锁访问其中一段数据时，其他段的数据也能被其他线程访问。然而在jdk1.8中的实现已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层依然采用数组+链表+红黑树的存储结构。







![image-20210813092427849](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210813092427849.png)





## 🐄CountDownLatch（线程计数器 ）

CountDownLatch 类位于java.util.concurrent 包下，利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他4 个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。

```java

public class countDown {
    public static void main(String[] args) throws InterruptedException {


        final CountDownLatch latch = new CountDownLatch(2);
        new Thread() {
            public void run() {
                try {
                    System.out.println("子线程" + Thread.currentThread().getName() + "正在执行");
                    Thread.sleep(3000);
                    System.out.println("子线程" + Thread.currentThread().getName() + "执行完毕");
                    latch.countDown();
                }catch (InterruptedException e)
                {
                    e.printStackTrace();}
            }

            ;
        }.start();
        new Thread() {
            public void run() {
                try {
                    System.out.println("子线程" + Thread.currentThread().getName() + "正在执行");
                    Thread.sleep(3000);
                    System.out.println("子线程" + Thread.currentThread().getName() + "执行完毕");
                    latch.countDown();
                }catch (InterruptedException e)
                {
                    e.printStackTrace();}

            }

            ;
        }.start();
        System.out.println("等待2 个子线程执行完毕...");
        latch.await();
        System.out.println("2 个子线程已经执行完毕");
        System.out.println("继续执行主线程");
    }
}


```





![image-20210805095809238](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210805095809238.png)

例二：

```java
/**
 * @author ：图灵-杨过
 * @date：2019/7/11
 * @version: V1.0
 * @slogan: 天下风云出我辈，一入代码岁月催
 * @description : 看医生任务
 */
public class SeeDoctorTask implements Runnable {
    private CountDownLatch countDownLatch;

    public SeeDoctorTask(CountDownLatch countDownLatch){
        this.countDownLatch = countDownLatch;
    }

    public void run() {
        try {
            System.out.println("开始看医生");
            Thread.sleep(2000);
            System.out.println("看医生结束，准备离开病房");
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            if (countDownLatch != null)
                countDownLatch.countDown();
        }
    }

}
```

```java
public class QueueTask implements Runnable {

    private CountDownLatch countDownLatch;

    public QueueTask(CountDownLatch countDownLatch){
        this.countDownLatch = countDownLatch;
    }
    public void run() {
        try {
            System.out.println("开始在医院药房排队买药....");
            Thread.sleep(5000);
            System.out.println("排队成功，可以开始缴费买药");
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            if (countDownLatch != null)
                countDownLatch.countDown();
        }
    }
}
```

```java
public class CountDownLaunchRunner {

    public static void main(String[] args) throws InterruptedException {
        long now = System.currentTimeMillis();
        CountDownLatch countDownLatch = new CountDownLatch(1);

        new Thread(new SeeDoctorTask(countDownLatch)).start();
        new Thread(new QueueTask(countDownLatch)).start();


        Thread.sleep(3000);
        //等待线程池中的2个任务执行完毕，否则一直等待,zk分布式锁
        countDownLatch.countDown();
        System.out.println("over，回家 cost:"+(System.currentTimeMillis()-now));
    }
```







## CyclicBarrier和CountDownLatch的区别

CyclicBarrirer从名字上来理解是“循环的屏障”的意思。前⾯提到了
CountDownLatch⼀旦计数值 count 被降为0后，就不能再重新设置了，它只能起⼀次“屏障”的作⽤。⽽CyclicBarrier拥有CountDownLatch的所有功能，还可以使⽤ reset() ⽅法重置屏障。

两个看上去有点像的类，都在java.util.concurrent 下，都可以用来表示代码运行到某个点上，二者的区别在于：
1、CyclicBarrier 的某个线程运行到某个点上之后，该线程即停止运行，直到所有的线程都到达了这个点，所有线程才重新运行； CountDownLatch 则不是，某线程运行到某个点上之后，只是给某个数值-1而已，该线程继续运行
2、CyclicBarrier 只能唤起一个任务， CountDownLatch 可以唤起多个任务

3、CyclicBarrier 可重用， CountDownLatch 不可重用，计数值为0该CountDownLatch 就不可再用了

![image-20210923191001974](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210923191001974.png)

CountDownLatch:

计数器：计数器只能使用一次。

等待：一个线程或多个等待另外n个线程完成之后才能执行。



**CountDownLatch的用法**
CountDownLatch典型用法1：某一线程在开始运行前等待n个线程执行完毕。将CountDownLatch的计数器初始化为n new CountDownLatch(n) ，每当一个任务线程执行完毕，就将计数器减1 countdownlatch.countDown()，当计数器的值变为0时，在CountDownLatch上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。

CountDownLatch典型用法2：实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的CountDownLatch(1)，将其计数器初始化为1，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为0，多个线程同时被唤醒。

CountDownLatch原理
CountDownLatch是通过一个计数器来实现的，计数器的初始化值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就相应得减1。当计数器到达0时，表示所有的线程都已完成任务，然后在闭锁上等待的线程就可以恢复执行任务。 



CyclicBarrier:

计数器：计数器可以重置(通过reset()方法)。

等待：n个线程相互等待，任何一个线程完成之前，所有的线程都必须等待。



CountDownLatch

说明： 一个线程等待其他线程执行完之后再执行，相当于加强版的join，在初始化CountDownLatch是需要设定计数器的数值（计数器数据不一定跟线程数相同，但是一定计数器的值一定是要大于等于线程数，一个线程中可以进行多次扣减。当计数器扣减至0时才可继续向下执行）

举例说明：
比如LOL在游戏开始时需要玩家全部准备完毕之后才开始，开始游戏可以理解为“主线程”，玩家准备理解为“其他线程”，在“其他线程”没有准备完毕之前，“主线程时等待状态”，当“其他线程”准备完毕之后“主线程”就会执行下一步开始游戏的动作

![image-20211221231403292](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211221231403292.png)

```java
public class CountDownLatchTest {
    private static CountDownLatch countDownLatsh = new CountDownLatch(5);

    private static class Player implements Runnable{
        private Integer index;
        public Player(Integer index){
            this.index = index;
        }

        @Override
        public void run() {
            System.out.println("玩家"+index+"准备完成");
            countDownLatsh.countDown();
        }
    }  
    public static void main(String[] args) throws InterruptedException {   
        for(int i = 0; i < 5; i++){
            Player player = new Player(i);
            Thread thread = new Thread(player);
            thread.start();
        }
        countDownLatsh.await();
        System.out.println("玩家准备完毕，开始游戏");
    }
}

```

玩家0准备完成 玩家1准备完成 玩家2准备完成 玩家3准备完成 玩家4准备完成 玩家准备完毕，开始游戏

cyclicbarrier
说明： 让一组线程到达某个屏障，然后被阻塞，一直到最后一个线程到达屏障，然后屏障开放，所有被阻塞的线程继续执行，计数器与线程数相等。
CyclicBarrier(int parties, Runnable barrierAction) 当时使用这个构造函数时，barrierAction定义的任务会执行

举例说明： 假设有一家公司要全体员工进行团建活动，活动内容为翻越三个障碍物，每一个人翻越障碍物所用的时间是不一样的。但是公司要求所有人在翻越当前障碍物之后再开始翻越下一个障碍物，也就是所有人翻越第一个障碍物之后，才开始翻越第二个，以此类推比如跨栏比赛，我们修改一下规则，当所有选手都跨过第一个栏杆是，才去跨第二个，以此类推，每一个员工都是一个“其他线程”。当所有人都翻越的所有的障碍物之后，程序才结束。而主线程可能早就结束了，这里我们不用管主线程。

![image-20211221232314397](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20211221232314397.png)



代码

```java
public class CyclicBarrierTest {

    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(5);
    
    public static class Surmount implements Runnable{
        @Override
        public void run() {

            try {
                for(int i = 1; i < 4; i++){
                    Random rand = new Random();
                    int randomNum = rand.nextInt((3000 - 1000) + 1) + 1000;//产生1000到3000之间的随机整数
                    Thread.sleep(randomNum);
                    String name = Thread.currentThread().getName();
                    System.out.println(name+"翻过了第" + i +"个障碍");
                    cyclicBarrier.await();
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (BrokenBarrierException e) {
                e.printStackTrace();
            }
        }
    }
    
    public static void main(String[] args){
        for (int i = 1; i < 6; i++){
            Thread thread = new Thread(new Surmount(),"选手"+ i );
            thread.start();
        }
        System.out.println("main is end");
    }
}

```





## 🐄CyclicBarrier

（回环栅栏-等待至barrier 状态再全部同时执行）
字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier 可以被重用。我们暂且把这个状态就就直接让到达barrier 的线程执行后续任务。

❓❓未理解

```java
    public static void main(String[] args) throws InterruptedException {

        int N = 4;
        CyclicBarrier barrier = new CyclicBarrier(N);
        for(int i=0;i<N;i++)
            new Writer(barrier).start();
    }
    static class Writer extends Thread{
        private CyclicBarrier cyclicBarrier;
        public Writer(CyclicBarrier cyclicBarrier) {
            this.cyclicBarrier = cyclicBarrier;
        }
        @Override
        public void run() {
            try {
                Thread.sleep(3000); //以睡眠来模拟线程需要预定写入数据操作
                System.out.println(" 线程"+Thread.currentThread().getName()+" 写入数据完毕，等待其他线程写入完毕");
cyclicBarrier.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }catch(BrokenBarrierException e){
                e.printStackTrace();
            }
            System.out.println("所有线程写入完毕，继续处理其他任务，比如数据操作");
        }
    }
```

![image-20210805100504529](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210805100504529.png)



## 如何控制某个方法允许并发访问线程的大小

Semaphore两个重要的方法就是semaphore.acquire() 请求一个信号量，这时候的信号量个数-1（一旦没有可使用的信号量，也即信号量个数变为负数时，再次请求的时候就会阻塞，直到其他线程释放了信号量）semaphore.release()释放一个信号量，此时信号量个数+1

```java
public class semaphere {
      private Semaphore mSemaphore = new Semaphore(5);
                public void run(){
                    for(int i=0; i< 20; i++){
                        new Thread(new Runnable() {
                            @Override
                public void run() {
                    test();
                }
            }).start();
        }
    }
    private void test(){
        try {
            mSemaphore.acquire();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println(Thread.currentThread().getName() + " 进来了");
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println(Thread.currentThread().getName() + " 出去了");
        mSemaphore.release();
    }

    public static void main(String[] args) {
        semaphere se = new semaphere();
        se.run();
    }
}
```



《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险
Executors 返回线程池对象的弊端如下：
FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为
Integer.MAX_VALUE,可能堆积大量的请求，从而导致OOM。
CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为
Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。

```java
    public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>(),
                                      threadFactory);
    }
public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>(),
                                threadFactory));
}
    public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>(),
                                      threadFactory);
    }
        public ScheduledThreadPoolExecutor(int corePoolSize,
                                       ThreadFactory threadFactory) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
              new DelayedWorkQueue(), threadFactory);
    }
```



## 🐄Semaphore（信号量-控制同时访问的线程个数）

Semaphore 是一种基于计数的信号量。它可以设定一个阈值，基于此，多个线程竞争获取许可信号，做完自己的申请后归还，超过阈值后，线程申请许可信号将会被阻塞。Semaphore 可以用来构建一些对象池，资源池之类的，比如数据库连接池

我们也可以创建计数为1 的Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。

```java
// 创建一个计数阈值为5 的信号量对象
// 只能5 个线程同时访问

Semaphore semp = new Semaphore(5);
try { // 申请许可
semp.acquire();
try {
// 业务逻辑
    } catch (Exception e) {
} finally {
// 释放许可
semp.release();
}
} catch (InterruptedException e) {
}
```



Semaphore 基本能完成ReentrantLock 的所有工作，使用方法也与之类似，通过acquire()与release()方法来获得和释放临界资源。经实测，Semaphone.acquire()方法默认为可响应中断锁，与ReentrantLock.lockInterruptibly()作用效果一致，也就是说在等待临界资源的过程中可以被Thread.interrupt()方法中断。

此外，Semaphore 也实现了**可轮询的锁请求与定时锁的功能**，除了方法名tryAcquire 与tryLock不同，其使用方法与ReentrantLock 几乎一致。Semaphore 也提供了公平与非公平锁的机制，也可在构造函数中进行设定。
Semaphore 的锁释放操作也由手动进行，因此与ReentrantLock 一样，为避免线程因抛出异常而无法正常释放锁的情况发生，释放锁的操作也必须在finally 代码块中完成。

Semaphore 翻译成字面意思为 信号量，Semaphore 可以控制同时访问的线程个数，通过acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。
Semaphore 类中比较重要的几个方法：

1. public void acquire(): 用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。
2. public void acquire(int permits):获取permits 个许可
3. public void release() { } :释放许可。注意，在释放许可之前，必须先获获得许可。
4. public void release(int permits) { }:释放permits 个许可上面4 个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法:

1. public boolean tryAcquire():尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回false
2. public boolean tryAcquire(long timeout, TimeUnit unit):尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false
3. public boolean tryAcquire(int permits):尝试获取permits 个许可，若获取成功，则立即返回true，若获取失败，则立即返回false
4. public boolean tryAcquire(int permits, long timeout, TimeUnit unit): 尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false
5. 还可以通过availablePermits()方法得到可用的许可数目。

例子：若一个工厂有5 台机器，但是有8 个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore 来实现：

```java
 public static void main(String[] args) throws InterruptedException {

       int N = 8;//工人数目
        Semaphore semaphore = new Semaphore(5);//机器数目
        for(int i = 0;i < N;i++)
           new Worker(i,semaphore).start();
    }

static class Worker extends Thread{
            private int num;
            private Semaphore semaphore;
            public Worker(int num,Semaphore semaphore)
            {
                this.num = num;
                this.semaphore = semaphore;
            }
@Override
public void run()
{
    try{
        semaphore.acquire();
        System.out.println("一个工人"+this.num+"在占用机器生产");
        Thread.sleep(2000);
        System.out.println("一个工人"+this.num+"释放机器");
        semaphore.release();
    }catch (InterruptedException e)
    {
        e.printStackTrace();
    }
}
            }
```



![image-20210805101515742](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210805101515742.png)

最多只有五个人占用机器



## 练习：交替打印字符串

前置知识点：

做算法题，按序执行，使用信号量的方式，使用了new Semaphore(0)，之前不明白，后来了解到，当信号量为0的时候，在线程使用了acquire()去请求信号量，结果就会导致整个程序阻塞了。原来是调用了acquire()相当于是信号量从0，减去1变成-1，此时如果没有执行release，那么线程就会阻塞在这里。使用release会使信号量+1。此时才不会阻塞。

总结，使用了new Semaphore(0)之后要先release然后才能acquire

编写一个可以从 1 到 n 输出代表这个数字的字符串的程序，但是：

如果这个数字可以被 3 整除，输出 "fizz"。
如果这个数字可以被 5 整除，输出 "buzz"。
如果这个数字可以同时被 3 和 5 整除，输出 "fizzbuzz"。
例如，当 n = 15，输出： 1, 2, fizz, 4, buzz, fizz, 7, 8, fizz, buzz, 11, fizz, 13, 14, fizzbuzz。

请你实现一个有四个线程的多线程版  FizzBuzz， 同一个 FizzBuzz 实例会被如下四个线程使用：

线程A将调用 fizz() 来判断是否能被 3 整除，如果可以，则输出 fizz。
线程B将调用 buzz() 来判断是否能被 5 整除，如果可以，则输出 buzz。
线程C将调用 fizzbuzz() 来判断是否同时能被 3 和 5 整除，如果可以，则输出 fizzbuzz。
线程D将调用 number() 来实现输出既不能被 3 整除也不能被 5 整除的数字。

--------

解答：

```java
class FizzBuzz {
    private int n;
Semaphore semaphorenormal;
Semaphore semaphore3;
Semaphore semaphore5;
Semaphore semaphore35;
    public FizzBuzz(int n) {
        this.n = n;
        semaphorenormal = new Semaphore(1);
        semaphore3 = new Semaphore(0);
semaphore5 = new Semaphore(0);
semaphore35 = new Semaphore(0);
    }
    // printFizz.run() outputs "fizz".
    public void fizz(Runnable printFizz) throws InterruptedException {
for(int i = 3;i<=n;i+=3)
{
    semaphore3.acquire();
if(i % 5==0)
continue;
printFizz.run();
semaphorenormal.release();
}
    }
    // printBuzz.run() outputs "buzz".
    public void buzz(Runnable printBuzz) throws InterruptedException {
        for(int i = 5;i<=n;i+=5)
{
    semaphore5.acquire();
if(i % 3==0)
continue;
printBuzz.run();
semaphorenormal.release();
}
    }

    // printFizzBuzz.run() outputs "fizzbuzz".
    public void fizzbuzz(Runnable printFizzBuzz) throws InterruptedException {
                for(int i = 15;i<=n;i+=15)
{
    semaphore35.acquire();
printFizzBuzz.run();
semaphorenormal.release();
}
    }

    // printNumber.accept(x) outputs "x", where x is an integer.
    public void number(IntConsumer printNumber) throws InterruptedException {
      
        for(int i = 1;i<=n;i++)
        {
semaphorenormal.acquire();
            if(i %3==0&&i%5==0)
          { 
              semaphore3.release();
              semaphore5.release();
               semaphore35.release();
          
          continue;
          }
            if(i%3==0)
           {
                semaphore3.release();
           continue;
           }
            if(i%5==0)
            {
                semaphore5.release();
                continue;
            }
            printNumber.accept(i);
            semaphorenormal.release();
        }
    }
}
```







## semaphore源码

Semaphore（信号量）， 从概念上讲，信号量维护一套许可。每次 acquire 方法调用都会根据需要进行阻塞，直到获得许可为止，然后将其占用。每次 release 方法调用都会添加一个许可，可能会唤醒因没有获取到许可而阻塞的线程。Semaphore 基于 AQS 实现，不熟悉 AQS 的同学可以查阅笔者关于 AQS 源码分析的文章进行学习。关于 Semaphore 的使用我们就不过多赘述了，直接进入源码分析，我们首先来看一下 Semaphore 的构造方法：
Semaphore：
public Semaphore(int permits, boolean fair) {    sync = fair ? new FairSync(permits) : new NonfairSync(permits); }

permits 为许可的数量，fair 变量确定使用公平锁或非公平锁。Semaphore 的另一个重载的只有 permits 参数的构造方法使用的是非公平锁。下面我们来看许可的获取操作：
Semaphore：

public void acquire() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}
acquireSharedInterruptibly 方法，是可以响应中断的共享锁获取方法，方法中会调用由子类实现的 tryAcquireShared 方法实现共享锁获取逻辑，我们首先来看 Semaphore 非公平锁对于 tryAcquireShared 方法的实现：

**Semaphore.NonfairSync：**

```java
protected int tryAcquireShared(int acquires) {
    /* 非公平共享锁获取 */
    return nonfairTryAcquireShared(acquires);
}
```

Semaphore.Sync：

```java


final int nonfairTryAcquireShared(int acquires) {
    // 自旋
    for (;;) {
        // Semaphore 用 AQS 的 state 变量的值代表可用许可数
        int available = getState();
        // 可用许可数减去本次需要获取的许可数即为剩余许可数
        int remaining = available - acquires;
        // 如果剩余许可数小于0或者 CAS 将当前可用许可数设置为剩余许可数成功，则返回成功许可数
        if (remaining < 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}
```

Semaphore.FairSync：

```java


protected int tryAcquireShared(int acquires) {
    for (;;) {
        // 这里多了一步判断，是否存在应该先于当前线程获得锁的线程
        if (hasQueuedPredecessors())
            return -1;
        int available = getState();
        int remaining = available - acquires;
        if (remaining < 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}
```

我们发现，公平锁与非公平锁对 tryAcquireShared 方法的实现的唯一区别就是公平锁首先会判断是否存在应该先于当前线程获得锁的线程，如果存在说明当前线程不是下一个应该获取锁的线程。hasQueuedPredecessors 方法主要确认以下几种情况：

等待队列为空
当前线程所在的节点是头结点
当前线程所在的节点是头结点的后继节点
满足上述三个条件的任意一个，说明当前线程是下一个可以获取锁的线程，反之则说明当前线程不是下一个应该获取锁的线程，这时 tryAcquireShared 方法会返回-1代表获取共享锁失败。





## 线程池相关知识点

A. 执行程序
➢ Executors 线程池工厂类
首次我们来说下线程池的作用:
线程池作用就是限制系统中执行线程的数量。
根据系统的环境情况，可以自动或手动设置线程数量，达到运行的最佳效果；少了浪费了系统资源，多了造成系统拥挤效率不高。用线程池控制线程数量，其他线程 排队等候。一个任务执行完毕，再从队列的中取最前面的任务开始执行。若队列中没有等待进程，线程池的这一资源处于等待。当一个新任务需要运行时，如果线程 池中有等待的工作线程，就可以开始运行了；否则进入等待队列。
➢为什么要用线程池:
减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务
可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB 内存，线程开的越多，消耗的内存也就越大，最后死机)

线程池的好处：

第一：降低资源消耗。**通过重复利用已创建的线程降低线程创建和销毁造成的消耗。**

（为什么线程池可以重复利用已经创建的线程？为什么new Thread就不可以  ：

**线程池的基本思想还是一种对象池的思想，开辟一块内存空间，里面存放了众多(未死亡)的线程**，池中线程执行调度由池管理器来处理。当有线程任务时，从池中取一个，执行完成后线程对象归池，这样可以避免反复创建线程对象所带来的性能开销，节省了系统的资源）
第二：提高响应速度。当任务到达时，任务**可以不需要等到线程创建**就能立即执行。
第三：提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。



![image-20210905110100233](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210905110100233.png)

![image-20210905110719481](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210905110719481.png)

第一，在线程池中有一定数量的工作线程，并且线程数量以及任务数量会受到一定的控制和管理；第二，任务的执行将以异步的方式进行，也就是说线程池提交执行任务的方法将会立即返回；第三，线程池会负责执行任务的信息统计。 

ThreadPoolExecutor构造函数：

```java
public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize, long keepAliveTime,TimeUnit unit, BlockingQueue<Runnable> workQueue) {
this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,Executors.defaultThreadFactory(), defaultHandler);
}
```

1. corePoolSize：指定了线程池中的线程数量。
2. maximumPoolSize：指定了线程池中的最大线程数量。
3. keepAliveTime：当前线程池数量超过corePoolSize 时，**多余的空闲线程的存活时间，即多少时间内会被销毁。**
4. unit：keepAliveTime 的单位。
5. workQueue：任务队列，被提交但尚未被执行的任务。
6. threadFactory：线程工厂，用于创建线程，一般用默认的即可。
7. handler：拒绝策略，当任务太多来不及处理，如何拒绝任务。

执行顺序：

![image-20210824174158452](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210824174158452.png)

核心线程不会被释放。

![image-20210824174241402](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210824174241402.png)

![image-20210824174326052](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210824174326052.png)

**Executors各个方法的弊端：**
newFixedThreadPool和newSingleThreadExecutor：主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至OOM。
newCachedThreadPool和newScheduledThreadPool：要问题是线程数最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至OOM。
@Async默认异步配置使用的是SimpleAsyncTaskExecutor，该线程池默认来一个任务创建一个线程，若系统中不断的创建线程，最终会导致系统占用内存过高，引发OutOfMemoryError错误。针对线程创建问题，SimpleAsyncTaskExecutor提供了限流机制，通过concurrencyLimit属性来控制开关，当concurrencyLimit>=0时开启限流机制，默认关闭限流机制即concurrencyLimit=-1，当关闭情况下，会不断创建新的线程来处理任务。基于默认配置，SimpleAsyncTaskExecutor并不是严格意义的线程池，达不到线程复用的功能。 





```java
public static void main(String[] args)
        throws ExecutionException, InterruptedException
{
    // ① 创建ThreadPoolExecutor，7个构造参数
ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, 30,
            TimeUnit.SECONDS,
            new ArrayBlockingQueue<>(10),
            Executors.defaultThreadFactory(),
            new ThreadPoolExecutor.DiscardPolicy());

    // ② 提交执行异步任务，不关注返回值
executor.execute(() -> System.out.println(" execute the runnable task"));

    // ③ 提交执行异步任务，关注返回值
Future<String> future = executor.submit(() -> " Execute the callable task and this is the result");

    // ④获取并输出callable任务的返回值
    System.out.println(future.get());
} 

```

线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。
JDK 内置的拒绝策略如下：

1. AbortPolicy ：（中止策略）直接抛出异常，阻止系统正常运行。
2. CallerRunsPolicy ：（调用者运行策略） 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。
3. DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。
4. DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。
以上内置拒绝策略均实现了RejectedExecutionHandler 接口，若以上策略仍无法满足实际需要，完全可以自己扩展RejectedExecutionHandler 接口。

例子2：有返回值的线程池

有返回值的任务必须实现Callable 接口，类似的，无返回值的任务必须Runnable 接口。执行Callable 任务后，可以获取一个Future 的对象，在该对象上调用get 就可以获取到Callable 任务返回的Object 了，再结合线程池接口ExecutorService 就可以实现传说中有返回结果的多线程了。

```java
//创建一个线程池
ExecutorService pool = Executors.newFixedThreadPool(taskSize);
// 创建多个有返回值的任务
List<Future> list = new ArrayList<Future>();
for (int i = 0; i < taskSize; i++) {
Callable c = new MyCallable(i + " ");
// 执行任务并获取Future 对象
Future f = pool.submit(c);
list.add(f);
}
// 关闭线程池
pool.shutdown();
// 获取所有并发任务的运行结果
for (Future f : list) {
// 从Future 对象上获取任务的返回值，并输出到控制台
System.out.println("res：" + f.get().toString());
```







1. 当提交一个新任务到线程池时，具体的执行流程如下：

   1. 当我们提交任务，线程池会根据corePoolSize大小创建若干任务数量线程执行任务
   2. 当任务的数量超过corePoolSize数量，后续的任务将会进入阻塞队列阻塞排队
   3. 当阻塞队列也满了之后，那么将会继续创建(maximumPoolSize最大线程数-corePoolSize核心线程数)个数量的线程来执行任务，如果任务处理完成，maximumPoolSize-corePoolSize额外创建的线程等待keepAliveTime之后被自动销毁
   4. 如果达到maximumPoolSize，阻塞队列还是满的状态，那么将根据不同的拒绝策略对应处理

   

   **线程池的基本思想还是一种对象池的思想，开辟一块内存空间，里面存放了众多(未死亡)的线程**，池中线程执行调度由池管理器来处理。当有线程任务时，从池中取一个，执行完成后线程对象归池，这样可以避免反复创建线程对象所带来的性能开销，节省了系统的资源

   ```java
   //创建固定大小的线程池
   ExecutorService fPool = Executors.newFixedThreadPool(3);
   //创建缓存大小的线程池
   ExecutorService cPool = Executors.newCachedThreadPool();
   //创建单一的线程池
   ExecutorService sPool = Executors.newSingleThreadExecutor();
   
   public static void main(String[] args) {
   //创建一个可重用固定线程数的线程池
   ExecutorService pool = Executors.newFixedThreadPool(2);
   //创建实现了Runnable 接口对象，Thread 对象当然也实现了Runnable 接口
   Thread t1 = new MyThread();
   Thread t2 = new MyThread();
   Thread t3 = new MyThread();
   Thread t4 = new MyThread();
   Thread t5 = new MyThread();
   //将线程放入池中进行执行
   pool.execute(t1);
   pool.execute(t2);
   pool.execute(t3);
   pool.execute(t4);
   pool.execute(t5);
   //关闭线程池
   pool.shutdown();
   }
   ```

   不管execute 执行几次，线程池始终都会使用2 个线程来处理。不会再去创建出其他线程来处理run 方法执行。这就是固定大小线程池

   

   java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。

   newCachedThreadPool 

   创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute 将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。

   newFixedThreadPool

   创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大多数 nThreads 线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之前，池中的线程将一直存在。

   newScheduledThreadPool

   创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。

   ```java
   ScheduledExecutorService scheduledThreadPool= Executors.newScheduledThreadPool(3); 
   
   scheduledThreadPool.schedule(newRunnable(){
    @Override
     public void run() 
     { 
   System.out.println("延迟三秒"); 
   } 
   }, 3, 
   TimeUnit.SECONDS); 
   scheduledThreadPool.scheduleAtFixedRate(newRunnable(){ @Override 
   public void run() { 
   System.out.println("延迟1秒后每三秒执行一次");
    } },1,3,TimeUnit.SECONDS);
   ```

   newSingleThreadExecutor 

   Executors.newSingleThreadExecutor()返回一个线程池（这个线程池只有一个线程）,**这个线程池可以在线程死后（或发生异常时）重新启动一个线程来替代原来的线程继续执行下去！**

   构造ThreadPoolExecutor所需要的参数是比较多的，同时，ThreadPoolExecutor中提供了四个构造函数的重载形式，但是最终真正被调用的构造函数是囊括了所有7个构造参数的构造函数，代码如下所示。 

   ```java
   public ThreadPoolExecutor(int corePoolSize,
                int maximumPoolSize,
                long keepAliveTime,
                TimeUnit unit,
                BlockingQueue<Runnable> workQueue,
                ThreadFactory threadFactory,
                RejectedExecutionHandler handler) {
   ...省略 
   }
   ```

   ■ corePoolSize：用于指定在线程池中维护的核心线程数量，即使当前线程池中的核心线程不工作，核心线程的数量也不会减少（在JDK1.6版本及以后可以通过设置允许核心线程超时的方法allowCoreThreadTimeOut来改变这种情况） 

    ■ maximumPoolSize：用于设置线程池中允许的线程数量的最大值。

   ■ keepAliveTime：当线程池中的线程数量超过核心线程数并且处于空闲时，线程池将回收一部分线程让出系统资源，该参数可用于设置超过corePoolSize数量的线程在多长时间后被回收，与unit配合使用。


   前线程池中的核心线程不工作，核心线程的数量也不会减少（在JDK1.6版本及以后可以通过设置允许核心线程超时的方法allowCoreThreadTimeOut来改变这种情况）。 

   ■ maximumPoolSize：用于设置线程池中允许的线程数量的最大值。 ■ keepAliveTime：当线程池中的线程数量超过核心线程数并且处于空闲时，线程池将回收一部分线程让出系统资源，该参数可用于设置超过corePoolSize数量的线程在多长时间后被回收，与unit配合使用。 

   ■ TimeUnit：用于设定keepAliveTime的时间单位。 

   ■ workQueue：用于存放已提交至线程池但未被执行的任务。 

   ■ ThreadFactory：用于创建线程的工厂，开发者可以通过自定义ThreadFactory来创建线程，比如，根据业务名为线程命名、设置线程优先级、设置线程是否为守护线程等、设置线程所属的线程组等。 

   ■ RejectedExecutionHandler： 
   当任务数量超过阻塞队列边界时，这个时候线程池就会拒绝新增的任务，该参数主要用于设置拒绝策略。 ThreadPoolExecutor的构造比较复杂，除了其对每一个构造参数都有一定的要求之外（比如，不能为null），个别构造参数之间也存在一定的约束关系。 

   包括：

   ■ DiscardOldestPolicy：丢弃任务队列中最老任务的策略（这是笔者通过类名直译过来的，事实上这样直译不够准确，通过4.2节阻塞队列部分的学习，相信大家都知道并不是所有的阻塞队列都是FIFO，也就是说**最早进入任务队列中的任务并不一定是最早**（老）的，比如，优先级阻塞队列会根据排序规则来决定将哪个任务放在队头）。 

   ```java
   public DiscardOldestPolicy()
   {
   }
   
   public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
     if (!e.isShutdown()) {
       // 从阻塞队列头部移除老的任务
       e.getQueue().poll();
       // 将最新的任务加入任务队列或者执行
       e.execute(r);
     }
   } 
   ```

   ■ AbortPolicy：中止策略，在线程池中使用该策略，在无法受理任务时会抛出拒绝执行异常RejectedExecutionException（运行时异常）。 ...省略

   ```java
   public AbortPolicy() { }
   
   public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
     // 抛出RejectedExecutionException异常
     throw new RejectedExecutionException("Task " + r.toString() +
                        " rejected from " +
                        e.toString());
   }
   
   
   ```

   ■ DiscardPolicy：丢弃策略，任务会被直接无视丢弃而等不到执行，因此该策略需要慎重使用。

   ```java
   public static class DiscardPolicy
          implements RejectedExecutionHandler
   {
     public DiscardPolicy()
     {
     }
     // 空实现，无视提交的任务
     public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
     }
   }
   ```

   ■ CallerRunsPolicy：调用者线程执行策略，前面的三种拒绝策略要么会在执行execute方法时抛出异常，要么会将任务丢弃。该策略不会导致新任务的丢失，**但是任务会在当前线程中被阻塞地执行**，也就是说任务不会由线程池中的工作线程执行。 

   ```java
   public CallerRunsPolicy()
   {
   }
   public void rejectedExecution(Runnable r, ThreadPoolExecutor e)
   {
     if (!e.isShutdown()) {
       // 在当前线程中同步执行任务
       r.run();
     }
   }
   
   
   ```

   ThreadPoolExecutor的demo:

   ```java
   /**
   * 这是⼀个简单的Runnable类，需要⼤约5秒钟来执⾏其任务。
   * @author shuang.kou
   */
   public class MyRunnable implements Runnable {
   private String command;
   public MyRunnable(String s) {
   this.command = s;
   }
   @Override
   public void run() {
   System.out.println(Thread.currentThread().getName() + " Start.Time = " + new Date());
   processCommand();
   System.out.println(Thread.currentThread().getName() + " End.Time = " + new Date());
   }
   private void processCommand() {
   try {
   Thread.sleep(5000);
   } catch (InterruptedException e) {
   e.printStackTrace();
   }
   }
   @Override
   public String toString() {
   return this.command;
   }
   }
   public class ThreadPoolExecutorDemo {
   private static final int CORE_POOL_SIZE = 5;
   private static final int MAX_POOL_SIZE = 10;
   private static final int QUEUE_CAPACITY = 100;
   private static final Long KEEP_ALIVE_TIME = 1L;
   public static void main(String[] args) {
   //使⽤阿⾥巴巴推荐的创建线程池的⽅式
   //通过ThreadPoolExecutor构造函数⾃定义参数创建
   ThreadPoolExecutor executor = new ThreadPoolExecutor(
   CORE_POOL_SIZE,
   MAX_POOL_SIZE,
   KEEP_ALIVE_TIME,
   TimeUnit.SECONDS,
   new ArrayBlockingQueue<>(QUEUE_CAPACITY),
   new ThreadPoolExecutor.CallerRunsPolicy());
   for (int i = 0; i < 10; i++) {
   //创建WorkerThread对象（WorkerThread类实现了Runnable 接⼝）
   Runnable worker = new MyRunnable("" + i);
   //执⾏Runnable
   executor.execute(worker);
   }
   //终⽌线程池
   executor.shutdown();
   while (!executor.isTerminated()) {
   }
   System.out.println("Finished all threads");
   }
   }
   ```

   

   ThreadPoolExecutor的其他方法 ThreadPoolExecutor不仅提供了可重复使用的工作线程，还使得任务的异步执行变得高效，同时它还提供了很多统计信息和查询监控线程池中的工作线程、任务等的方法，如表5-1 

   

   

   ■ TimeUnit、workQueue、ThreadFactory、RejectedExecutionHandler不能为null。 

   ■ corePoolSize可以设置为0，但不能小于0，并且corePoolSize不能大于线程的最大数量（maximumPoolSize）。 

   3. 执行任务方法详解 线程池被成功构造后，其内部的运行线程并不会立即被创建，**ThreadPoolExecutor的核心线程将会采用一种Lazy（懒）的方式来创建并且运行，当线程池被创建，并且首次调用执行任务方法时才会创建，并且运行** 

   4. 当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。在线程的生命周期中，它要经过新建(New)、就绪（Runnable）、运行（Running）、阻塞(Blocked)和死亡(Dead)5种状态。尤其是当线程启动以后，它不可能一直"霸占"着CPU独自运行，所以CPU需要在多条线程之间切换，于是线程状态也会多次在运行、阻塞之间切换

      为什么阿里巴巴手册不推荐用jdk的线程池工具？（即如ExecutorService executorService == Executors.newCachedThreadPool(); ）

   ---------newCachedThreadPool不会出现oom



# 用线程池进行定时任务

⾃JDK 1.5 开始，JDK提供了 ScheduledThreadPoolExecutor 类⽤于计划任务（⼜称定时任务），这个类有两个⽤途：
在给定的延迟之后运⾏任务 周期性重复执⾏任务
在这之前，是使⽤ Timer 类来完成定时任务的，但是 Timer 有缺陷：
Timer是单线程模式；
如果在执⾏任务期间某个TimerTask耗时较久，那么就会影响其它任务的调度；Timer的任务调度是基于绝对时间的，对系统时间敏感；Timer不会捕获执⾏TimerTask时所抛出的异常，由于Timer是单线程，所以⼀旦出现异常，则线程就会终⽌，其他任务也得不到执⾏。
所以JDK 1.5之后，⼤家就摒弃 Timer ,使⽤ScheduledThreadPoolExecutor 吧。

```java
public class ThreadPool {
private static final ScheduledExecutorService executor = new
ScheduledThreadPoolExecutor(1, Executors.defaultThreadFactory());
private static SimpleDateFormat df = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
public static void main(String[] args){
// 新建⼀个固定延迟时间的计划任务
executor.scheduleWithFixedDelay(new Runnable() {
@Override
public void run() {
if (haveMsgAtCurrentTime()) {
System.out.println(df.format(new Date()));
System.out.println("⼤家注意了，我要发消息了");
}
}
}, 1, 1, TimeUnit.SECONDS);
}
public static boolean haveMsgAtCurrentTime(){
//查询数据库，有没有当前时间需要发送的消息
//这⾥省略实现，直接返回true
return true;
}
}
```



# 为什么阿里巴巴开发规范不建议使用Excutors

阿里规约之所以强制要求手动创建线程池,规约是这么说的：

线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。

Executor提供的四个静态方法创建线程池，但是阿里规约却并不建议使用它。

Executors各个方法的弊端：
1）newFixedThreadPool和newSingleThreadExecutor:
  主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至OOM。这两个类的阻塞队列是一个无界队列LinkedBlockingQueue,是一个最大值为Integer.MAX_VALUE的线程阻塞队列，当添加任务的速度大于线程池处理任务的速度，可能会在队列堆积大量的请求，消耗很大的内存，甚至导致OOM。
2）newCachedThreadPool和newScheduledThreadPool:
  主要问题是线程数最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至OOM。创建的线程池允许的最大线程数是Integer.MAX_VALUE，空闲线程存活时间为0，当添加任务的速度大于线程池处理任务的速度，可能会创建大量的线程，消耗资源，甚至导致OOM。

   ## 自定义线程工厂示例

   ```java
   package io.github.viscent.mtia.ch8;//xm:javaMutiThreadInAction
   
   import java.lang.Thread.UncaughtExceptionHandler;
   import java.util.concurrent.ThreadFactory;
   import java.util.concurrent.atomic.AtomicInteger;
   import java.util.logging.Level;
   import java.util.logging.Logger;
   
   public class XThreadFactory implements ThreadFactory {
     final static Logger LOGGER = Logger.getAnonymousLogger();
     private final UncaughtExceptionHandler ueh;
     private final AtomicInteger threadNumber = new AtomicInteger(1);
     // 所创建的线程的线程名前缀
     private final String namePrefix;
   
     public XThreadFactory(UncaughtExceptionHandler ueh, String name) {
       this.ueh = ueh;
       this.namePrefix = name;
     }
   
     public XThreadFactory(String name) {
       this(new LoggingUncaughtExceptionHandler(), name);
     }
   
     public XThreadFactory(UncaughtExceptionHandler ueh) {
       this(ueh, "thread");
     }
   
     public XThreadFactory() {
       this(new LoggingUncaughtExceptionHandler(), "thread");
     }
   
     protected Thread doMakeThread(final Runnable r) {
       return new Thread(r) {
         @Override
         public String toString() {
           // 返回对问题定位更加有益的信息
           ThreadGroup group = getThreadGroup();
           String groupName = null == group ? "" : group.getName();
           String threadInfo = getClass().getSimpleName() + "[" + getName() + ","
               + getId() + ","
               + groupName + "]@" + hashCode();
           return threadInfo;
         }
       };
     }
   
     @Override
     public Thread newThread(Runnable r) {
       Thread t = doMakeThread(r);
       t.setUncaughtExceptionHandler(ueh);
       t.setName(namePrefix + "-" + threadNumber.getAndIncrement());
       if (t.isDaemon()) {
         t.setDaemon(false);
       }
       if (t.getPriority() != Thread.NORM_PRIORITY) {
         t.setPriority(Thread.NORM_PRIORITY);
       }
       if (LOGGER.isLoggable(Level.FINE)) {
         LOGGER.fine("new thread created" + t);
       }
       return t;
     }
   
     static class LoggingUncaughtExceptionHandler implements
         UncaughtExceptionHandler {
       @Override
       public void uncaughtException(Thread t, Throwable e) {
         // 将线程异常终止的相关信息记录到日志中
         LOGGER.log(Level.SEVERE, t + " terminated:", e);
       }
     }// LoggingUncaughtExceptionHandler类定义结束
   }
   ```

   使用刚刚创建的线程工厂：

   ```java
   public class XThreadFactoryUsage {
     final static ThreadPoolExecutor executor = new ThreadPoolExecutor(4, 4, 4,
         TimeUnit.SECONDS,
         new ArrayBlockingQueue<Runnable>(1 * 8),
         new ThreadPoolExecutor.CallerRunsPolicy());
   // CallerRunsPolicy :这个策略重试添加当前的任务,他会自动重复调用 execute() 方法,直到成功。
     public static void main(String[] args) {
       final ThreadFactory tf = new XThreadFactory("worker");
       executor.setThreadFactory(tf);
   
       final Random rnd = new Random();
   
       for (int i = 0; i < 10; i++) {
         executor.execute(new Runnable() {
           @Override
           public void run() {
             Debug.info("running...");
             // 模拟随机性运行时异常抛出
             new TaskWithException(rnd).run();
           }
   
         });
       }
     }
   }
   ```

   关于上面的自定义抛出异常：

   ```java
   public class TaskWithException implements Runnable {
      final Random rnd;
      
      public TaskWithException(Random rnd) {
        super();
        this.rnd = rnd;
     }
   
      @Override
      public void run() {
         
          while(true){
             if(rnd.nextInt(100)<2){
                throw new RuntimeException("test");
             }
             Tools.randomPause(50);
          }
   
      }
   
   }
   ```

   

   

   ## Java线程池中submit() 和 execute()方法有什么区别？

   两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中, **而submit()方法可以返回持有计算结果的Future对象**，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法。

   ![image-20210922221808188](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210922221808188.png)

   

   ## FutureTask的使用

   ```java
   Callable<Boolean>hJob = new HotWarterJob();//异步逻辑
   FutureTask<Boolean>hTask = new FutureTask<Boolean>(hJob);//搭桥实例
   Thread hThread = new Thread(hTask, "** 烧水-Thread");//异步线程
    
   
   ```

    FutureTask和Callable都是泛型类，泛型参数表示返回结果的类型。所以，在使用的时候，它们两个实例的泛型参数一定需要保持一致的。 最后，通过FutureTask类的实例，取得异步线程的执行结果。一般来说，通过FutureTask实例的get方法，可以获取线程的执行结果。 总之，FutureTask类的实现比join线程合并操作更加高明，能取得异步线程的结果。但是，也就未必高明到哪里去了。为啥呢？ 因为通过FutureTask类的get方法，获取异步结果时，主线程也会被阻塞的。这一点，**FutureTask和join也是一样的，它们俩都是异步阻塞模式。 异步阻塞的效率往往是比较低的，被阻塞的主线程不能干任何事情，唯一能干的，就是在傻傻地等待**。原生Java API，除了阻塞模式的获取结果外，并没有实现非阻塞的异步结果获取方法。如果需要用到获取异步的结果，则需要引入一些额外的框架，比如Guava框架 

---------------------------------------------------------------------------------------------

## future接口

juc包下future接口：有以下实现类：

![image-20220816214848266](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220816214848266.png)

RunnableFuture

RunnableFuture 接口同时继承了 Future 接口和 Runnable 接口，在成功执行完成 run() 以后，可以通过 Future 访问执行结果

RunnableFuture 接口的实现类是 FutureTask，FutureTask 是一个可取消的异步计算，FutureTask 类提供了 Future 的基本实现，（取消、判断是否取消、判断是否完成、获取异步结果（阻塞）、有限时间获取异步结果（阻塞））

FutureTask 能用来包装一个 Callable 或 Runnable 对象，因为它实现了 Runnable 接口，而且它能被传递到 Executor 进行执行，为了提供单例类，这个类再创建自定义的工作类时提供了 protected 构造函数


## Exchanger类

Exchanger类⽤于两个线程交换数据。它⽀持泛型，也就是说你可以在两个线程之间传送任何数据。先来⼀个案例看看如何使⽤，⽐如两个线程之间想要传送字符串：

```java
public class ExchangerDemo {
public static void main(String[] args) throws InterruptedException {
Exchanger<String> exchanger = new Exchanger<>();
new Thread(() -> {
try {
System.out.println("这是线程A，得到了另⼀个线程的数据："
+ exchanger.exchange("这是来⾃线程A的数据"));
  } catch (InterruptedException e) {
  e.printStackTrace();
  }
  }).start();
  System.out.println("这个时候线程A是阻塞的，在等待线程B的数据");
  Thread.sleep(1000);
  new Thread(() -> {
  try {
  System.out.println("这是线程B，得到了另⼀个线程的数据："
+ exchanger.exchange("这是来⾃线程B的数据"));
  } catch (InterruptedException e) {
  e.printStackTrace();
  }
  }).start();
  }
  }


```

输出：
这个时候线程A是阻塞的，在等待线程B的数据
这是线程B，得到了另⼀个线程的数据：这是来⾃线程A的数据
这是线程A，得到了另⼀个线程的数据：这是来⾃线程B的数据
可以看到，当⼀个线程调⽤exchange⽅法后，它是处于阻塞状态的，只有当另⼀个线程也调⽤了exchange⽅法，它才会继续向下执⾏。看源码可以发现它是使⽤park/unpark来实现等待状态的切换的，但是在使⽤park/unpark⽅法之前，使⽤了CAS检查，估计是为了提⾼性能。
Exchanger⼀般⽤于两个线程之间更⽅便地在内存中交换数据，因为其⽀持泛型，所以我们可以传输任何的数据，⽐如IO流或者IO缓存。根据JDK⾥⾯的注释的说法，可以总结为⼀下特性：
此类提供对外的操作是同步的；
⽤于成对出现的线程之间交换数据；
可以视作双向的同步队列；
可应⽤于基因算法、流⽔线设计等场景。

# JAVA 阻塞队列原理

阻塞队列，关键字是阻塞，先理解阻塞的含义，在阻塞队列中，线程阻塞有这样的两种情况：

1. 当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列。

2. 当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒。

阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。
这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元
素的线程会等待队列可用。
阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿
元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。
JDK7提供了7个阻塞队列。分别是：

ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。
LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。
PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。
DelayQueue：一个使用优先级队列实现的无界阻塞队列。
SynchronousQueue：一个不存储元素的阻塞队列。
LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。

![image-20210805094855026](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210805094855026.png)

BlockingQueue接口是Queue的子接口，它的主要用途并不是作为容器，而是作为线程同步的的工
具，因此他具有一个很明显的特性，当生产者线程试图向BlockingQueue放入元素时，如果队列已
满，则线程被阻塞，当消费者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞，
正是因为它所具有这个特性，所以在程序中多个线程交替向BlockingQueue中放入元素，取出元
素，它可以很好的控制线程之间的通信。
阻塞队列使用最经典的场景就是socket客户端数据的读取和解析，读取数据的线程不断将数据放入
队列，然后解析线程不断从队列取数据解析。

---

阻塞队列和生产者-消费者模式
**阻塞队列（Blocking queue）提供了可阻塞的put和take方法**，它们与可定时的offer和poll是等价的。如果Queue已经满了，put方法会被阻塞直到有空间可用；如果Queue是空的，那么take方法会被阻塞，直到有元素可用。Queue的长度可以有限，也可以无限；**无限的Queue永远不会充满，所以它的put方法永远不会阻塞。**

阻塞队列支持生产者-消费者设计模式。一个生产者-消费者设计分离了“生产产品”和“消费产品”。该模式不会发现一个工作便立即处理，而是把工作置于一个任务（“to do”）清单中，以备后期处理。生产者-消费者模式简化了开发，因为它解除了生产者和消费者之间相互依赖的代码。生产者和消费者以不同的或者变化的速度生产和消费数据，生产者-消费者模式将这些活动解耦，因而简化了工作负荷的管理。

生产者-消费者设计是围绕阻塞队列展开的，生产者把数据放入队列，并使数据可用，当消费者为适当的行为做准备时会从队列中获取数据。生产者不需要知道消费者的省份或者数量，甚至根本没有消费者—它们只负责把数据放入队列。类似地，消费者也不需要知道生产者是谁，以及是谁给它们安排的工作。BlockingQueue可以使用任意数量的生产者和消费者，从而简化了生产者-消费者设计的实现。最常见的生产者-消费者设计是将线程池与工作队列相结合。

阻塞队列简化了消费者的编码，因为take会保持阻塞直到可用数据出现。如果生产者不能足够快地产生工作，让消费者忙碌起来，那么消费者只能一直等待，直到有工作可做。同时，put方法的阻塞特性也大大地简化了生产者的编码；如果使用一个有界队列，那么当队列充满的时候，生产者就会阻塞，暂不能生成更多的工作，从而给消费者时间来赶进进度。

有界队列是强大的资源管理工具，用来建立可靠的应用程序：它们遏制那些可以产生过多工作量、具有威胁的活动，从而让你的程序在面对超负荷工作时更加健壮。

虽然生产者-消费者模式可以把生产者和消费者的代码相互解耦合，但是它们的行为还是间接地通过共享队列耦合在一起了

类库中包含一些BlockingQueue的实现，其中LinkedBlockingQueue和ArrayBlockingQueue是FIFO队列，与 LinkedList和ArrayList相似，但是却拥有比同步List更好的并发性能。PriorityBlockingQueue是一个按优先级顺序排序的队列，当你不希望按照FIFO的属性处理元素时，这个PriorityBolckingQueue是非常有用的。正如其他排序的容器一样，PriorityBlockingQueue可以比较元素本身的自然顺序（如果它们实现了Comparable），也可以使用一个 Comparator进行排序。

最后一个BlockingQueue的实现是SynchronousQueue，它根本上不是一个真正的队列，因为它不会为队列元素维护任何存储空间。不过，它维护一个排队的线程清单，这些线程等待把元素加入（enqueue）队列或者移出（dequeue）队列。因为SynchronousQueue没有存储能力，所以除非另一个线程已经准备好参与移交工作，否则put和take会一直阻止。SynchronousQueue这类队列只有在消费者充足的时候比较合适，它们总能为下一个任务作好准备。

SynchronousQueue 也是一个队列来的，**但它的特别之处在于它内部没有容器**，一个生产线程，当它生产产品（即put的时候），如果当前没有人想要消费产品(即当前没有线程执行take)，此生产线程必须阻塞，等待一个消费线程调用take操作，take操作将会唤醒该生产线程，同时消费线程会获取生产线程的产品（即数据传递）

同步队列：传输数据，如果生产者生产的元素入队，没有队列在消费则阻塞。如果有消费者尝试消费元素，如果不存在生产者生产则阻塞。


```java
public ArrayBlockingQueue(int capacity, boolean fair) {
    if (capacity <= 0)
        throw new IllegalArgumentException();
    this.items = new Object[capacity];
    lock = new ReentrantLock(fair);
    notEmpty = lock.newCondition();
    notFull =  lock.newCondition();
}
 public void put(E e) throws InterruptedException {
        checkNotNull(e);
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            while (count == items.length)
                notFull.await();
            enqueue(e);
        } finally {
            lock.unlock();
        }
    }

    public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            while (count == 0)
                notEmpty.await();
            return dequeue();
        } finally {
            lock.unlock();
        }
    }
 private E dequeue() {
        // assert lock.getHoldCount() == 1;
        // assert items[takeIndex] != null;
        final Object[] items = this.items;
        @SuppressWarnings("unchecked")
        E x = (E) items[takeIndex];
        items[takeIndex] = null;
        if (++takeIndex == items.length)
            takeIndex = 0;
        count--;
        if (itrs != null)
            itrs.elementDequeued();
        notFull.signal();
        return x;
    }
```



# 为什么是先添加到队列中而不是先创建最大线程？

先是阻塞队列的作用：

1.一般的队列只能作为一个有限长度的缓冲区，如果超出了缓冲区，就无法保留当前的任务了，但阻塞队列可以通过阻塞的方式保留住当前想要继续入队的任务。

2.阻塞队列可以保证任务队列中没有任务时阻塞获取任务的线程，使得线程进入wait状态，释放cpu资源。

3.阻塞队列自带阻塞和唤醒的功能，不需要额外处理，无任务执行时，线程池利用阻塞队列的take方法挂起，从而维持核心线程数的存活，不至于一直占用cpu资源

阻塞队列与普通队列的区别在于，当队列是空的时，从队列中获取元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。试图从空的阻塞队列中获取元素的线程将会被阻塞，直到其他的线程往空的队列插入新的元素。同样，试图往已满的阻塞队列中添加新元素的线程同样也会被阻塞，直到其他的线程使队列重新变得空闲起来，如从队列中移除一个或者多个元素，或者完全清空队列.

然后回答上面的问题：

在创建新线程的时候是需要获取全局锁的，这个时候其他的就得阻塞，影响了整体效率，先添加到队列中，如果有核心线程数中的线程已经完成了任务就可以从队列中拿，如果先是直接创建最大线程则会频繁创建和销毁线程，资源消耗率增大

# 线程池中线程复用原理

在 Java 中，所谓的线程池中的“线程”，其实是被抽象为了一个静态内部类 Worker，它基于 AQS 实现，存放在线程池的 HashSet\<Worker> workers 成员变量中；

而需要执行的任务则存放在成员变量 workQueue（BlockingQueue\<Runnable> workQueue）中。 这样，整个线程池实现的基本思想就是：**从 workQueue 中不断取出需要执行的任务，放在 Workers 中进行处理**。

线程池将线程和任务进行解耦，线程是线程，任务是任务，摆脱了之前通过thread创建线程时的一个线程必须对应一个任务的限制。在一个线程池中，同一个线程可以从阻塞队列中不断获取新任务来执行，其核心原理在于线程池对thread进行了封装，并不是每次执行任务都会调用thread.start()方法来创建新线程，而是让每个线程去执行一个“循环任务”（个人理解应该是从阻塞队列中不断取出新任务)，在这个循环任务中不停检查是否有任务需要被执行，如果有则直接执行，也就是调用任务中的run方法，将run方法当成一个普通方法执行，通过这种方式只使用固定的线程就将所有任务的run方法串联起来。（方法run()称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运行run 函数当中的代码。）

，ThreadPoolExecutor在创建线程时，**会将线程封装成⼯作线程worker,并放⼊⼯作线程组中，然后这个worker反复从阻塞队列中拿任务去执⾏**。话不多说，我们继续看看源码(源码中有一个wile循环会不断从阻塞队列中取任务)
这⾥的 addWorker ⽅法是在上⾯提到的 execute ⽅法⾥⾯调⽤的，先看看上半部分：

源码：

```java
// Worker类部分源码
private final class Worker extends AbstractQueuedSynchronizer implements Runnab
final Thread thread;
Runnable firstTask;
Worker(Runnable firstTask) {
setState(-1); // inhibit interrupts until runWorker
this.firstTask = firstTask;
this.thread = getThreadFactory().newThread(this);
}
public void run() {
runWorker(this);
}
//其余代码略...
}
```

Worker 类实现了 Runnable 接⼝，所以 Worker 也是⼀个线程任务。在构造⽅法中，创建了⼀个线程，线程的任务就是⾃⼰。故 addWorker ⽅法调⽤addWorker⽅法源码下半部分中的第4步 t.start ，会触发 Worker 类的 run ⽅法被JVM调⽤。

```java
// Worker.runWorker⽅法源代码
final void runWorker(Worker w) {
Thread wt = Thread.currentThread();
Runnable task = w.firstTask;
w.firstTask = null;
// 1.线程启动之后，通过unlock⽅法释放锁
w.unlock(); // allow interrupts
boolean completedAbruptly = true;
try {
// 2.Worker执⾏firstTask或从workQueue中获取任务，如果getTask⽅法不返回null,循
while (task != null || (task = getTask()) != null) {
// 2.1进⾏加锁操作，保证thread不被其他线程中断（除⾮线程池被中断）
w.lock();

// 2.2检查线程池状态，倘若线程池处于中断状态，当前线程将中断。
if ((runStateAtLeast(ctl.get(), STOP) ||
(Thread.interrupted() &&
runStateAtLeast(ctl.get(), STOP))) &&
!wt.isInterrupted())
wt.interrupt();
try {
// 2.3执⾏beforeExecute
beforeExecute(wt, task);
Throwable thrown = null;
try {
// 2.4执⾏任务
task.run();
} catch (RuntimeException x) {
thrown = x; throw x;
} catch (Error x) {
thrown = x; throw x;
} catch (Throwable x) {
thrown = x; throw new Error(x);
} finally {
// 2.5执⾏afterExecute⽅法
afterExecute(task, thrown);
}
} finally {
task = null;
w.completedTasks++;
// 2.6解锁操作
w.unlock();
}
}
completedAbruptly = false;
} finally {
processWorkerExit(w, completedAbruptly);
}
}
```

⾸先去执⾏创建这个worker时就有的任务，当执⾏完这个任务后，worker的⽣命周期并没有结束，**在 while 循环中，worker会不断地调⽤ getTask ⽅法从阻塞队列中获取任务然后调⽤ task.run() 执⾏任务,从⽽达到复⽤线程的⽬的**。只要 getTask ⽅法不返回 null ,此线程就不会退出。
当然，核⼼线程池中创建的线程想要拿到阻塞队列中的任务，先要判断线程池的状态，如果STOP或者TERMINATED，返回 null 。

```java
// Worker.getTask⽅法源码
private Runnable getTask() {
boolean timedOut = false; // Did the last poll() time out?
for (;;) {
int c = ctl.get();
int rs = runStateOf(c);
// Check if queue empty only if necessary.
if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {
decrementWorkerCount();
return null;
}
int wc = workerCountOf(c);
// Are workers subject to culling?
// 1.allowCoreThreadTimeOut变量默认是false,核⼼线程即使空闲也不会被销毁
// 如果为true,核⼼线程在keepAliveTime内仍空闲则会被销毁。
boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;
// 2.如果运⾏线程数超过了最⼤线程数，但是缓存队列已经空了，这时递减worker数量。
// 如果有设置允许线程超时或者线程数量超过了核⼼线程数量，
// 并且线程在规定时间内均未poll到任务且队列为空则递减worker数量
if ((wc > maximumPoolSize || (timed && timedOut))
&& (wc > 1 || workQueue.isEmpty())) {
if (compareAndDecrementWorkerCount(c))
return null;
continue;
}
try {
// 3.如果timed为true(想想哪些情况下timed为true),则会调⽤workQueue的poll⽅
// 超时时间是keepAliveTime。如果超过keepAliveTime时⻓，
// poll返回了null，上边提到的while循序就会退出，线程也就执⾏完了。
// 如果timed为false（allowCoreThreadTimeOut为falsefalse
// 且wc > corePoolSize为false），则会调⽤workQueue的take⽅法阻塞在当前。
// 队列中有任务加⼊时，线程被唤醒，take⽅法返回任务，并执⾏。
Runnable r = timed ?
workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
workQueue.take();
if (r != null)
return r;
timedOut = true;
} catch (InterruptedException retry) {
timedOut = false;
}
}
}
```

核⼼线程的会⼀直卡在 workQueue.take ⽅法，被阻塞并挂起，不会占⽤CPU资源，直到拿到 Runnable 然后返回（当然如果allowCoreThreadTimeOut设置为 true ,那么核⼼线程就会去调⽤ poll ⽅法，因为 poll 可能会返回 null ,所以这时候核⼼线程满⾜超时条件也会被销毁）。
⾮核⼼线程会workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) ，如果超时还没有拿到，下⼀次循环判断compareAndDecrementWorkerCount就会返回 null ,Worker对象的 run() ⽅法循环体的判断为 null ,任务结束，然后线程被系统回收 。

## 线程池中的线程是怎么创建的？是一开始就随着线程池的启动创建好的吗？

显然不是的。线程池默认初始化后不启动 Worker，等待有请求时才启动。

每当我们调用 execute() 方法添加一个任务时，线程池会做如下判断： 

 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； 

 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； 

 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； 

 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize那么执行拒绝策略。

## 1. FixedThreadPool 

FixedThreadPool 是固定大小的线程池，只有核心线程。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变

```java
// 创建ExecutorService，指定核心线程数
public static ExecutorService newFixedThreadPool(int nThreads) {
  return new ThreadPoolExecutor(nThreads, nThreads,
              0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<Runnable>());
}

// 创建ExecutorService，指定核心线程数和ThreadFactory
public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {
  return new ThreadPoolExecutor(nThreads, nThreads,
              0L, TimeUnit.MILLISECONDS,
              new LinkedBlockingQueue<Runnable>(),
              threadFactory);
} 


```

关闭线程的 shutdownAndAwaitTermination方法：

```java
void shutdownAndAwaitTermination(ExecutorService executor,long timeout, TimeUnit unit)
{
    // 首先执行executor的立即关闭方法
    executor.shutdown();
    try
    {
        // 如果在指定时间内线程池仍旧未被关闭
        if (!executor.awaitTermination(timeout, unit))
        {
            // 则执行立即关闭方法，排干任务队列中的任务
            executor.shutdownNow();
         // 如果线程池中的工作线程正在执行一个非常耗时且不可中断的方法，则中断失败
            if (!executor.awaitTermination(timeout, unit))
            {
                // print executor not terminated by normal.
            }
        }
    } catch (InterruptedException e)
    {}
 

```

例子：

![image-20220105162557696](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220105162557696.png)

##  2.singleThreadPool();



被垃圾回收器回收时，线程池的shutdown方法会被执行，当然我们还是建议显式地调用线程池的关闭方法。 

```java
public static void main(String[] args)
    throws InterruptedException
{
  // 创建SingleThreadPool并执行任务
  singleThreadPool();
  // 输出当前JVM的线程堆栈信息
  printThreadStack();
  // 简单分割
  System.out.println("*************************************");
  // 显式调用GC，但是并不会立即作用（详见笔者第一本书中的ActiveObject）
  System.gc();
  TimeUnit.MINUTES.sleep(1);
  // 再次输出当前JVM的线程堆栈信息
  printThreadStack();
}
// 输出JVM线程堆栈信息
private static void printThreadStack()
{
  ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();
  long[] ids = threadMXBean.getAllThreadIds();
  for (long id : ids)
  {
    System.out.println(threadMXBean.getThreadInfo(id));
  }
}

private static void singleThreadPool()
{
  ExecutorService executor = Executors.newSingleThreadExecutor();
  // 提交执行异步任务
  executor.execute(() -> System.out.println("normal task."));
} //运行上面的程序，会看到当GC发生时，线程池的shutdown方法成功执行。 
    
```

## 3. CachedThreadPool

CachedThreadPool 是无界线程池，如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60 秒不执行任务）线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。 线程池大小完全依赖于操作系统（或者说 JVM）能够创建的最大线程大小。SynchronousQueue 是一个是缓冲区为 1 的阻塞队列。

```java
3. CachedThreadPool // 创建Cached线程池
public static ExecutorService newCachedThreadPool() {
  return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
               60L, TimeUnit.SECONDS,
               new SynchronousQueue<Runnable>());
}
// 创建Cached线程池并指定ThreadFactory
public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {
  return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
              60L, TimeUnit.SECONDS,
              new SynchronousQueue<Runnable>(),
              threadFactory);
} 
```

1).工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE),这样可灵活的往线程池中添加线程。
2).如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。



CachedThreadPool根据需要创建新线程，但会重用以前构造的可用线程。该线程池通常会用于提高执行量大的、耗时较短的、异步任务程序的运行性能，在该线程池中，如果有可用的线程将被直接重用。如果没有可用的线程，则会创建一个新线程并将其添加到池中。**未被使用且空闲时间超过60秒的线程将被终止并从线程池中移除，因此长时间空闲的线程不会消耗任何资源。** 

4. ScheduledThreadPool // 构造指定核心线程数的ScheduledThreadPoolExecutor
   public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
    return new ScheduledThreadPoolExecutor(corePoolSize);
   }

// 指定核心线程数和ThreadFactory





就绪状态（RUNNABLE）： 当线程对象调用了start()方法之后，该线程处于就绪状态。Java虚拟机会为其创建方法调用栈和程序计数器，等待调度运行。



线程会以下面三种方式结束，结束后就是死亡状态。 

正常结束 

1. run()或call()方法执行完成，线程正常结束。 异常结束 

2. 线程抛出一个未捕获的Exception或Error。

3. 调用stop 

   直接调用该线程的stop()方法来结束该线程—该方法通常容易导致死锁，不推荐使用。



## **CompletionService简介**

CompletionService与ExecutorService类似都可以用来执行线程池的任务，ExecutorService继承了Executor接口，而CompletionService则是一个接口，那么为什么CompletionService不直接继承Executor接口呢？主要是Executor的特性决定的，Executor框架不能完全保证任务执行的异步性，那就是如果需要实现任务（task）的异步性，只要为每个task创建一个线程就实现了任务的异步性。代码往往包含`new Thread(task).start()`。这种方式的问题在于，它没有限制可创建线程的数量（在ExecutorService可以限制），不过，这样最大的问题是在高并发的情况下，不断创建线程异步执行任务将会极大**增大线程创建的开销**、**造成极大的资源消耗**和**影响系统的稳定性**。另外，Executor框架还支持同步任务的执行，就是在execute方法中调用提交任务的run()方法就属于同步调用。

一般情况下，如果需要判断任务是否完成，思路是得到Future列表的每个Future，然后反复调用其get方法，并将timeout参数设为0，从而通过轮询的方式判断任务是否完成。为了更精确实现任务的异步执行以及更简便的完成任务的异步执行，可以使用CompletionService。

**CompletionService实现原理**

CompletionService实际上可以看做是Executor和BlockingQueue的结合体。CompletionService在接收到要执行的任务时，通过类似BlockingQueue的put和take获得任务执行的结果。CompletionService的一个实现是ExecutorCompletionService，ExecutorCompletionService把具体的计算任务交给Executor完成。

在实现上，ExecutorCompletionService在构造函数中会创建一个BlockingQueue（使用的基于链表的无界队列LinkedBlockingQueue），该BlockingQueue的作用是保存Executor执行的结果。当计算完成时，调用FutureTask的done方法。当提交一个任务到ExecutorCompletionService时，首先将任务包装成QueueingFuture，它是FutureTask的一个子类，然后改写FutureTask的done方法，之后把Executor执行的计算结果放入BlockingQueue中。QueueingFuture的源码如下：

```java
   private class QueueingFuture extends FutureTask<Void> {
       QueueingFuture(RunnableFuture<V> task) {
           super(task, null);
           this.task = task;
       }

       protected void done() {
           completionQueue.add(task);
       }
       private final Future<V> task;
   }
```

从代码可以看到，CompletionService将提交的任务转化为QueueingFuture，并且覆盖了done方法，在done方法中就是将任务加入任务队列中。这点与之前对Executor框架的分析是一致的。



## 线程池中队列常用类型

ArrayBlockingQueue 是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则
对元素进行排序。
LinkedBlockingQueue 一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元
素，吞吐量通常要高于ArrayBlockingQueue 。
SynchronousQueue 一个不存储元素的阻塞队列。
PriorityBlockingQueue 一个具有优先级的无限阻塞队列。PriorityBlockingQueue 也是基于
最小二叉堆实现
DelayQueue 只有当其指定的延迟时间到了，才能够从队列中获取到该元素。
DelayQueue 是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞





## 核心线程数怎么设置

并发不高、任务执行时间长的业务怎样使用线程池？并发高、业务执行时间长的业务怎样使用线程池？

1、高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换
2、并发不高、任务执行时间长的业务要区分开看：
假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以加大线程池中的线程数目，让CPU处理更多的业务.假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换
3、并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，看看这些业务里面某些数据是否能做缓存是第一步，增加服务器是第二步，至于线程池的设置，设置参考（2）。
最后，业务执行时间长的问题，也可能需要分析一下，看看能不能使用中间件对任务进行拆分和解耦。

分为CPU密集型和IO密集型
CPU
这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1，比 CPU 核心数多出
来的一个线程是为了**防止线程偶发的缺页中断**，或者其它原因导致的任务暂停而带来的影响。一旦
任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空
闲时间。
IO密集型
这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占
用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们
可以多配置一些线程，具体的计算方法是 ： 核心线程数=CPU核心数量*2。



## 在Java中Executor、ExecutorService、Executors的区别？

Executor 和 ExecutorService 这两个接口主要的区别是：
ExecutorService 接口继承了 Executor 接口，是 Executor 的子接口
Executor 和 ExecutorService 第二个区别是：Executor 接口定义了 execute()方法用来接收一个Runnable接口的对象，而 ExecutorService 接口中的 submit()方法可以接受Runnable和Callable接口的对象。
Executor 和 ExecutorService 接口第三个区别是 Executor 中的 execute() 方法不返回任何结果，而 ExecutorService 中的 submit()方法可以通过一个 Future 对象返回运算结果。
Executor 和 ExecutorService 接口第四个区别是除了允许客户端提交一个任务，ExecutorService还提供用来控制线程池的方法。比如：调用 shutDown() 方法终止线程池。
Executors 类提供工厂方法用来创建不同类型的线程池。
比如: newSingleThreadExecutor() 创建一个只有一个线程的线程池，newFixedThreadPool(int  numOfThreads)来创建固定线程数的线程池，newCachedThreadPool()可以根据需要创建新的线程，但如果已有线程是空闲的会重用已有线程。

## 线程池的源码

```java
private boolean addWorker(Runnable firstTask, boolean core) {
    //检查是否可以根据当前池状态和给定边界（核心或最大值）添加新工作人员。 如果是这样，则相应地调整工作人员计数，并且如果可能，创建并启动一个新工作人员，将 firstTask 作为其第一个任务运行。 如果池已停止或有资格关闭，则此方法返回 false。 如果线程工厂在询问时未能创建线程，它也会返回 false。 如果线程创建失败，要么是由于线程工厂返回 null，要么是由于异常（通常是 Thread.start() 中的 OutOfMemoryError），我们干净地回滚。
//private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0))
    retry:
    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c);

        // Check if queue empty only if necessary.
        if (rs >= SHUTDOWN &&
            ! (rs == SHUTDOWN &&
               firstTask == null &&
               ! workQueue.isEmpty()))
            return false;

        for (;;) {
            int wc = workerCountOf(c);
            if (wc >= CAPACITY ||
                wc >= (core ? corePoolSize : maximumPoolSize))
                return false;
            //    private boolean compareAndIncrementWorkerCount(int expect) {
      //  return ctl.compareAndSet(expect, expect + 1);
   / }
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            if (runStateOf(c) != rs)
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }

    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        w = new Worker(firstTask);
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get());

                if (rs < SHUTDOWN ||
                    (rs == SHUTDOWN && firstTask == null)) {
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    workers.add(w);
                    int s = workers.size();
                    if (s > largestPoolSize)
                        largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
            addWorkerFailed(w);
    }
    return workerStarted;
}
```

ThreadPoolExecutor 类中定义了⼀个 volatile int 变量runState来表示线程池的状态 ，分别为RUNNING、SHURDOWN、STOP、TIDYING 、TERMINATED。
线程池创建后处于RUNNING状态。
调⽤shutdown()⽅法后处于SHUTDOWN状态，线程池不能接受新的任务，清除⼀些空闲worker,会等待阻塞队列的任务完成。
调⽤shutdownNow()⽅法后处于STOP状态，线程池不能接受新的任务，中断所有线程，阻塞队列中没有被执⾏的任务全部丢弃。此时，poolsize=0,阻塞队列的size也为0。
当所有的任务已终⽌，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。
接着会执⾏terminated()函数。
ThreadPoolExecutor中有⼀个控制状态的属性叫ctl，它是⼀个
AtomicInteger类型的变量。线程池处在TIDYING状态时，执⾏完terminated()⽅法之后，就会由 TIDYING-> TERMINATED， 线程池被设置为TERMINATED状态。

excute方法：

```java
// JDK 1.8
public void execute(Runnable command) {
if (command == null)
throw new NullPointerException();
int c = ctl.get();
// 1.当前线程数⼩于corePoolSize,则调⽤addWorker创建核⼼线程执⾏任务
if (workerCountOf(c) < corePoolSize) {
if (addWorker(command, true))
return;
c = ctl.get();
}
// 2.如果不⼩于corePoolSize，则将任务添加到workQueue队列。
if (isRunning(c) && workQueue.offer(command)) {
int recheck = ctl.get();
// 2.1 如果isRunning返回false(状态检查)，则remove这个任务，然后执⾏拒绝策略。
if (! isRunning(recheck) && remove(command))
reject(command);
// 2.2 线程池处于running状态，但是没有线程，则创建线程
else if (workerCountOf(recheck) == 0)
addWorker(null, false);
}
// 3.如果放⼊workQueue失败，则创建⾮核⼼线程执⾏任务，
// 如果这时创建⾮核⼼线程失败(当前线程总数不⼩于maximumPoolSize时)，就会执⾏拒绝策略。
else if (!addWorker(command, false))
reject(command);
}
```

ctl.get() 是获取线程池状态，⽤ int 类型表示。第⼆步中，⼊队前进⾏了⼀
次 isRunning 判断，⼊队之后，⼜进⾏了⼀次 isRunning 判断。
为什么要⼆次检查线程池的状态?
在多线程的环境下，线程池的状态是时刻发⽣变化的。很有可能刚获取线程池状态后线程池状态就改变了。判断是否将 command 加⼊ workqueue 是线程池之前的状态。倘若没有⼆次检查，万⼀线程池处于⾮RUNNING状态（在多线程环境下很有可能发⽣），那么 command 永远不会执⾏。
总结⼀下处理流程

1. 线程总数量 < corePoolSize，⽆论线程是否空闲，都会新建⼀个核⼼线程执⾏任务（让核⼼线程数量快速达到corePoolSize，在核⼼线程数量 <corePoolSize时）。注意，这⼀步需要获得全局锁。
2. 线程总数量 >= corePoolSize时，新来的线程任务会进⼊任务队列中等待，然后空闲的核⼼线程会依次去缓存队列中取任务来执⾏（体现了线程复⽤）。
3. 当缓存队列满了，说明这个时候任务已经多到爆棚，需要⼀些“临时⼯”来执⾏这些任务了。于是会创建⾮核⼼线程去执⾏这个任务。注意，这⼀步需要获得全局锁。
4. 缓存队列满了， 且总线程数达到了maximumPoolSize，则会采取上⾯提到的拒绝策略进⾏处理。



# guava框架使用

总体来说，Guava的主要手段是增强而不是另起炉灶。为了实现非阻塞获取异步线程的结果，Guava对Java的异步回调机制，做了以下的增强： 

（1）引入了一个新的接口ListenableFuture，继承了Java的Future接口，使得Java的Future异步任务，在Guava中能被监控和获得非阻塞异步执行的结果。 

（2）引入了一个新的接口FutureCallback，这是一个独立的新接口。该接口的目的，是在异步任务执行完成后，根据异步结果，完成不同的回调处理，并且可以处理异步结果。现在的问题来了，既然Guava的ListenableFuture接口是对Java的Future接口的扩展，都表示异步任务。那么Guava的异步任务实例，从何而来呢？ 

ListenableFuture异步任务

 如果要获取Guava的ListenableFuture异步任务实例，主要是通过向线程池（ThreadPool）提交Callable任务的方式来获取。不过，这里所说的线程池，不是Java的线程池，而是Guava自己定制的Guava线程池。 Guava线程池，是对Java线程池的一种装饰。创建Guava线程池的方法如下： 

```java
ExecutorServicejPool=  Executors.newFixedThreadPool(10);
 //Guava线程池
ListeningExecutorServicegPool=  MoreExecutors.listeningDecorator(jPool);
  //首先创建Java线程池，然后以它作为Guava线程池的参数，再构造一个Guava线程池。有了Guava的线程池之后，就可以通过submit方法来提交任务了；任务提交之后的返回结果，就是我们所要的ListenableFuture异步任务实例了。 简单地说，获取异步任务实例的方式，是通过向线程池提交Callable业务逻辑来实现。代码如下：  
//调用submit方法来提交任务，返回异步任务实例
ListenableFuture<Boolean>hFuture = gPool.submit(hJob);
//绑定回调实例
Futures.addCallback(listenableFuture,  newFutureCallback<Boolean>()
{
     //实现回调方法，有两个
});
  

```

获取了ListenableFuture实例之后，通过Futures.addCallback方法，将FutureCallback回调逻辑的实例绑定到ListenableFuture异步任务实例，实现异步执行完成后的回调。 总结一下，Guava异步回调的流程如下： 

第1步：实现Java的Callable接口，创建异步执行逻辑。还有一种情况，如果不需要返回值，异步执行逻辑也可以实现Java的Runnable接口。

 第2步：创建Guava线程池。 

第3步：将第1步创建的Callable/Runnable异步执行逻辑的实例，通过submit提交到Guava线程池，从而获取ListenableFuture异步任务实例。 

第4步：创建FutureCallback回调实例，通过Futures.addCallback将回调实例绑定到ListenableFuture异步任务上。 完成以上四步，当Callable/Runnable异步执行逻辑完成后，就会回调异步回调实例FutureCallback的回调方法onSuccess/onFailure。 

案例：

使用Guava实现泡茶喝的实践案例 前面已经完成了join版本、FutureTask版本的泡茶喝实践案例。大家对此实例的业务功能，应该已经非常熟悉了，这里不再赘述。下面是Guava的异步回调的演进版本，代码如下： 

```java
package com.crazymakercircle.coccurent;
//….
public class GuavaFutureDemo {
 public class GuavaFutureDemo {
    private static final Logger logger = Logger.getLogger("GuavaFuture");
    public static final int SLEEP_GAP = 500;

    public static String getCurThreadName() {
        return Thread.currentThread().getName();
    }

    //业务逻辑：烧水
    static class HotWarterJob implements Callable<Boolean> {
        @Override
        public Boolean call() throws Exception {
            try {
                System.out.println("洗好水壶");
                System.out.println("灌上凉水");
                System.out.println("放在火上");
                //线程睡眠一段时间，代表烧水中
                Thread.sleep(SLEEP_GAP);
                System.out.println("水开了");
            } catch (InterruptedException e) {
                System.out.println(" 发生异常被中断.");
                return false;
            }
            System.out.println(" 运行结束.");
            return true;

        }

        //业务逻辑：清洗
        static class WashJob implements Callable<Boolean> {
            @Override
            public Boolean call() throws Exception {
                try {
                    System.out.println("洗茶壶");
                    System.out.println("洗茶杯");
                    System.out.println("拿茶叶");
                    //线程睡眠一段时间，代表清洗中
                    Thread.sleep(SLEEP_GAP);
                    System.out.println("洗完了");
                } catch (InterruptedException e) {
                    System.out.println(" 清洗工作发生异常被中断.");
                    return false;

                }
                return true;
            }

            //新创建一个异步业务类型，作为泡茶喝主线程类
            static class MainJob implements Runnable {
                boolean warterOk = false;
                boolean cupOk = false;
                int gap = SLEEP_GAP / 10;

                @Override
                public void run() {
                    while (true) {
                        try {
                            Thread.sleep(gap);
                            System.out.println("读书中......");
                        } catch (InterruptedException e) {
                            System.out.println(getCurThreadName() + "发生异常被中断.");
                        }
                        if (warterOk && cupOk) {
                            drinkTea(warterOk, cupOk);
                        }
                    }
                }

                public void drinkTea(Boolean wOk, Boolean cOK) {
                    if (wOk && cOK) {
                        System.out.println("泡茶喝，茶喝完");
                        this.warterOk = false;
                        this.gap = SLEEP_GAP * 100;
                    } else if (!wOk) {
                        System.out.println("烧水失败，没有茶喝了");
                    } else if (!cOK) {
                        System.out.println("杯子洗不了，没有茶喝了");
                    }
                }
            }

            public static void main(String args[]) {
                //创建一个新的线程实例，作为泡茶主线程
                MainJob mainJob = new MainJob();
                Thread mainThread = new Thread(mainJob);
                mainThread.setName("主线程");
                mainThread.start();
                //烧水的业务逻辑实例
                Callable<Boolean> hotJob = new HotWarterJob();
                //清洗的业务逻辑实例
                Callable<Boolean> washJob = new WashJob();
                //创建Java 线程池
                ExecutorService jPool = Executors.newFixedThreadPool(10);
                //包装Java线程池，构造Guava 线程池
                ListeningExecutorService gPool = MoreExecutors.listeningDecorator(jPool);
                //提交烧水的业务逻辑实例，到Guava线程池获取异步任务
                ListenableFuture<Boolean> hotFuture = gPool.submit(hotJob);
                //绑定异步回调，烧水完成后，把喝水任务的warterOk标志设置为true
                Futures.addCallback(hotFuture, new FutureCallback<Boolean>() {
                    public void onSuccess(Boolean r) {
                        if (r) {
                            mainJob.warterOk = true;
                        }
                    }

                    public void onFailure(Throwable t) {
                        logger.info("烧水失败，没有茶喝了");
                    }
                };
                //提交清洗的业务逻辑实例，到Guava线程池获取异步任务
                ListenableFuture<Boolean> washFuture = gPool.submit(washJob);
                //绑定任务执行完成后的回调逻辑到异步任务
                Futures.addCallback(washFuture, new FutureCallback<Boolean>() {

                    public void onSuccess(Boolean r) {
                        if (r) {
                            mainJob.cupOk = true;
                        }
                    }

                    public void onFailure(Throwable t) {
                        logger.info("杯子洗不了，没有茶喝了");
                    }
                });
            }


   
}
}
```




 Guava异步回调和Java的FutureTask异步回调，本质的不同在于： ·**Guava是非阻塞的异步回调，调用线程是不阻塞的，可以继续执行自己的业务逻辑**。 ·FutureTask是阻塞的异步回调，调用线程是阻塞的，在获取异步结果的过程中，一直阻塞，等待异步线程返回结果。 

FutureTask执行多任务计算

利用FutureTask和ExecutorService，能够用多线程的方式提交计算任务，主线程继续执行其余任务，当主线程须要子线程的计算结果时，在异步获取子线程的执行结果

```java
public class FutureTaskForMultiCompute {

    public staticvoid main(String[] args) {

        FutureTaskForMultiCompute inst = new FutureTaskForMultiCompute();
        // 建立任务集合
        List<FutureTask<Integer>> taskList = new ArrayList<FutureTask<Integer>>();
        // 建立线程池
        ExecutorService exec = Executors.newFixedThreadPool(5);
        for (int i = 0; i < 10; i++) {
            // 传入Callable对象建立FutureTask对象
            FutureTask<Integer> ft = new FutureTask<Integer>(inst.new ComputeTask(i, "" + i));
            taskList.add(ft);
            // 提交给线程池执行任务，也能够经过exec.invokeAll(taskList)一次性提交全部任务;
            exec.submit(ft);
        }

        System.out.println("全部计算任务提交完毕, 主线程接着干其余事情！");

        // 开始统计各计算线程计算结果
        Integer totalResult = 0;
        for (FutureTask<Integer> ft : taskList) {
            try {
                //FutureTask的get方法会自动阻塞,直到获取计算结果为止
                totalResult = totalResult + ft.get();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (ExecutionException e) {
                e.printStackTrace();
            }
        }

        // 关闭线程池
        exec.shutdown();
        System.out.println("多任务计算后的总结果是:" + totalResult);

    }

    private class ComputeTask implements Callable<Integer> {

        private Integer result = 0;
        private String taskName = "";

        public ComputeTask(Integer iniResult, String taskName) {
            result = iniResult;
            this.taskName = taskName;
            System.out.println("生成子线程计算任务: " + taskName);
        }

        public String getTaskName() {
            return this.taskName;
        }

        @Override
        public Integer call() throws Exception {
            // TODO Auto-generated method stub

            for (int i = 0; i < 100; i++) {
                result = +i;
            }
            // 休眠5秒钟，观察主线程行为，预期的结果是主线程会继续执行，到要取得FutureTask的结果是等待直至完成。
            Thread.sleep(5000);
            System.out.println("子线程计算任务: " + taskName + " 执行完成!");
            return result;
        }
    }
}
```

2.高并发环境下

FutureTask在高并发环境下确保任务只执行一次并发

在不少高并发的环境下，每每咱们只须要某些任务只执行一次。这种使用情景FutureTask的特性恰能胜任。举一个例子，假设有一个带key的链接池，当key存在时，即直接返回key对应的对象；当key不存在时，则建立链接。对于这样的应用场景，一般采用的方法为使用一个Map对象来存储key和链接池对应的对应关系，典型的代码以下面所示：

```java
private Map<String, Connection> connectionPool = new HashMap<String, Connection>();
    private ReentrantLock lock = new ReentrantLock();

    public Connection getConnection(String key) {
        try {
            lock.lock();
            if (connectionPool.containsKey(key)) {
                return connectionPool.get(key);
            } else {
                //建立 Connection  
                Connection conn = createConnection();
                connectionPool.put(key, conn);
                return conn;
            }
        } finally {
            lock.unlock();
        }
    }

    //建立Connection  
    private Connection createConnection() {
        return null;
    }
```

在上面的例子中，咱们经过加锁确保高并发环境下的线程安全，也确保了connection只建立一次，然而确牺牲了性能。改用ConcurrentHash的状况下，几乎能够避免加锁的操作，性能大大提升，可是在高并发的状况下有可能出现Connection被建立屡次的现象。这时最须要解决的问题就是当key不存在时，建立Connection的动做能放在connectionPool以后执行，这正是FutureTask发挥做用的时机，基于ConcurrentHashMap和FutureTask的改造代码以下：

```java
  private ConcurrentHashMap<String, FutureTask<Connection>> connectionPool = new ConcurrentHashMap<String, FutureTask<Connection>>();

    public Connection getConnection(String key) throws Exception {
        FutureTask<Connection> connectionTask = connectionPool.get(key);
        if (connectionTask != null) {
            return connectionTask.get();
        } else {
            Callable<Connection> callable = new Callable<Connection>() {
                @Override
                public Connection call() throws Exception {
                    // TODO Auto-generated method stub  
                    return createConnection();
                }
            };
            FutureTask<Connection> newTask = new FutureTask<Connection>(callable);
            connectionTask = connectionPool.putIfAbsent(key, newTask);
            if (connectionTask == null) {
                connectionTask = newTask;
                connectionTask.run();
            }
            return connectionTask.get();
        }
    }

    //建立Connection  
    private Connection createConnection() {
        return null;
    }
```



总体来说，Guava的主要手段是增强而不是另起炉灶。为了实现非阻塞获取异步线程的结果，Guava对Java的异步回调机制，做了以下的增强： （1）引入了一个新的接口ListenableFuture，继承了Java的Future接口，使得Java的Future异步任务，在Guava中能被监控和获得非阻塞异步执行的结果。 （2）引入了一个新的接口FutureCallback，这是一个独立的新接口。该接口的目的，是在异步任务执行完成后，根据异步结果，完成不同的回调处理，并且可以处理异步结果。现在的问题来了，既然Guava的ListenableFuture接口是对Java的Future接口的扩展，都表示异步任务。那么Guava的异步任务实例，从何而来呢？ 
5.4.3　ListenableFuture异步任务 如果要获取Guava的ListenableFuture异步任务实例，主要是通过向线程池（ThreadPool）提交Callable任务的方式来获取。不过，这里所说的线程池，不是Java的线程池，而是Guava自己定制的Guava线程池。 Guava线程池，是对Java线程池的一种装饰。









## Runnable 和Callable 的区别

有时，我们需要在主线程中开启多个线程并发执行一个任务，==然后收集各个线程执行返回的结果并将最终结果汇总起来，这时就要用到Callable接口==。具体的实现方法为：创建一个类并实现Callable接口，在call方法中实现具体的运算逻辑并返回计算结果。具体的调用过程为：创建一个线程池、一个用于接收返回结果的Future List及Callable线程实例，使用线程池提交任务并将线程执行之后的结果保存在Future中，在线程执行结束后遍历Future List中的Future对象，在该对象上调用get方法就可以获取Callable线程任务返回的数据并汇总结果





1、Callable 规定（重写）的方法是call()，Runnable 规定（重写）的方法是run()。
2、Callable 的任务执行后可返回值，而Runnable 的任务是不能返回值的。
3、Call 方法可以抛出异常， run 方法不可以。
4、运行Callable 任务可以拿到一个Future 对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行， 还可获取执行结果。

线程池就是提前创建若干个线程，如果有任务需要处理，线程池里的线程就会处理任务， 处理完之后线程并不会被销毁， 而是等待下一个任务。由于创建和销毁线程都是消耗系统资源的，所以当你想要频繁的创建和销毁线程的时候就可以考虑使用线程池来提升系统的性能。



## Future详解



 简单来说，Future代表着一个异步任务在未来的执行结果，这个结果可以在最终的某个时间节点通过Future的get方法来获得，关于Future更多的细节和原理，在笔者的书《Java高并发编程详解：多线程与架构设计》中第19章“Future设计模式”里进行了很详细的阐述，这里不再赘述，有需要的读者可以自行查阅。 

FutureTask可用于异步获取执行结果或取消执行任务的场景。通过传入Runnable或者Callable的任务给FutureTask，直接调用其run方法或者放入线程池执行，之后可以在外部通过FutureTask的get方法异步获取执行结果，因此，FutureTask非常适合用于耗时的计算，主线程可以在完成自己的任务后，再去获取结果。**另外，FutureTask还可以确保即使调用了多次run方法，它都只会执行一次Runnable或者Callable任务**，或者通过cancel取消FutureTask的执行等。



\1. FutureTask执行多任务计算的使用场景 

Callable 最大区别就是返回范型 V 结果。

那么下一个问题就是，如何把子线程的结果回传回来呢？在 Java 里，有一个类是配合 Callable 使用的：FutureTask，不过注意，它获取结果的 get 方法会阻塞主线程。

举例，我们想让子线程去计算从 1 加到 100，并把算出的结果返回到主线程。

```java
private static void doTaskWithResultInWorker() {  
    Callable<Integer> callable = new Callable<Integer>() {  
        @Override  
        public Integer call() throws Exception {  
            System.out.println("Task starts");  
            Thread.sleep(1000);  
            int result = 0;  
            for (int i=0; i<=100; i++) {  
                result += i;  
            }  
            System.out.println("Task finished and return result");  
            return result;  
        }  
    };  
    FutureTask<Integer> futureTask = new FutureTask<>(callable);  
    new Thread(futureTask).start();  
    try {  
        System.out.println("Before futureTask.get()");  
        System.out.println("Result: " + futureTask.get());  
        System.out.println("After futureTask.get()");  
    } catch (InterruptedException e) {  
        e.printStackTrace();  
    } catch (ExecutionException e) {  
        e.printStackTrace();  
    }  
}  


```







**对于长时间运行的任务来说，使其异步执行并立即返回一个Future接口是一种比较不错的选择，因为这样可以允许程序在等待结果的同时继续去执行其他的任务**，比如如下这些任务。■ 密集型计算（数学和科学计算）。 ■ 针对大数据的处理计算。 ■ 通过远程方法调用数据。 下面来看一个简单的例子，快速了解一下Future接口的特点，以及其在异步任务中所带来的便利。

```java
 ExecutorService executor = Executors.newSingleThreadExecutor();
// 提交任务，传入Callable接口，并且立即返回Future
Future<Double> future = executor.submit(() ->
{
  try
  {
    // 模拟任务执行耗时
    TimeUnit.SECONDS.sleep(20);
  } catch (InterruptedException e)
  {
    e.printStackTrace();
  }
  return 53.3d;
});
// 当前线程在等待结果结束的同时还可以做一些其他的事情
System.out.println("main thread do other thing.");
// 获取执行结果
System.out.println("The task result: " + future.get());

executor.shutdown(); Future接口也是在JDK1.5版本中随着并发包一起被引入JDK的，Future接口的定义如下所示（共包含5个接口方法）。 package java.util.concurrent;
public interface Future<V>
{
  /**
  \* 取消任务的执行，如果mayInterruptIfRunning为true，则工作线程将会被中断，
  \* 否则即使执行了cancel方法，也会等待其完成，
  \* 无论mayInterruptIfRunning为true还是false,isCancelled()都会为true,并且执行get 方法会抛异常
  */
  boolean cancel(boolean mayInterruptIfRunning);

  /**
  *判断异步任务是否被取消
  */
  boolean isCancelled();
    /**
    * 判断异步任务的执行是否结束
    */
    boolean isDone();

    /**
    * 获取异步任务的执行结果，如果任务未运行结束，则该方法会使当前线程阻塞
    * 异步任务运行错误，调用get方法会抛出ExecutionException异常
    */
    V get() throws InterruptedException, ExecutionException;

    // 同get方法，但是允许设置最大超时时间
    V get(long timeout, TimeUnit unit)
        throws InterruptedException,
                ExecutionException, TimeoutException;
}  
Future接口中定义的方法，我们在源码注释中已经进行了详细的说明，现在重点说明一下其中的一些接口方法和关键接口callable。 
    ■ 取消异步正在执行的任务：如果一个异步任务的运行特别耗时，那么Future是允许对其进行取消操作 

 // 创建只有一个工作线程的线程池，并指定ThreadFactory
public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                            0L, TimeUnit.MILLISECONDS,
                            new LinkedBlockingQueue<Runnable>(),
                            threadFactory));
}

static class FinalizableDelegatedExecutorService
    extends DelegatedExecutorService {
    FinalizableDelegatedExecutorService(ExecutorService executor) {
        super(executor);
}
    // 重写finalize方法
    protected void finalize() {
        // 当gc发生的时候，线程池会被执行shutdown
        super.shutdown();
    }
 }  SingleThreadPool是只有一个核心线程的线程池，但是Finalizable代理了该线程池，因此当线程池引用可 

```



# 1.ThreadLocal 的作用？

如果想实现每一个线程都有自己的专属本地变量该如何解决呢？jdk提供的threadlocal类正是为了解决这样的问题，它主要是为了每个线程绑定自己的值，如果创建了一个threadlocal变量，则访问这个变量的每个线程都会有这个变量的本地副本，可以用set get方法来获取默认值或将其值改为当前线程所存副本的值

![image-20230213220641912](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20230213220641912.png)

从Java官方文档中的描述：ThreadLocal类用来提供线程内部的局部变量。这种变量在多线程环境下访问（通过get和set方法访问）时能保证各个线程的变量相对独立于其他线程内的变量。ThreadLocal实例通常来说都是private static类型的，用于关联线程和线程上下文。

总结:
1. 线程并发: 在多线程并发的场景下
2. 传递数据: 我们可以通过ThreadLocal在同一线程，不同组件中传递公共变量
3. 线程隔离: 每个线程的变量都是独立的，不会互相影响

使用T和readLocal类既可以保证并发，提高性能，又能满足线程资源的隔离性，即各个线程之间不会发生一个线程改变了另一个线程中变量的内容

## threadlocal源码

查看thread类源码：

```java
public class Thread implements Runnable {
......
//与此线程有关的ThreadLocal值。由ThreadLocal类维护
ThreadLocal.ThreadLocalMap threadLocals = null;
//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护
ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
......
}
```

thread类有一个inheritableThreadLocals和threadLocals变量，我们把ThreadLocalMap理解为ThreadLocal实现的定制化的hashmap，默认两个变量都是null,只有当前线程调用set get方法时才创建它们，实际上我们调用set get方法时，调用的是ThreadLocalMap的get set方法

```java
public void set(T value) {
Thread t = Thread.currentThread();
ThreadLocalMap map = getMap(t);
if (map != null)
map.set(this, value);
else
createMap(t, value);
}
ThreadLocalMap getMap(Thread t) {
return t.threadLocals;
}
```

map:最终的变量是放在了当前线程的threadlocalmap中，并不是存在threadlocal中，threadlocal可以理解为只是threadlocalmap的封装，传递了变量值

```java
ThreadLocalMap(ThreadLocalThreadLocal
<?> firstKey, Object firstValue) {
......
} //key就是ThreadLocal对象，值就是set方法设置的值

```

ThreadLocalMap的key是ThreadLocal的弱引用，而Value是强引用，所以如果ThreadLocal没有被外部强引用的情况下，在垃圾回收时key会被清理掉而value不会，这样ThreadLocalMap就会出现key为null的Entry，如果我们不做任何措施，value永远无法被gc回收，就可能产生内存泄漏

![image-20220204113215014](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220204113215014.png)



## 验证线程变量间的隔离性

```java
public class ThreadLocalExt extends ThreadLocal{
    @Override//这样重写了以后ThreadLocal的第一次get()方法就有了默认值，不会返回null
    protected Object initialValue(){
        return System.currentTimeMillis();
    }
}
```



```java
public class Tools {
    public static ThreadLocalExt ext = new ThreadLocalExt();
}
```

```java
public class ThreadA extends Thread{

    @Override
    public void run(){
     try{
         for (int i = 0; i < 10; i++) {
             System.out.println("在A中取值"+Tools.ext.get());
             Thread.sleep(100);

         }
     }catch (InterruptedException e)
     {
         e.printStackTrace();
     }
    }

}
```



```java
public class Run {
    public static void main(String[] args) {
        try {
            for (int i = 0; i < 10; i++) {
                System.out.println("在main中取值" + Tools.ext.get());
                Thread.sleep(100);
            }
            Thread.sleep(5000);
            ThreadA a = new ThreadA();
            a.start();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```

![image-20211015115043989](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211015115043989.png)

由结果可知父子线程各自有所拥有的值。



使用案例2

 	我们来看下面这个案例	, 感受一下ThreadLocal 线程隔离的特点： 

```java
public class MyDemo {
    private String content;

    private String getContent() {
        return content;
    }

    private void setContent(String content) {
        this.content = content;
    }

    public static void main(String[] args) {
        MyDemo demo = new MyDemo();
        for (int i = 0; i < 5; i++) {
            Thread thread = new Thread(new Runnable() {
                @Override
                public void run() {
                    demo.setContent(Thread.currentThread().getName() + "的数据");
                    System.out.println("-----------------------");
             		System.out.println(Thread.currentThread().getName() + "--->" + demo.getContent());
                }
            });
            thread.setName("线程" + i);
            thread.start();
        }
    }
}
```

打印结果:

![1574149020726](C:\Users\heziyi6\Desktop\开发\资料-ThreadLocal\01-�ʼ�\img\002.png)

​	从结果可以看出多个线程在访问同一个变量的时候出现的异常，线程间的数据没有隔离。下面我们来看下采用 ThreadLocal 的方式来解决这个问题的例子。

```java
public class MyDemo {

    private static ThreadLocal<String> tl = new ThreadLocal<>();

    private String content;

    private String getContent() {
        return tl.get();
    }

    private void setContent(String content) {
         tl.set(content);
    }

    public static void main(String[] args) {
        MyDemo demo = new MyDemo();
        for (int i = 0; i < 5; i++) {
            Thread thread = new Thread(new Runnable() {
                @Override
                public void run() {
                    demo.setContent(Thread.currentThread().getName() + "的数据");
                    System.out.println("-----------------------");
                    System.out.println(Thread.currentThread().getName() + "--->" + demo.getContent());
                }
            });
            thread.setName("线程" + i);
            thread.start();
        }
    }
}
```

打印结果: 

​			![1574149117289](C:\Users\heziyi6\Desktop\开发\资料-ThreadLocal\01-�ʼ�\img\003.png)



从结果来看，这样很好的解决了多线程之间数据隔离的问题，十分方便。

## threadlocalmap

```java
static class ThreadLocalMap {

    static class Entry extends WeakReference<ThreadLocal<?>> {
        /** The value associated with this ThreadLocal. */
        Object value;

        Entry(ThreadLocal<?> k, Object v) {
            super(k);
            value = v;
        }
    }
```

![image-20220319001004918](C:\Users\heziyi6\AppData\Roaming\Typora\typora-user-images\image-20220319001004918.png)

线程保存ThreadLocalMap对象，对象主要通过Entry[]数组存放键{threadlocal}值，通过threadlocal的threadLocalHashCode定位存放数组位置，Entry extendsWeakReference\<ThreadLocal> 的value保存变量副本，通过Entry.get获取threadlocal。

如果这里使用普通的key-value形式来定义存储结构，实质上就会造成节点的生命周期与线程强绑定，只要线程没有销毁，那么节点在GC分析中一直处于可达状态，没办法被回收，而程序本身也无法判断是否可以清理节点。弱引用是Java中四档引用的第三档，比软引用更加弱一些，如果一个对象没有强引用链可达，那么一般活不过下一次GC。当某个ThreadLocal已经没有强引用可达，则随着它被垃圾回收，在ThreadLocalMap里对应的Entry的键值会失效，这为ThreadLocalMap本身的垃圾清理提供了便利。

## ThreadLocal 是怎么解决并发安全的？

 ThreadLocal 这是 Java 提供的一种保存线程私有信息的机制，因为其在整个线程生命周期内有效，所以可以方便地在一个线程关联的不同业务模块之间传递信息，比如事务 ID、Cookie 等上下文相关信息。 ThreadLocal 为每一个线程维护变量的副本，把共享数据的可见范围限制在同一个线程之内，其实现原理是，在 ThreadLocal 类中有一个 Map（ThreadLocal.ThreadLocalMap)，用于存储每一个线程的变量的副本。

使用 ThreadLocal 要注意 remove！ ThreadLocal 的实现是基于一个所谓的 ThreadLocalMap，在 ThreadLocalMap 中，它的 key 是一个弱引用。 通常弱引用都会和引用队列配合清理机制使用，但是 ThreadLocal 是个例外，它并没有这么做。 这意味着，废弃项目的回收依赖于显式地触发，否则就要等待线程结束，进而回收相应 ThreadLocalMap！这就是很多 OOM 的来源，所以通常都会建议，应用一定要自己负责 remove，并且不要和线程池配合，因为 worker 线程往往是不会退出的。





##  ThreadLocal类与synchronized关键字

#### 1.3.1 synchronized同步方式

情况1：用类直接在两个线程中调用两个不同的同步方法

结果：会产生互斥。

解释：因为对静态对象加锁实际上对类（.class）加锁，类对象只有一个，可以理解为任何时候都只有一个空间，里面有N个房间，一把锁，因此房间（同步方法）之间一定是互斥的。

注：上述情况和用单例模式声明一个对象来调用非静态方法的情况是一样的，因为永远就只有这一个对象。所以访问同步方法之间一定是互斥的。



情况2：用一个类的静态对象在两个线程中调用静态方法或非静态方法

结果：会产生互斥。

解释：因为是一个对象调用，同上。



情况3：一个对象在两个线程中分别调用一个静态同步方法和一个非静态同步方法

结果：不会产生互斥。

解释：因为虽然是一个对象调用，但是两个方法的锁类型不同，调用的静态方法实际上是类对象在调用，即这两个方法产生的并不是同一个对象锁，因此不会互斥，会并发执行。




​	这里可能有的朋友会觉得在上述例子中我们完全可以通过加锁来实现这个功能。我们首先来看一下用synchronized代码块实现的效果:

```java
public class Demo02 {
    
    private String content;

    public String getContent() {
        return content;
    }

    public void setContent(String content) {
        this.content = content;
    }

    public static void main(String[] args) {
        Demo02 demo02 = new Demo02();
        
        for (int i = 0; i < 5; i++) {
            Thread t = new Thread(){
                @Override
                public void run() {
                    synchronized (Demo02.class){
                        demo02.setContent(Thread.currentThread().getName() + "的数据");
                        System.out.println("-------------------------------------");
                        String content = demo02.getContent();
                        System.out.println(Thread.currentThread().getName() + "--->" + content);
                    }
                }
            };
            t.setName("线程" + i);
            t.start();
        }
    }
}
```

打印结果: 

​			![1578321788844](C:\Users\heziyi6\Desktop\开发\资料-ThreadLocal\01-�ʼ�\img\007.png)

​	从结果可以发现, 加锁确实可以解决这个问题，但是在这里我们强调的是线程数据隔离的问题，并不是多线程共享数据的问题, 在这个案例中使用synchronized关键字是不合适的。

#### 1.3.2 ThreadLocal与synchronized的区别

​	虽然ThreadLocal模式与synchronized关键字都用于处理多线程并发访问变量的问题, 不过两者处理问题的角度和思路不同。



|        | synchronized                                                 | ThreadLocal                                                  |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 原理   | 同步机制采用'以时间换空间'的方式, 只提供了一份变量,让不同的线程排队访问 | ThreadLocal采用'以空间换时间'的方式, 为每一个线程都提供了一份变量的副本,从而实现同时访问而相不干扰 |
| 侧重点 | 多个线程之间访问资源的同步                                   | 多线程中让每个线程之间的数据相互隔离                         |



```tex
总结： 在刚刚的案例中，虽然使用ThreadLocal和synchronized都能解决问题,但是使用ThreadLocal更为合适,因为这样可以使程序拥有更高的并发性。
```





## ThreadLocal运用场景之事务案例

​	通过以上的介绍，我们已经基本了解ThreadLocal的特点。但是它具体是运用在什么场景中呢？ 接下来让我们看一个案例： 事务操作。





从名字我们就可以看到ThreadLocal叫做线程变量，意思是ThreadLocal中填充的变量属于当前线程，该变量对其他线程而言是隔离的。**ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量**。
从字面意思来看非常容易理解，但是从实际使用的角度来看，就没那么容易了，作为一个面试常问的点，使用场景那也是相当的丰富：
1、在进行对象跨层传递的时候，使用ThreadLocal可以避免多次传递，打破层次间的约束。
2、线程间数据隔离
3、进行事务操作，用于存储线程事务信息。
4、数据库连接，Session会话管理。

> ThreadLocal是解决线程安全问题一个很好的思路，它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。

在Java的多线程编程中，为保证多个线程对共享变量的安全访问，通常会使用synchronized来保证同一时刻只有一个线程对共享变量进行操作。这种情况下可以将[类变量](https://links.jianshu.com/go?to=https%3A%2F%2Fbaike.baidu.com%2Fitem%2F%E7%B1%BB%E5%8F%98%E9%87%8F)放到ThreadLocal类型的对象中，使变量在每个线程中都有独立拷贝，不会出现一个线程读取变量时而被另一个线程修改的现象。最常见的ThreadLocal使用场景为用来解决数据库连接、Session管理等。在下面会例举几个场景。

**ThreadLocal的应用场景# Session管理**



```java
public static Session getSession() throws InfrastructureException {  
 Session s = (Session) threadSession.get();
 try {
 if (s == null) {
 s = getSessionFactory().openSession();
 threadSession.set(s);
 }
 } catch (HibernateException ex) {
 throw new InfrastructureException(ex);
 }
 return s;
}
```



**ThreadLocal的应用场景# 多线程**



```java
/* 
* @Author 安仔夏天很勤奋
 * Create Date is  2019/3/21
 *
 * 描述 Java中的ThreadLocal类允许我们创建只能被同一个线程读写的变量。
 * 因此，如果一段代码含有一个ThreadLocal变量的引用，即使两个线程同时执行这段代码，
 * 它们也无法访问到对方的ThreadLocal变量。
 */
public class ThreadLocalExsample {

 /**
 * 创建了一个MyRunnable实例，并将该实例作为参数传递给两个线程。两个线程分别执行run()方法，
 * 并且都在ThreadLocal实例上保存了不同的值。如果它们访问的不是ThreadLocal对象并且调用的set()方法被同步了，
 * 则第二个线程会覆盖掉第一个线程设置的值。但是，由于它们访问的是一个ThreadLocal对象，
 * 因此这两个线程都无法看到对方保存的值。也就是说，它们存取的是两个不同的值。
 */
 public static class MyRunnable implements Runnable {
 /**
 * 实例化了一个ThreadLocal对象。我们只需要实例化对象一次，并且也不需要知道它是被哪个线程实例化。
 * 虽然所有的线程都能访问到这个ThreadLocal实例，但是每个线程却只能访问到自己通过调用ThreadLocal的set()方法设置的值。即使是两个不同的线程在同一个ThreadLocal对象上设置了不同的值，
 * 他们仍然无法访问到对方的值。
 */
 private ThreadLocal threadLocal = new ThreadLocal();
 @Override
 public void run() {
 //一旦创建了一个ThreadLocal变量，你可以通过如下代码设置某个需要保存的值
 threadLocal.set((int) (Math.random() * 100D));
 try {
 Thread.sleep(2000);
 } catch (InterruptedException e) {
 }
 //可以通过下面方法读取保存在ThreadLocal变量中的值
 System.out.println("-------threadLocal value-------"+threadLocal.get());
 }
 }

 public static void main(String[] args) {
 MyRunnable sharedRunnableInstance = new MyRunnable();
 Thread thread1 = new Thread(sharedRunnableInstance);
 Thread thread2 = new Thread(sharedRunnableInstance);
 thread1.start();
 thread2.start();
 }
}

运行结果
-------threadLocal value-------38
-------threadLocal value-------88
```

> ThreadLocal 中 set 和 get 操作的都是对应线程的 table数组，因此在不同的线程中访问同一个 ThreadLocal 对象的 set 和 get 进行存取数据是不会相互干扰的。

总结

在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals**，这个threadLocals就是用来存储实际的变量副本的**，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。 初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。 然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。



ThreadLocal有什么用
简单说ThreadLocal就是一种以空间换时间的做法，在每个Thread里面维护了一个以开地址法实现的ThreadLocal.ThreadLocalMap，**把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了**

为什么可以避免线程安全问题？ThreadLocal，即线程本地变量。如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个本地拷贝，多个线程操作这个变量的时候，实际是操作自己本地内存里面的变量，从而起到线程隔离的作用，避免了线程安全问题。

```java
//创建一个ThreadLocal变量
static ThreadLocal<String> localVariable = new ThreadLocal<>();
```





1. 实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的；
2. 为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像上面代码中的longLocal和stringLocal；
3. 在进行get之前，必须先set，否则会报空指针异常；如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。 因为在上面的代码分析过程中，我们发现如果没有先set的话，即在map中查找不到对应的存储，则会通过调用setInitialValue方法返回i，而在setInitialValue方法中，有一个语句是T value = initialValue()， 而默认情况下，initialValue方法返回的是null。

对照着几段关键源码来看:

```java
public class Thread implements Runnable {
//ThreadLocal.ThreadLocalMap是Thread的属性
ThreadLocal.ThreadLocalMap threadLocals = null;
}
```

ThreadLocal中的关键方法set()和get():

```java
public void set(T value) {
Thread t = Thread.currentThread(); //获取当前线程t
ThreadLocalMap map = getMap(t); //根据当前线程获取到ThreadLocalMap
if (map != null)
map.set(this, value); //K，V设置到ThreadLocalMap中
else
createMap(t, value); //创建一个新的ThreadLocalMap
}
public T get() {
Thread t = Thread.currentThread();//获取当前线程t
ThreadLocalMap map = getMap(t);//根据当前线程获取到ThreadLocalMap
if (map != null) {
//由this（即ThreadLoca对象）得到对应的Value，即ThreadLocal的泛型值
ThreadLocalMap.Entry e = map.getEntry(this);
if (e != null) {
@SuppressWarnings("unchecked")
T result = (T)e.value;
return result;
}
}
return setInitialValue();
}
```

ThreadLocalMap的Entry数组

```java
static class ThreadLocalMap {
static class Entry extends WeakReference<ThreadLocal<?>> {
/** The value associated with this ThreadLocal. */
Object value;
Entry(ThreadLocal<?> k, Object v) {
super(k);
value = v;
}
}
}
```



所以怎么回答「ThreadLocal的实现原理」？如下，结构图：

![image-20210920173755147](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210920173755147.png)

Thread类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，即每个线程都有一个属于自己的ThreadLocalMap。
ThreadLocalMap内部维护着Entry数组，每个Entry代表一个完整的对象，key是ThreadLocal本身，value是ThreadLocal的泛型值。
**每个线程在往ThreadLocal里设置值的时候，都是往自己的ThreadLocalMap里存，读也是以某个ThreadLocal作为引用，在自己的map里找对应的key，从而实现了线程隔离。**



## ThreadLocal 内存泄露问题

![image-20210920174052762](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210920174052762.png)

![image-20210920175720247](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210920175720247.png)



弱引用：只要垃圾回收机制一运行，不管JVM的内存空间是否充足，都会回收该对象占用的内存。
弱引用比较容易被回收。因此，如果ThreadLocal（ThreadLocalMap的Key）被垃圾回收器回收了，但是因为ThreadLocalMap生命周期和Thread是一样的，它这时候如果不被回收，就会出现这种情况：
ThreadLocalMap的key没了，value还在，这就会「造成了内存泄漏问题」。
**如何「解决内存泄漏问题」？使用完ThreadLocal后，及时调用remove()方法释放内存空间。**



## 自定义一个threadlocal

```java
public class ThreadLocalExt extends ThreadLocal{
    @Override//这样重写了以后ThreadLocal的第一次get()方法就有了默认值，不会返回null
    protected Object initialValue(){
        return System.currentTimeMillis();
    }
}
```



```java
public class Tools {
    public static ThreadLocalExt ext = new ThreadLocalExt();
}
```

```java
public class ThreadA extends Thread{

    @Override
    public void run(){
     try{
         for (int i = 0; i < 10; i++) {
             System.out.println("在A中取值"+Tools.ext.get());
             Thread.sleep(100);

         }
     }catch (InterruptedException e)
     {
         e.printStackTrace();
     }
    }

}
```



```java
public class Run {
    public static void main(String[] args) {
        try {
            for (int i = 0; i < 10; i++) {
                System.out.println("在main中取值" + Tools.ext.get());
                Thread.sleep(100);
            }
            Thread.sleep(5000);
            ThreadA a = new ThreadA();
            a.start();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```

![image-20211015115043989](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211015115043989.png)

由结果可知父子线程各自有所拥有的值。

## threadlocalmap不是只能存一个值吗为什么要用数组

为什么 ThreadLocal.ThreadLocalMap 底层是长度 16 的数组呢？
对 ThreadLocal 的操作见第 3 点，可以看到 ThreadLocal 每次 set 方法都是对同个 key（因为是同个 ThreadLocal 对象，所以 key 肯定都是一样的）进行操作。

如此操作，看似对 ThreadLocal 的操作永远只会存 1 个值，那用长度为 1 的数组它不香吗？为什么还要用 16 长度呢？

好了，其实这里有个需要注意的地方，ThreadLocal 是可以存多个值的

那怎么存多个值呢？看如下代码：


```java
// 在主线程执行以下代码：
ThreadLocal<String> threadLocal = new ThreadLocal<>();
threadLocal.set("七淅在学Java");
ThreadLocal<String> threadLocal2 = new ThreadLocal<>();
threadLocal2.set("七淅在学Java2");
```

按代码执行后，看着是 new 了 2 个 ThreadLocal 对象，但实际上，数据的存储都是在同一个 ThreadLocal.ThreadLocalMap 上操作的

再次强调：ThreadLocal.ThreadLocalMap 才是数据存取的地方，ThreadLocal 只是 api 调用入口）。真相在 ThreadLocal 类源码的 getMap()

因此上述代码最终结果就是一个 ThreadLocalMap 存了 2 个不同 ThreadLocal 对象作为 key，对应 value 为 七淅在学Java、七淅在学Java2。


# 用线程池实现异步编程

![image-20210921123421200](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210921123421200.png)

![image-20210921123602778](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210921123602778.png)

![image-20210921132247203](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210921132247203.png)



## worker

![image-20210921141122697](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210921141122697.png)

![image-20210921141506948](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210921141506948.png)

![image-20210921141549197](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210921141549197.png)

![image-20210921141627853](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210921141627853.png)



## 如果你提交任务时，线程池队列已满，这时会发生什么

这里区分一下：
★★★如果使用的是无界队列LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为LinkedBlockingQueue可以近乎认为是一个无穷大的队列，可以无限存放任务
★★★如果使用的是有界队列比如ArrayBlockingQueue，任务首先会被添加到ArrayBlockingQueue中，ArrayBlockingQueue满了，会根据maximumPoolSize的值增加线程数量，如果增加了线程数量还是处理不过来，ArrayBlockingQueue继续满，那么则会使用拒绝策略RejectedExecutionHandler处理满了的任务，默认是AbortPolicy



# CompletableFuture的使用

获取所有完成结果——allOf

```java
public static CompletableFuture<Void> allOf(CompletableFuture<?>... cfs)
```

allOf方法，当所有给定的任务完成后，返回一个全新的已完成CompletableFuture

```java
CompletableFuture<Integer> future1 = CompletableFuture.supplyAsync(() -> {
            try {
                //使用sleep()模拟耗时操作
                TimeUnit.SECONDS.sleep(2);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return 1;
        });

        CompletableFuture<Integer> future2 = CompletableFuture.supplyAsync(() -> {
            return 2;
        });
        CompletableFuture.allOf(future1, future1);
        // 输出3
        System.out.println(future1.join()+future2.join());
```

获取率先完成的任务结果——anyOf

- 仅等待Future集合种最快结束的任务完成（有可能因为他们试图通过不同的方式计算同一个值），并返回它的结果。 **小贴士** ：如果最快完成的任务出现了异常，也会先返回异常，如果害怕出错可以加个**exceptionally()** 去处理一下可能发生的异常并设定默认返回值

```java
public static CompletableFuture<Object> anyOf(CompletableFuture<?>... cfs)
CompletableFuture<Integer> future = CompletableFuture.supplyAsync(() -> {
            throw new NullPointerException();
        });

        CompletableFuture<Integer> future2 = CompletableFuture.supplyAsync(() -> {
            try {
                // 睡眠3s模拟延时
                TimeUnit.SECONDS.sleep(3);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return 1;
        });
        CompletableFuture<Object> anyOf = CompletableFuture
                .anyOf(future, future2)
                .exceptionally(error -> {
                    error.printStackTrace();
                    return 2;
                });
        System.out.println(anyOf.join());
```

## 循环创建并发任务

```java
public static void main(String[] args) {
        long begin = System.currentTimeMillis();
        // 自定义一个线程池
        ExecutorService executorService = Executors.newFixedThreadPool(10);
        // 循环创建10个CompletableFuture
        List<CompletableFuture<Integer>> collect = IntStream.range(1, 10).mapToObj(i -> {
            CompletableFuture<Integer> future = CompletableFuture.supplyAsync(() -> {
                // 在i=5的时候抛出一个NPE
                if (i == 5) {
                    throw new NullPointerException();
                }
                try {
                    // 每个依次睡眠1-9s，模拟线程耗时
                    TimeUnit.SECONDS.sleep(i);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(i);
                return i;
            }, executorService)
                    // 这里处理一下i=5时出现的NPE
                    // 如果这里不处理异常，那么异常会在所有任务完成后抛出,小伙伴可自行测试
                    .exceptionally(Error -> {
                        try {
                            TimeUnit.SECONDS.sleep(5);
                            System.out.println(100);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                        return 100;
                    });
            return future;
        }).collect(Collectors.toList());
        // List列表转成CompletableFuture的Array数组,使其可以作为allOf()的参数
        // 使用join()方法使得主线程阻塞，并等待所有并行线程完成
        CompletableFuture.allOf(collect.toArray(new CompletableFuture[]{})).join();
        System.out.println("最终耗时" + (System.currentTimeMillis() - begin) + "毫秒");
        executorService.shutdown();
    }
```

## 使用CompletableFuture场景

[CompletableFuture用法详解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/344431341)

- 执行比较耗时的操作时，尤其是那些依赖一个或多个远程服务的操作，使用异步任务可以改善程序的性能，加快程序的响应速度
- 使用CompletableFuture类，它提供了异常管理的机制，让你有机会抛出、管理异步任务执行种发生的异常
- 如果这些异步任务之间相互独立，或者他们之间的的某一些的结果是另一些的输入，你可以讲这些异步任务构造或合并成一个



# 进阶 JUC



## 有三个线程T1,T2,T3,如何保证顺序执行？
在多线程中有多种方法让线程按特定顺序执行，你可以用线程类的join()方法在一个线程中启动另一个线程，另外一个线程完成该线程继续执行。为了确保三个线程的顺序你应该先启动最后一个(T3调用T2，T2调用T1)，这样T1就会先完成而T3最后完成。
实际上先启动三个线程中哪一个都行， 因为在每个线程的run方法中用join方法限定了三个线程的执行顺序。

```java
// 1.现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行
public static void main(String[] args) {
final Thread t1 = new Thread(new Runnable() {
@Override
public void run() {
System.out.println("t1");
}
});
final Thread t2 = new Thread(new Runnable() {
@Override
public void run() {
try {
// 引用t1线程，等待t1线程执行完
t1.join();
} catch (InterruptedException e) {
e.printStackTrace();
}
System.out.println("t2");
}
});
Thread t3 = new Thread(new Runnable() {
@Override
public void run() {
try {
// 引用t2线程，等待t2线程执行完
t2.join();
} catch (InterruptedException e) {
e.printStackTrace();
}
System.out.println("t3");
}
});
t3.start();//这里三个线程的启动顺序可以任意，大家可以试下！
t2.start();
t1.start();
}
}
```

方法二：

```java
/**
 * @author wwj
 * 通过SingleThreadExecutor让线程按顺序执行
 */
public class ThreadPoolDemo {

    static ExecutorService executorService = Executors.newSingleThreadExecutor();

    public static void main(String[] args) throws Exception {

        final Thread thread1 = new Thread(new Runnable() {
            @Override
            public void run() {
                System.out.println("产品经理规划新需求");
            }
        });

        final Thread thread2 = new Thread(new Runnable() {
            @Override
            public void run() {
                System.out.println("开发人员开发新需求功能");
            }
        });

        Thread thread3 = new Thread(new Runnable() {
            @Override
            public void run() {
                System.out.println("测试人员测试新功能");
            }
        });
          executorService.submit(thread1);
        System.out.println("然后，开发人员开发新需求功能...");
        executorService.submit(thread2);
        System.out.println("最后，测试人员测试新功能...");
        executorService.submit(thread3);
        executorService.shutdown();
```

使用condition:

```java
Condition（条件变量）:通常与一个锁关联。需要在多个Contidion中共享一个锁时，可以传递一个Lock/RLock实例给构造方法，否则它将自己生成一个RLock实例。

Condition中await()方法类似于Object类中的wait()方法。

Condition中await(long time,TimeUnit unit)方法类似于Object类中的wait(long time)方法。

Condition中signal()方法类似于Object类中的notify()方法。

Condition中signalAll()方法类似于Object类中的notifyAll()方法。
 代码：
    public class ThreadConditionDemo {

    private static Lock lock = new ReentrantLock();
    private static Condition condition1 = lock.newCondition();
    private static Condition condition2 = lock.newCondition();

    /**
     * 为什么要加这两个标识状态?
     * 如果没有状态标识，当t1已经运行完了t2才运行，t2在等待t1唤醒导致t2永远处于等待状态
     */
    private static Boolean t1Run = false;
    private static Boolean t2Run = false;

    public static void main(String[] args) {

        final Thread thread1 = new Thread(new Runnable() {
            @Override
            public void run() {
                lock.lock();
                System.out.println("产品经理规划新需求");
                t1Run = true;
                condition1.signal();
                lock.unlock();
            }
        });

        final Thread thread2 = new Thread(new Runnable() {
            @Override
            public void run() {
                lock.lock();
                try {
                    if(!t1Run){
                        System.out.println("开发人员先休息会...");
                        condition1.await();
                    }
                    System.out.println("开发人员开发新需求功能");
                    t2Run = true;
                    condition2.signal();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                lock.unlock();
            }
        });

        Thread thread3 = new Thread(new Runnable() {
            @Override
            public void run() {
                lock.lock();
                try {
                    if(!t2Run){
                        System.out.println("测试人员先休息会...");
                        condition2.await();
                    }
                    System.out.println("测试人员测试新功能");
                    lock.unlock();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        });

        System.out.println("早上：");
        System.out.println("测试人员来上班了...");
        thread3.start();
        System.out.println("产品经理来上班了...");
        thread1.start();
        System.out.println("开发人员来上班了...");
        thread2.start();
```

使用countdownlatch:

```java
/**
 * @author wwj
 * 通过CountDownLatch（倒计数）使线程按顺序执行
 */
public class ThreadCountDownLatchDemo {

    /**
     * 用于判断线程一是否执行，倒计时设置为1，执行后减1
     */
    private static CountDownLatch c1 = new CountDownLatch(1);

    /**
     * 用于判断线程二是否执行，倒计时设置为1，执行后减1
     */
    private static CountDownLatch c2 = new CountDownLatch(1);

    public static void main(String[] args) {
        final Thread thread1 = new Thread(new Runnable() {
            @Override
            public void run() {
                System.out.println("产品经理规划新需求");
                //对c1倒计时-1
                c1.countDown();
            }
        });

        final Thread thread2 = new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    //等待c1倒计时，计时为0则往下运行
                    c1.await();
                    System.out.println("开发人员开发新需求功能");
                    //对c2倒计时-1
                    c2.countDown();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        });

        Thread thread3 = new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    //等待c2倒计时，计时为0则往下运行
                    c2.await();
                    System.out.println("测试人员测试新功能");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        });

        System.out.println("早上：");
        System.out.println("测试人员来上班了...");
        thread3.start();
        System.out.println("产品经理来上班了...");
        thread1.start();
        System.out.println("开发人员来上班了...");
        thread2.start();
    }
```

cyclicbarrier:

````java
 static CyclicBarrier barrier1 = new CyclicBarrier(2);
    static CyclicBarrier barrier2 = new CyclicBarrier(2);

    public static void main(String[] args) {

        final Thread thread1 = new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    System.out.println("产品经理规划新需求");
                    //放开栅栏1
                    barrier1.await();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } catch (BrokenBarrierException e) {
                    e.printStackTrace();
                }
            }
        });

        final Thread thread2 = new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    //放开栅栏1
                    barrier1.await();
                    System.out.println("开发人员开发新需求功能");
                    //放开栅栏2
                    barrier2.await();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } catch (BrokenBarrierException e) {
                    e.printStackTrace();
                }
            }
        });

        final Thread thread3 = new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    //放开栅栏2
                    barrier2.await();
                    System.out.println("测试人员测试新功能");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } catch (BrokenBarrierException e) {
                    e.printStackTrace();
                }
            }
        });

        System.out.println("早上：");
        System.out.println("测试人员来上班了...");
        thread3.start();
        System.out.println("产品经理来上班了...");
        thread1.start();
        System.out.println("开发人员来上班了...");
        thread2.start();
    }
````





## 题目：四个线程ABCD，其中D要等到ABC全部执行完后才执行，且ABC同步运行

可以采用CounteddownLatch

1.首先创建计数器，设置初始值

2.在等待线程里调用countDownLatch.await()方法

3.在其他线程里调用countDownLatch.countDown()方法

4.当其他线程的countDown()方法把计数值变成0时，等待线程里的countDownLatch.await()立即退出

```java
private static void runDAfterABC(){
        int worker = 3;
    CountDownLatch countDownLatch = new CountDownLatch(worker);
    new Thread(new Runnable() {

    @Override
   public void run(){
            System.out.println("d is waiting");
            try{
                countDownLatch.await();//调用这个以后，d会挂起等待，直到abc结束
                System.out.println("all down,d is starting");
            }catch (InterruptedException e){
                e.printStackTrace();
            }
        }
    }).start();
    for(char threadName = 'A';threadName <= 'C';threadName++)
    {
        final String tn = String.valueOf(threadName);
        System.out.println(tn + "is working");
        new Thread(new Runnable() {
            @Override
            public void run() {

                try{
                    Thread.sleep(1000);//个人理解只有这个sleep以后三个线程才会几乎同时执行
                }catch (InterruptedException e){
                    e.printStackTrace();
                }

                System.out.println(tn+"finished work");
                countDownLatch.countDown();
            }
        }).start();

    }
```

结果：

![image-20210901103229311](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210901103229311.png)

前面四行几乎同时打印，后面四行几乎同时打印

CountDownLatch 就是一个倒计数器，我们把初始计数值设置为 3，当 D 运行时，先调用 countDownLatch.await() 检查计数器值是否为 0，若不为 0 则保持等待状态；当 A B C 各自运行完后都会利用 countDownLatch.countDown()，将倒计数器减 1，当三个都运行完后，计数器被减至 0；此时立即触发 D 的 await() 运行结束，继续向下执行。

因此，CountDownLatch 适用于一个线程去等待多个线程的情况。

## 1114按序打印

#### 

难度简单368

给你一个类：

```
public class Foo {
  public void first() { print("first"); }
  public void second() { print("second"); }
  public void third() { print("third"); }
}
```

三个不同的线程 A、B、C 将会共用一个 `Foo` 实例。

- 线程 A 将会调用 `first()` 方法
- 线程 B 将会调用 `second()` 方法
- 线程 C 将会调用 `third()` 方法

请设计修改程序，以确保 `second()` 方法在 `first()` 方法之后被执行，`third()` 方法在 `second()` 方法之后被执行。

```java
  public Foo() {
        
    }

    public void first(Runnable printFirst) throws InterruptedException {
        
        // printFirst.run() outputs "first". Do not change or remove this line.
        printFirst.run();
    }

    public void second(Runnable printSecond) throws InterruptedException {
        
        // printSecond.run() outputs "second". Do not change or remove this line.
        printSecond.run();
    }

    public void third(Runnable printThird) throws InterruptedException {
        
        // printThird.run() outputs "third". Do not change or remove this line.
        printThird.run();
    }  public Foo() {
        
    }

    public void first(Runnable printFirst) throws InterruptedException {
        
        // printFirst.run() outputs "first". Do not change or remove this line.
        printFirst.run();
    }

    public void second(Runnable printSecond) throws InterruptedException {
        
        // printSecond.run() outputs "second". Do not change or remove this line.
        printSecond.run();
    }

    public void third(Runnable printThird) throws InterruptedException {
        
        // printThird.run() outputs "third". Do not change or remove this line.
        printThird.run();
    }  public Foo() {
        
    }

    public void first(Runnable printFirst) throws InterruptedException {
        
        // printFirst.run() outputs "first". Do not change or remove this line.
        printFirst.run();
    }

    public void second(Runnable printSecond) throws InterruptedException {
        
        // printSecond.run() outputs "second". Do not change or remove this line.
        printSecond.run();
    }

    public void third(Runnable printThird) throws InterruptedException {
        
        // printThird.run() outputs "third". Do not change or remove this line.
        printThird.run();
    }  public Foo() {
        
    }

    public void first(Runnable printFirst) throws InterruptedException {
        
        // printFirst.run() outputs "first". Do not change or remove this line.
        printFirst.run();
    }

    public void second(Runnable printSecond) throws InterruptedException {
        
        // printSecond.run() outputs "second". Do not change or remove this line.
        printSecond.run();
    }

    public void third(Runnable printThird) throws InterruptedException {
        
        // printThird.run() outputs "third". Do not change or remove this line.
        printThird.run();
    }
```



-----

答案：

```java
private Semaphore one = new Semaphore(0);
private Semaphore two = new Semaphore(0);
    public Foo() {
        
    }

    public void first(Runnable printFirst) throws InterruptedException {
        
        // printFirst.run() outputs "first". Do not change or remove this line.
        printFirst.run();
        one.release();
    }

    public void second(Runnable printSecond) throws InterruptedException {
        one.acquire();//Semaphore为0就是没有资源可以获取，调用acquire只能阻塞，当有别的线程调用release时，才会给信号量加一个资源
        // printSecond.run() outputs "second". Do not change or remove this line.
        printSecond.run();
    two.release();
    }

    public void third(Runnable printThird) throws InterruptedException {
        two.acquire();
        // printThird.run() outputs "third". Do not change or remove this line.
        printThird.run();
    }
```



## 三个运动员各自准备，等到三个人都准备好后，再一起跑

上面是一个形象的比喻，针对 线程 A B C 各自开始准备，直到三者都准备完毕，然后再同时运行 。也就是要实现一种 线程之间互相等待 的效果，那应该怎么来实现呢？

**上面的 CountDownLatch 可以用来倒计数，但当计数完毕，只有一个线程的 await() 会得到响应，无法让多个线程同时触发。**

为了实现线程间互相等待这种需求，我们可以利用 CyclicBarrier 数据结构，它的基本用法是：

1. 先创建一个公共 CyclicBarrier 对象，设置 同时等待 的线程数，CyclicBarrier cyclicBarrier = new CyclicBarrier(3);
2. 这些线程同时开始自己做准备，自身准备完毕后，需要等待别人准备完毕，这时调用 cyclicBarrier.await(); 即可开始等待别人；
3. 当指定的 同时等待 的线程数都调用了 cyclicBarrier.await(); 时，意味着这些线程都准备完毕好，然后这些线程才 同时继续执行。

实现代码如下，设想有三个跑步运动员，各自准备好后等待其他人，全部准备好后才开始跑：

```java
private static void runDAfterABC(){
        int worker = 3;
    CyclicBarrier cyclicBarrier = new CyclicBarrier(worker);
    for(char tname = 'A';tname <= 'C';tname++)
    {
        final String na = String.valueOf(tname);
        new Thread(new Runnable() {
            @Override
            public void run() {

                System.out.println(na+"is prepara");
                int prepara = new Random().nextInt(1000)+1000;
                try{
                    Thread.sleep(prepara);
                }catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
                try{
                    System.out.println(na+"is finish");
                    cyclicBarrier.await();//当前运动员准备完毕，等待另外的运动员
                }catch (InterruptedException e)
                {
                    e.printStackTrace();
                }catch (BrokenBarrierException e)
                {
                    e.printStackTrace();
                }
                System.out.println(na+"is running");
            }
        }).start();

    }

}
```

测试发现，finish输出时间不是同时，running输出的时间是同时

![image-20210901104641479](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20210901104641479.png)

synchronized是java内置的关键字，它提供了一种独占的加锁方式。synchronized的获取和释放锁由jvm实现，用户不需要显示的释放锁，非常方便，然而synchronized也有一定的局限性，例如：
1. 当线程尝试获取锁的时候，如果获取不到锁会一直阻塞，这个阻塞的过程，用户无法控制
2. 如果获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。JDK1.5之后发布，加入了Doug Lea实现的java.util.concurrent包。包内提供了Lock类，用来提供更多扩展的加锁功能。Lock弥补了synchronized的局限，提供了更加细粒度的加锁功能。

## 两个线程交替打印ab

```java
public class WaitAndNotify {
private static Object lock = new Object();
static class ThreadA implements Runnable {
@Override
public void run() {
synchronized (lock) {
for (int i = 0; i < 5; i++) {
try {
System.out.println("ThreadA: " + i);
lock.notify();
lock.wait();
} catch (InterruptedException e) {
e.printStackTrace();
}
}
lock.notify();//实验发现如果A线程如果不加这个会导致程序一直不结束，但B线程不加这个不会，推测是B最后一次进入了wait方法以后一直
}
}
}
static class ThreadB implements Runnable {
@Override
public void run() {
synchronized (lock) {
for (int i = 0; i < 5; i++) {
try {
System.out.println("ThreadB: " + i);
lock.notify();
lock.wait();
} catch (InterruptedException e) {
e.printStackTrace();
}
}
lock.notify();
}
}
}
public static void main(String[] args) throws InterruptedException {
new Thread(new ThreadA()).start();
Thread.sleep(1000);
new Thread(new ThreadB()).start();
}
}
// 输出：
ThreadA: 0
ThreadB: 0
ThreadA: 1
ThreadB: 1
ThreadA: 2
ThreadB: 2
//需要注意的是等待/通知机制使⽤的是使⽤同⼀个对象锁
  也可以将上面改成用volatile
    public class Signal {
private static volatile int signal = 0;
static class ThreadA implements Runnable {
@Override
public void run() {
while (signal < 5) {
if (signal % 2 == 0) {
System.out.println("threadA: " + signal);
synchronized (this) {
signal++;
}
}
}
}
}
static class ThreadB implements Runnable {
@Override
public void run() {
while (signal < 5) {
if (signal % 2 == 1) {
System.out.println("threadB: " + signal);
synchronized (this) {
signal = signal + 1;
}
}
}
}
}

```





　

## 定时器Timer的使用 

在JDK库中Timer类主要负责计划任务的功能，也就是在指定的时间开始执行某一个任务。

Timer类的主要作用就是设置计划任务，但封装任务的类却是TimerTask类，执行计划任务的代码要放入TimerTask的子类中，因为TimerTask是一个抽象类。 在下面的章节中将介绍全部与计划任务有关的方法。

### 方法schedule（TimerTask task，Date time）的测试 



该方法的作用是在指定的日期执行一次某一任务。下一步将新创建的Timer改成守护线程。新建Java类Run1TimerIsDaemon.java，代码如下：

```java
 package test;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.Timer;
import java.util.TimerTask;
public class Run1TimerIsDaemon {
  private static Timer timer = new Timer(true);//这里加了参数将新创建的Timer改为守护线程
  static public class MyTask extends TimerTask {
    @Override
    public void run() {
      System.out.println("运行了！时间为：" + new Date());
    }
  }
  public static void main(String[] args) {
    try {
      MyTask task = new MyTask();
      SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
      String dateString = "2014-10-12 12:05:00";
      Date dateRef = sdf.parse(dateString);
      System.out.println("字符串时间：" + dateRef.toLocaleString() + " 当前时间："
        \+ new Date().toLocaleString());
      timer.schedule(task, dateRef);
    } catch (ParseException e) {
      e.printStackTrace();
    }
  }
}
```



 程序运行后的结果如图5-4所示。 图5-4　守护线程创建成功进程退出 程序运行后迅速结束当前的进程，并且TimerTask中的任务不再被运行，因为进程已经结束了。

 TimerTask是以队列的方式一个一个被顺序执行的，所以执行的时间有可能和预期的时间不一致，因为前面的任务有可能消耗的时间较长，则后面的任务运行的时间也会被延迟。 

TimerTask类中的cancel（）方法的作用是将自身从任务队列中清除。

Timer类的cancel（）方法 和TimerTask类中的cancel（）方法清除自身不同，Timer类中的cancel（）方法的作用是将任务队列中的全部任务清空。 





## Stream和CompletableFuture结合

下面我们借用Stream和CompletableFuture来看看业务线程如何并发地发起多次rpc请求，从而缩短整个处理流程的耗时。  

```java
 // 1.生成ip列表
    List<String> ipList = new ArrayList<String>();    
for (int i = 1; i <= 10; ++i) {
      ipList.add("192.168.0." + i);
    }

    // 2.并发调用
    long start = System.currentTimeMillis();
    List<CompletableFuture<String>> futureList = ipList.stream()
        .map(ip -> CompletableFuture.supplyAsync(() -> rpcCall(ip, ip)))//同步转换为异步
        .collect(Collectors.toList());//收集结果

    //3.等待所有异步任务执行完毕
    List<String> resultList = futureList.stream()
                      .map(future -> future.join())
                      　//同步等待结果
                      .collect(Collectors.toList());
                      　//对结果进行收集

    // 4.输出
    resultList.stream().forEach(r -> System.out.println(r));

​    System.out.println("cost:" + (System.currentTimeMillis() - start)); 


```













# 饿汉懒汉模式



什么是立即加载？立即加载就是使用类的时候已经将对象创建完毕，常见的实现办法就是直接new实例化。而立即加载从中文的语境来看，有“着急”、“急迫”的含义，所以也称为“饿汉模式”。 **立即加载/“饿汉模式”是在调用方法前，实例已经被创建了，**来看一下实现代码。 创建测试用的项目，名称为singleton_0，创建类MyObject.java代码如下：

```java
ackage test;
public class MyObject {
  // 立即加载方式==饿汉模式
  private static MyObject myObject = new MyObject();
  private MyObje}
  public static MyObject getInstance() {
    // 此代码版本为立即加载
    // 此版本代码的缺点是不能有其他实例变量
    // 因为getInstance()方法没有同步
    // 所以有可能出现非线程安全问题
    return myObject;
  }
} 
创建线程类MyThread.java代码如下： 
    package extthread;
import test.MyObject;
public class MyThread extends Thread {
  @Override
  public void run() {
    System.out.println(MyObject.getInstance().hashCode());
  }
} 
创建运行类Run.java代码如下： 
    package test.run;
import extthread.MyThread;
public class Run {
  public static void main(String[] args) {
    MyThread t1 = new MyThread();
    MyThread t2 = new MyThread();
    MyThread t3 = new MyThread();
    t1.start();
    t2.start();
    t3.start();
  }
}
```



 p
ct() {控制台打印的hashCode是同一个值，说明对象是同一个，也就实现了立即加载型单例设计模式。　延迟加载/“懒汉模式” 什么是延迟加载？延迟加载就是在调用get（）方法时实例才被创建，常见的实现办法就是在get（）方法中进行new实例化。而延迟加载从中文的语境来看，是“缓慢”、“不急迫”的含义，所以也称为“懒汉模式”。 1.延迟加载/“懒汉模式”解析 延迟加载/“懒汉模式”是在调用方法时实例才被创建。一起来看一下实现代码。 创建测试用的项目singleton_1，创建类MyObject.java代码如下：

```java
package test;
public class MyObject {
  private static MyObject myObject;
  private MyObject() {
  }
public static MyObject getInstance() {
    // 延迟加载
    if (myObject != null) {
    } else {
      myObject = new MyObject();
    }
    return myObject;
  }
} 创建线程类MyThread.java代码如下： package extthread;
import test.MyObject;
public class MyThread extends Thread {
  @Override
  public void run() {
    System.out.println(MyObject.getInstance().hashCode());
  }
} 
```



 创建运行类Run.java代码如下： 

```java
package test.run;
import extthread.MyThread;
public class Run {
  public static void main(String[] args) {
    MyThread t1 = new MyThread();
    t1.start();
  }
}
```




此实验虽然取得一个对象的实例，但如果是在多线程的环境中，就会出现取出多个实例的情况，与单例模式的初衷是相背离的。



# Java并发包中原子操作类原理剖析



java中原子操作更新数组，Atomic包提供了哪几个类？

-----AtomicIntegerArray 原子更新整型数组里的元素 AtomicLongArray原子更新长整型数组里的元素 AtomicReferenceArray 原子更新引用类型数组里的元素

引用操作：

```java
public class AtomicReferenceTest {
public static AtomicReference<user> atomicUserRef = new
AtomicReference<user>();
public static void main(String[] args) {
User user = new User("conan"， 15);
atomicUserRef.set(user);
User updateUser = new User("Shinichi"， 17);
atomicUserRef.compareAndSet(user， updateUser);
System.out.println(atomicUserRef.get().getName());
System.out.println(atomicUserRef.get().getOld());
}
static class User {
private String name;
private int old;
public User(String name， int old) {
this.name = name;
this.old = old;
}
public String getName() {
return name;
}
public int getOld() {
return old;
}
}
}
```

AtomicInteger的常用方法：

public final int get() //获取当前的值
public final int getAndSet(int newValue)//获取当前的值，并设置新的值
public final int getAndIncrement()//获取当前的值，并⾃增
public final int getAndDecrement() //获取当前的值，并⾃减
public final int getAndAdd(int delta) //获取当前的值，并加上预期的值
boolean compareAndSet(int expect, int update) //如果输⼊的数值等于预期值，
则以原⼦⽅式将该值设置为输⼊值（update）
public final void lazySet(int newValue)//最终设置为newValue,使⽤ lazySet
设置之后可能导致其他线程在之后的⼀⼩段时间内还是可以读到旧的值。



JUC包提供了一系列的原子性操作类，这些类都是使用非阻塞算法CAS+volatile+native方法实现的，相比使用锁（sychonized)实现原子性操作这在性能上有很大提高。由于原子性操作类的原理都大致相同，所以本章只讲解最简单的AtomicLong类的实现原理以及JDK 8中新增的LongAdder和LongAccumulator类的原理。有了这些基础，再去理解其他原子性操作类的实现就不会感到困难了。JUC并发包中包含有**AtomicInteger、AtomicLong和AtomicBoolean**等原子性操作类，它们的原理类似，本章讲解AtomicLong类。AtomicLong是原子性递增或者递减类，其内部使用Unsafe来实现，我们看下面的代码。

cas原理是拿期望的值与原本的值进行比较，如果相同则更新成新的值

```java
public class AtomicLong extends Number implements java.io.Serializable {
    private static final long serialVersionUID = 1927816293512124184L;
//记录底层JVM是否长期支持无锁的compareAndSet。虽然内在的compareAndSetLong方法在这两种情况下都可以工作，但一些结构应该在Java级别处理，以避免锁定用户可见的锁。
    /**
     * Records whether the underlying JVM supports lockless
     * compareAndSet for longs. While the intrinsic compareAndSetLong
     * method works in either case, some constructions should be
     * handled at Java level to avoid locking user-visible locks.
     */
    static final boolean VM_SUPPORTS_LONG_CAS = VMSupportsCS8();

    /**
     * Returns whether underlying JVM supports lockless CompareAndSet
     * for longs. Called only once and cached in VM_SUPPORTS_LONG_CAS.
     */
    private static native boolean VMSupportsCS8();

    private static final Unsafe U = Unsafe.getUnsafe();
    private static final long VALUE
        = U.objectFieldOffset(AtomicLong.class, "value");

    private volatile long value;

    /**
     * Creates a new AtomicLong with the given initial value.
     *
     * @param initialValue the initial value
     */
    public AtomicLong(long initialValue) {
        value = initialValue;
    }

    /**
     * Creates a new AtomicLong with initial value {@code 0}.
     */
    public AtomicLong() {
    }

    /**
     * Returns the current value,
     * with memory effects as specified by {@link VarHandle#getVolatile}.
     *
     * @return the current value
     */
    public final long get() {
        return value;
    }

    /**
     * Sets the value to {@code newValue},
     * with memory effects as specified by {@link VarHandle#setVolatile}.
     *
     * @param newValue the new value
     */
    public final void set(long newValue) {
        // See JDK-8180620: Clarify VarHandle mixed-access subtleties
        U.putLongVolatile(this, VALUE, newValue);
    }

    /**
     * Sets the value to {@code newValue},
     * with memory effects as specified by {@link VarHandle#setRelease}.
     *
     * @param newValue the new value
     * @since 1.6
     */
    public final void lazySet(long newValue) {
        U.putLongRelease(this, VALUE, newValue);
    }

    /**
     * Atomically sets the value to {@code newValue} and returns the old value,
     * with memory effects as specified by {@link VarHandle#getAndSet}.
     *
     * @param newValue the new value
     * @return the previous value
     */
    public final long getAndSet(long newValue) {
        return U.getAndSetLong(this, VALUE, newValue);
    }

    
    public final boolean compareAndSet(long expectedValue, long newValue) {
        return U.compareAndSetLong(this, VALUE, expectedValue, newValue);
    }


    @Deprecated(since="9")
    public final boolean weakCompareAndSet(long expectedValue, long newValue) {
        return U.weakCompareAndSetLongPlain(this, VALUE, expectedValue, newValue);
    }

 
    public final boolean weakCompareAndSetPlain(long expectedValue, long newValue) {
        return U.weakCompareAndSetLongPlain(this, VALUE, expectedValue, newValue);
    }

    
    public final long getAndIncrement() {
        return U.getAndAddLong(this, VALUE, 1L);
    }

   
    public final long getAndDecrement() {
        return U.getAndAddLong(this, VALUE, -1L);
    }
    public final long getAndAdd(long delta) {
        return U.getAndAddLong(this, VALUE, delta);
    }

 
    public final long incrementAndGet() {
        return U.getAndAddLong(this, VALUE, 1L) + 1L;
    }


    public final long decrementAndGet() {
        return U.getAndAddLong(this, VALUE, -1L) - 1L;
    }

    public final long addAndGet(long delta) {
        return U.getAndAddLong(this, VALUE, delta) + delta;
    }

 
    ...}
```



```java
// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“⽐较并替换”的作⽤）
private static final Unsafe unsafe = Unsafe.getUnsafe();
private static final long valueOffset;
static {
try {
valueOffset = unsafe.objectFieldOffset
(AtomicInteger.class.getDeclaredField("value"));
} catch (Exception ex) { throw new Error(ex); }
}
private volatile int value;
```



 private static final Unsafe U = Unsafe.getUnsafe();为何能通过Unsafe.getUnsafe（）方法获取到Unsafe类的实例？其实这是因为AtomicLong类也是在rt.jar包下面的，AtomicLong类就是通过BootStarp类加载器进行加载的。 



前面讲过，AtomicLong通过CAS提供了非阻塞的原子性操作，相比使用阻塞算法的同步器来说它的性能已经很好了，但是JDK开发组并不满足于此。使用AtomicLong时，在高并发下大量线程会同时去竞争更新同一个原子变量，但是由于同时只有一个线程的CAS操作会成功，这就造成了大量线程竞争失败后，会通过无限循环不断进行自旋尝试CAS的操作，而这会白白浪费CPU资源。 因此JDK 8新增了一个原子性递增或者递减类LongAdder用来克服在高并发下使用AtomicLong的缺点。既然AtomicLong的性能瓶颈是由于过多线程同时去竞争一个变量的更新而产生的，那么如果把一个变量分解为多个变量，让同样多的线程去竞争多个资源，是不是就解决了性能问题？

是的，LongAdder就是这个思路。如图4-1所示。

![image-20211020170611904](C:\Users\14172\AppData\Roaming\Typora\typora-user-images\image-20211020170611904.png)

使用LongAdder时，则是在内部维护多个Cell变量，每个Cell里面有一个初始值为0的long型变量，这样，在同等并发量的情况下，争夺单个变量更新操作的线程量会减少，这变相地减少了争夺共享资源的并发量。**另外，多个线程在争夺同一个Cell原子变量时如果失败了，它并不是在当前Cell变量上一直自旋CAS重试，而是尝试在其他Cell的变量上进行CAS尝试，这个改变增加了当前线程重试CAS成功的可能性。**最后，在获取LongAdder当前值时，是把所有Cell变量的value值累加后再加上base返回的。 LongAdder维护了一个延迟初始化的原子性更新数组（默认情况下Cell数组是null）和一个基值变量base。由于Cells占用的内存是相对比较大的，所以一开始并不创建它，而是在需要时创建，也就是惰性加载。 当一开始判断Cell数组是null并且并发线程较少时，所有的累加操作都是对base变量进行的。保持Cell数组的大小为2的N次方，在初始化时Cell数组中的Cell元素个数为2，数组里面的变量实体是Cell类型。Cell类型是AtomicLong的一个改进，用来减少缓存的争用，也就是解决伪共享问题。 对于大多数孤立的多个原子操作进行字节填充是浪费的，因为原子性操作都是无规律地分散在内存中的（也就是说多个原子性变量的内存地址是不连续的），多个原子变量被放入同一个缓存行的可能性很小。但是原子性数组元素的内存地址是连续的，所以数组内的多个元素能经常共享缓存行，因此这里使用＠sun.misc.Contended注解对Cell类进行字节填充，这防止了数组中多个元素共享一个缓存行，在性能上是一个提升。 
